diff --git a/node_modules/react-native-vision-camera/android/.project b/node_modules/react-native-vision-camera/android/.project
new file mode 100644
index 0000000..315da03
--- /dev/null
+++ b/node_modules/react-native-vision-camera/android/.project
@@ -0,0 +1,34 @@
+<?xml version="1.0" encoding="UTF-8"?>
+<projectDescription>
+	<name>react-native-vision-camera</name>
+	<comment>Project react-native-vision-camera created by Buildship.</comment>
+	<projects>
+	</projects>
+	<buildSpec>
+		<buildCommand>
+			<name>org.eclipse.jdt.core.javabuilder</name>
+			<arguments>
+			</arguments>
+		</buildCommand>
+		<buildCommand>
+			<name>org.eclipse.buildship.core.gradleprojectbuilder</name>
+			<arguments>
+			</arguments>
+		</buildCommand>
+	</buildSpec>
+	<natures>
+		<nature>org.eclipse.jdt.core.javanature</nature>
+		<nature>org.eclipse.buildship.core.gradleprojectnature</nature>
+	</natures>
+	<filteredResources>
+		<filter>
+			<id>1761060382076</id>
+			<name></name>
+			<type>30</type>
+			<matcher>
+				<id>org.eclipse.core.resources.regexFilterMatcher</id>
+				<arguments>node_modules|\.git|__CREATED_BY_JAVA_LANGUAGE_SERVER__</arguments>
+			</matcher>
+		</filter>
+	</filteredResources>
+</projectDescription>
diff --git a/node_modules/react-native-vision-camera/android/bin/.project b/node_modules/react-native-vision-camera/android/bin/.project
new file mode 100644
index 0000000..315da03
--- /dev/null
+++ b/node_modules/react-native-vision-camera/android/bin/.project
@@ -0,0 +1,34 @@
+<?xml version="1.0" encoding="UTF-8"?>
+<projectDescription>
+	<name>react-native-vision-camera</name>
+	<comment>Project react-native-vision-camera created by Buildship.</comment>
+	<projects>
+	</projects>
+	<buildSpec>
+		<buildCommand>
+			<name>org.eclipse.jdt.core.javabuilder</name>
+			<arguments>
+			</arguments>
+		</buildCommand>
+		<buildCommand>
+			<name>org.eclipse.buildship.core.gradleprojectbuilder</name>
+			<arguments>
+			</arguments>
+		</buildCommand>
+	</buildSpec>
+	<natures>
+		<nature>org.eclipse.jdt.core.javanature</nature>
+		<nature>org.eclipse.buildship.core.gradleprojectnature</nature>
+	</natures>
+	<filteredResources>
+		<filter>
+			<id>1761060382076</id>
+			<name></name>
+			<type>30</type>
+			<matcher>
+				<id>org.eclipse.core.resources.regexFilterMatcher</id>
+				<arguments>node_modules|\.git|__CREATED_BY_JAVA_LANGUAGE_SERVER__</arguments>
+			</matcher>
+		</filter>
+	</filteredResources>
+</projectDescription>
diff --git a/node_modules/react-native-vision-camera/android/bin/CMakeLists.txt b/node_modules/react-native-vision-camera/android/bin/CMakeLists.txt
new file mode 100644
index 0000000..17097c1
--- /dev/null
+++ b/node_modules/react-native-vision-camera/android/bin/CMakeLists.txt
@@ -0,0 +1,88 @@
+project(VisionCamera)
+cmake_minimum_required(VERSION 3.9.0)
+
+set(PACKAGE_NAME "VisionCamera")
+set(BUILD_DIR ${CMAKE_SOURCE_DIR}/build)
+set(CMAKE_VERBOSE_MAKEFILE ON)
+set(CMAKE_CXX_STANDARD 17)
+
+# Third party libraries (Prefabs)
+find_package(ReactAndroid REQUIRED CONFIG)
+find_package(fbjni REQUIRED CONFIG)
+find_library(LOG_LIB log)
+
+# Enables OpenGL/EGL HardwareBuffer and EGLImageKHR APIs
+add_definitions(-DEGL_EGLEXT_PROTOTYPES)
+add_definitions(-DGL_GLEXT_PROTOTYPES)
+
+if (ENABLE_FRAME_PROCESSORS)
+        add_definitions(-DVISION_CAMERA_ENABLE_FRAME_PROCESSORS=true)
+else()
+        add_definitions(-DVISION_CAMERA_ENABLE_FRAME_PROCESSORS=false)
+endif()
+
+
+# Add react-native-vision-camera sources
+add_library(
+        ${PACKAGE_NAME}
+        SHARED
+        # Java JNI
+        src/main/cpp/VisionCamera.cpp
+        src/main/cpp/MutableJByteBuffer.cpp
+        # Frame Processor
+        src/main/cpp/frameprocessors/FrameHostObject.cpp
+        src/main/cpp/frameprocessors/FrameProcessorPluginHostObject.cpp
+        src/main/cpp/frameprocessors/JSIJNIConversion.cpp
+        src/main/cpp/frameprocessors/VisionCameraProxy.cpp
+        src/main/cpp/frameprocessors/java-bindings/JSharedArray.cpp
+        src/main/cpp/frameprocessors/java-bindings/JFrame.cpp
+        src/main/cpp/frameprocessors/java-bindings/JFrameProcessor.cpp
+        src/main/cpp/frameprocessors/java-bindings/JFrameProcessorPlugin.cpp
+        src/main/cpp/frameprocessors/java-bindings/JVisionCameraProxy.cpp
+        src/main/cpp/frameprocessors/java-bindings/JVisionCameraScheduler.cpp
+)
+
+# Header Search Paths (includes)
+target_include_directories(
+        ${PACKAGE_NAME}
+        PRIVATE
+        "src/main/cpp"
+        "src/main/cpp/frameprocessors"
+        "src/main/cpp/frameprocessors/java-bindings"
+        "${NODE_MODULES_DIR}/react-native/ReactCommon"
+        "${NODE_MODULES_DIR}/react-native/ReactCommon/callinvoker"
+        "${NODE_MODULES_DIR}/react-native/ReactAndroid/src/main/jni/react/turbomodule" # <-- CallInvokerHolder JNI wrapper
+)
+
+# Link everything together
+target_link_libraries(
+        ${PACKAGE_NAME}
+        ${LOG_LIB}                          # <-- Logcat logger
+        android                             # <-- Android JNI core
+        ReactAndroid::jsi                   # <-- RN: JSI
+        fbjni::fbjni                        # <-- fbjni
+)
+
+# Link react-native (different prefab between RN 0.75 and RN 0.76)
+if(ReactAndroid_VERSION_MINOR GREATER_EQUAL 76)
+    target_link_libraries(
+        ${PACKAGE_NAME}
+        ReactAndroid::reactnative                 # <-- RN: Native Modules umbrella prefab
+    )
+else()
+    target_link_libraries(
+        ${PACKAGE_NAME}
+        ReactAndroid::reactnativejni              # <-- RN: JNI Utils (e.g. CallInvoker)
+    )
+endif()
+
+# Optionally also add Frame Processors here
+message("VisionCamera: Frame Processors: ${ENABLE_FRAME_PROCESSORS}!")
+if (ENABLE_FRAME_PROCESSORS)
+    message("VisionCamera: Linking react-native-worklets...")
+    find_package(react-native-worklets-core REQUIRED CONFIG)
+    target_link_libraries(
+            ${PACKAGE_NAME}
+            react-native-worklets-core::rnworklets
+    )
+endif()
diff --git a/node_modules/react-native-vision-camera/android/bin/README.md b/node_modules/react-native-vision-camera/android/bin/README.md
new file mode 100644
index 0000000..6eebb68
--- /dev/null
+++ b/node_modules/react-native-vision-camera/android/bin/README.md
@@ -0,0 +1,26 @@
+# android
+
+This folder contains the Android-platform-specific code for react-native-vision-camera.
+
+## Prerequesites
+
+1. Install ktlint
+    ```sh
+    brew install ktlint
+    ```
+
+## Getting Started
+
+It is recommended that you work on the code using the Example project (`example/android/`), since that always includes the React Native header files, plus you can easily test changes that way.
+
+You can however still edit the library project here by opening this folder with Android Studio.
+
+## Committing
+
+Before committing, make sure that you're not violating the Kotlin codestyles. To do that, run the following command:
+
+```bash
+bun check-android
+```
+
+This will also try to automatically fix any errors by re-formatting the Kotlin code.
diff --git a/node_modules/react-native-vision-camera/android/bin/build.gradle b/node_modules/react-native-vision-camera/android/bin/build.gradle
new file mode 100644
index 0000000..0b65a5c
--- /dev/null
+++ b/node_modules/react-native-vision-camera/android/bin/build.gradle
@@ -0,0 +1,251 @@
+import java.nio.file.Paths
+import com.android.Version
+
+def agpVersion = Version.ANDROID_GRADLE_PLUGIN_VERSION.tokenize('.')[0].toInteger()
+def androidManifestPath = agpVersion >= 7 ? 'src/main/AndroidManifest.xml' : 'src/hasNamespace/AndroidManifest.xml'
+
+buildscript {
+  def kotlin_version = rootProject.ext.has("kotlinVersion") ? rootProject.ext.get("kotlinVersion") : project.properties["VisionCamera_kotlinVersion"]
+
+  repositories {
+    maven {
+      url "https://plugins.gradle.org/m2/"
+    }
+    mavenCentral()
+    google()
+  }
+
+  dependencies {
+    classpath "com.android.tools.build:gradle:8.7.2"
+    classpath "org.jetbrains.kotlin:kotlin-gradle-plugin:$kotlin_version"
+  }
+}
+
+def resolveBuildType() {
+    Gradle gradle = getGradle()
+    String tskReqStr = gradle.getStartParameter().getTaskRequests()["args"].toString()
+
+    return tskReqStr.contains("Release") ? "release" : "debug"
+}
+
+def isNewArchitectureEnabled() {
+  // To opt-in for the New Architecture, you can either:
+  // - Set `newArchEnabled` to true inside the `gradle.properties` file
+  // - Invoke gradle with `-newArchEnabled=true`
+  // - Set an environment variable `ORG_GRADLE_PROJECT_newArchEnabled=true`
+  return project.hasProperty("newArchEnabled") && project.newArchEnabled == "true"
+}
+
+if (isNewArchitectureEnabled()) {
+  apply plugin: "com.facebook.react"
+}
+apply plugin: "com.android.library"
+apply plugin: "kotlin-android"
+
+def safeExtGet(prop, fallback) {
+  rootProject.ext.has(prop) ? rootProject.ext.get(prop) : fallback
+}
+
+def safeExtGetBool(prop, fallback) {
+  Boolean.parseBoolean("${safeExtGet(prop, fallback)}")
+}
+
+def reactNativeArchitectures() {
+  def value = project.getProperties().get("reactNativeArchitectures")
+  return value ? value.split(",") : ["armeabi-v7a", "x86", "x86_64", "arm64-v8a"]
+}
+
+static def findNodeModules(baseDir) {
+  def basePath = baseDir.toPath().normalize()
+  // Node"s module resolution algorithm searches up to the root directory,
+  // after which the base path will be null
+  while (basePath) {
+    def nodeModulesPath = Paths.get(basePath.toString(), "node_modules")
+    def reactNativePath = Paths.get(nodeModulesPath.toString(), "react-native")
+    if (nodeModulesPath.toFile().exists() && reactNativePath.toFile().exists()) {
+      return nodeModulesPath.toString()
+    }
+    basePath = basePath.getParent()
+  }
+  throw new GradleException("react-native-vision-camera: Failed to find node_modules/ path!")
+}
+
+logger.warn("[VisionCamera] Thank you for using VisionCamera ❤️")
+logger.warn("[VisionCamera] If you enjoy using VisionCamera, please consider sponsoring this project: https://github.com/sponsors/mrousavy")
+
+def nodeModules = findNodeModules(projectDir)
+logger.warn("[VisionCamera] node_modules found at $nodeModules")
+
+def enableFrameProcessors = safeExtGetBool('VisionCamera_enableFrameProcessors', true)
+logger.warn("[VisionCamera] VisionCamera_enableFrameProcessors is set to $enableFrameProcessors!")
+
+def hasWorklets = findProject(":react-native-worklets-core") != null
+if (hasWorklets) {
+  logger.warn("[VisionCamera] react-native-worklets-core found, Frame Processors are ${enableFrameProcessors ? "enabled" : "disabled"}!")
+} else {
+  logger.warn("[VisionCamera] react-native-worklets-core not found, Frame Processors are disabled!")
+  enableFrameProcessors = false
+}
+
+def enableCodeScanner = safeExtGetBool('VisionCamera_enableCodeScanner', false)
+logger.warn("[VisionCamera] VisionCamera_enableCodeScanner is set to $enableCodeScanner!")
+
+repositories {
+  google()
+  mavenCentral()
+}
+
+android {
+    namespace 'com.mrousavy.camera'
+  if (agpVersion >= 7) {
+    namespace "com.mrousavy.camera"
+  }
+
+  // Used to override the NDK path/version on internal CI or by allowing
+  // users to customize the NDK path/version from their root project (e.g. for M1 support)
+  if (rootProject.hasProperty("ndkPath")) {
+    ndkPath rootProject.ext.ndkPath
+  }
+  if (rootProject.hasProperty("ndkVersion")) {
+    ndkVersion rootProject.ext.ndkVersion
+  }
+
+  buildFeatures {
+    prefab true
+    prefabPublishing true
+  }
+
+  prefab {
+    VisionCamera {
+      headers "${project.buildDir}/headers/visioncamera/"
+    }
+  }
+
+  defaultConfig {
+    minSdkVersion safeExtGet("minSdkVersion", 21)
+    compileSdkVersion safeExtGet("compileSdkVersion", 34)
+    targetSdkVersion safeExtGet("targetSdkVersion", 34)
+    versionCode 1
+    versionName "1.0"
+    buildConfigField "boolean", "IS_NEW_ARCHITECTURE_ENABLED", isNewArchitectureEnabled().toString()
+
+    externalNativeBuild {
+      cmake {
+        cppFlags "-O2 -frtti -fexceptions -Wall -Wno-unused-variable -fstack-protector-all"
+        arguments "-DANDROID_STL=c++_shared",
+                "-DNODE_MODULES_DIR=${nodeModules}",
+                "-DENABLE_FRAME_PROCESSORS=${enableFrameProcessors ? "ON" : "OFF"}",
+                "-DANDROID_SUPPORT_FLEXIBLE_PAGE_SIZES=ON"
+        abiFilters (*reactNativeArchitectures())
+      }
+    }
+  }
+
+  sourceSets {
+    main {
+      manifest.srcFile androidManifestPath
+    }
+  }
+
+  compileOptions {
+    sourceCompatibility JavaVersion.VERSION_1_8
+    targetCompatibility JavaVersion.VERSION_1_8
+  }
+
+  externalNativeBuild {
+    cmake {
+      path "CMakeLists.txt"
+    }
+  }
+  packagingOptions {
+    doNotStrip resolveBuildType() == "debug" ? "**/**/*.so" : ""
+    excludes = [
+            "META-INF",
+            "META-INF/**",
+            "**/libc++_shared.so",
+            "**/libfbjni.so",
+            "**/libjsi.so",
+            "**/libfolly_json.so",
+            "**/libfolly_runtime.so",
+            "**/libglog.so",
+            "**/libhermes.so",
+            "**/libhermes-executor-debug.so",
+            "**/libhermes_executor.so",
+            "**/libreactnative.so",
+            "**/libreactnativejni.so",
+            "**/libturbomodulejsijni.so",
+            "**/libreact_nativemodule_core.so",
+            "**/libjscexecutor.so",
+            "**/libhermestooling.so"
+    ]
+  }
+}
+
+dependencies {
+  //noinspection GradleDynamicVersion
+  implementation "com.facebook.react:react-android:+"
+
+  // CameraX dependency
+  def camerax_version = "1.5.0-alpha03"
+  implementation "androidx.camera:camera-core:${camerax_version}"
+  implementation "androidx.camera:camera-camera2:${camerax_version}"
+  implementation "androidx.camera:camera-lifecycle:${camerax_version}"
+  implementation "androidx.camera:camera-video:${camerax_version}"
+  implementation "androidx.camera:camera-view:${camerax_version}"
+  implementation "androidx.camera:camera-extensions:${camerax_version}"
+
+  // Lifecycle dependency
+  implementation "androidx.lifecycle:lifecycle-common:2.8.7"
+
+  // Some Coroutines extension functions
+  implementation "org.jetbrains.kotlinx:kotlinx-coroutines-android:1.9.0"
+
+  if (enableCodeScanner) {
+    // User enabled code-scanner, so we bundle the 2.4 MB model in the app.
+    implementation 'com.google.mlkit:barcode-scanning:17.3.0'
+  } else {
+    // Fall-back to just including the code for the CodeScanner to avoid the 2.4 MB bundle in the app.
+    // On devices with Google Play Services, this can also download the CodeScanner model on-demand.
+    implementation "com.google.android.gms:play-services-mlkit-barcode-scanning:18.3.1"
+  }
+
+  if (enableFrameProcessors) {
+    // Frame Processor integration (optional)
+    implementation project(":react-native-worklets-core")
+  }
+}
+
+task deleteCmakeCache() {
+  doFirst {
+    delete "${projectDir}/.cxx"
+    delete "${nodeModules}/react-native-vision-camera/android/.cxx"
+    delete "${nodeModules}/react-native-vision-camera/android/build"
+  }
+}
+
+task prepareHeaders(type: Copy) {
+  from fileTree('./src/main/cpp').filter { it.isFile() }
+  include "*.h"
+  into "${project.buildDir}/headers/visioncamera/react-native-vision-camera/"
+  includeEmptyDirs = false
+}
+
+preBuild.dependsOn(prepareHeaders)
+
+tasks.configureEach { task ->
+  // C++ build
+  if (task.name.contains("configureCMakeDebug")) {
+    rootProject.getTasksByName("packageReactNdkDebugLibs", true).forEach {
+      task.dependsOn(it)
+    }
+  }
+  if (task.name.contains("configureCMakeRel")) {
+    rootProject.getTasksByName("packageReactNdkReleaseLibs", true).forEach {
+      task.dependsOn(it)
+    }
+  }
+  // C++ clean
+  if (task.name.contains("clean")) {
+    task.dependsOn(deleteCmakeCache)
+  }
+}
diff --git a/node_modules/react-native-vision-camera/android/bin/build/generated/source/buildConfig/debug/com/mrousavy/camera/BuildConfig.class b/node_modules/react-native-vision-camera/android/bin/build/generated/source/buildConfig/debug/com/mrousavy/camera/BuildConfig.class
new file mode 100644
index 0000000..1a826ae
Binary files /dev/null and b/node_modules/react-native-vision-camera/android/bin/build/generated/source/buildConfig/debug/com/mrousavy/camera/BuildConfig.class differ
diff --git a/node_modules/react-native-vision-camera/android/bin/gradle.properties b/node_modules/react-native-vision-camera/android/bin/gradle.properties
new file mode 100644
index 0000000..81ee012
--- /dev/null
+++ b/node_modules/react-native-vision-camera/android/bin/gradle.properties
@@ -0,0 +1,19 @@
+## For more details on how to configure your build environment visit
+# http://www.gradle.org/docs/current/userguide/build_environment.html
+#
+# Specifies the JVM arguments used for the daemon process.
+# The setting is particularly useful for tweaking memory settings.
+# Default value: -Xmx1024m -XX:MaxPermSize=256m
+org.gradle.jvmargs=-Xms512M -Xmx4g -XX:MaxMetaspaceSize=1g -Dkotlin.daemon.jvm.options="-Xmx1g"
+org.gradle.parallel=true
+org.gradle.daemon=true
+org.gradle.configureondemand=true
+#
+# When configured, Gradle will run in incubating parallel mode.
+# This option should only be used with decoupled projects. More details, visit
+# http://www.gradle.org/docs/current/userguide/multi_project_builds.html#sec:decoupled_projects
+# org.gradle.parallel=true
+#Fri Feb 19 20:46:14 CET 2021
+VisionCamera_kotlinVersion=1.7.20
+android.enableJetifier=true
+android.useAndroidX=true
diff --git a/node_modules/react-native-vision-camera/android/bin/src/hasNamespace/AndroidManifest.xml b/node_modules/react-native-vision-camera/android/bin/src/hasNamespace/AndroidManifest.xml
new file mode 100644
index 0000000..f5a395b
--- /dev/null
+++ b/node_modules/react-native-vision-camera/android/bin/src/hasNamespace/AndroidManifest.xml
@@ -0,0 +1,4 @@
+<manifest xmlns:android="http://schemas.android.com/apk/res/android"
+          package="com.mrousavy.camera">
+
+</manifest>
diff --git a/node_modules/react-native-vision-camera/android/bin/src/main/AndroidManifest.xml b/node_modules/react-native-vision-camera/android/bin/src/main/AndroidManifest.xml
new file mode 100644
index 0000000..0a0938a
--- /dev/null
+++ b/node_modules/react-native-vision-camera/android/bin/src/main/AndroidManifest.xml
@@ -0,0 +1,3 @@
+<manifest xmlns:android="http://schemas.android.com/apk/res/android">
+
+</manifest>
diff --git a/node_modules/react-native-vision-camera/android/bin/src/main/cpp/MutableJByteBuffer.cpp b/node_modules/react-native-vision-camera/android/bin/src/main/cpp/MutableJByteBuffer.cpp
new file mode 100644
index 0000000..e472da3
--- /dev/null
+++ b/node_modules/react-native-vision-camera/android/bin/src/main/cpp/MutableJByteBuffer.cpp
@@ -0,0 +1,36 @@
+//
+// Created by Marc Rousavy on 17.01.24.
+//
+
+#include "MutableJByteBuffer.h"
+
+#include <fbjni/ByteBuffer.h>
+#include <fbjni/fbjni.h>
+#include <jsi/jsi.h>
+
+namespace vision {
+
+MutableJByteBuffer::MutableJByteBuffer(jni::alias_ref<jni::JByteBuffer> byteBuffer) {
+  _byteBuffer = jni::make_global(byteBuffer);
+}
+
+MutableJByteBuffer::~MutableJByteBuffer() {
+  // Hermes GC might destroy HostObjects on an arbitrary Thread which might not be
+  // connected to the JNI environment. To make sure fbjni can properly destroy
+  // the Java method, we connect to a JNI environment first.
+  jni::ThreadScope::WithClassLoader([&] { _byteBuffer.reset(); });
+}
+
+uint8_t* MutableJByteBuffer::data() {
+  return _byteBuffer->getDirectBytes();
+}
+
+size_t MutableJByteBuffer::size() const {
+  return _byteBuffer->getDirectSize();
+}
+
+jni::global_ref<jni::JByteBuffer> MutableJByteBuffer::getByteBuffer() {
+  return _byteBuffer;
+}
+
+} // namespace vision
diff --git a/node_modules/react-native-vision-camera/android/bin/src/main/cpp/MutableJByteBuffer.h b/node_modules/react-native-vision-camera/android/bin/src/main/cpp/MutableJByteBuffer.h
new file mode 100644
index 0000000..421af3e
--- /dev/null
+++ b/node_modules/react-native-vision-camera/android/bin/src/main/cpp/MutableJByteBuffer.h
@@ -0,0 +1,33 @@
+//
+// Created by Marc Rousavy on 17.01.24.
+//
+
+#pragma once
+
+#include <fbjni/ByteBuffer.h>
+#include <fbjni/fbjni.h>
+#include <jsi/jsi.h>
+#include <memory>
+
+namespace vision {
+
+using namespace facebook;
+
+class MutableJByteBuffer : public jsi::MutableBuffer {
+public:
+  /**
+   * Wraps the given JByteBuffer in a MutableBuffer for use in JS.
+   */
+  explicit MutableJByteBuffer(jni::alias_ref<jni::JByteBuffer> byteBuffer);
+  ~MutableJByteBuffer();
+
+public:
+  uint8_t* data() override;
+  size_t size() const override;
+  jni::global_ref<jni::JByteBuffer> getByteBuffer();
+
+private:
+  jni::global_ref<jni::JByteBuffer> _byteBuffer;
+};
+
+} // namespace vision
diff --git a/node_modules/react-native-vision-camera/android/bin/src/main/cpp/MutableRawBuffer.h b/node_modules/react-native-vision-camera/android/bin/src/main/cpp/MutableRawBuffer.h
new file mode 100644
index 0000000..43121c2
--- /dev/null
+++ b/node_modules/react-native-vision-camera/android/bin/src/main/cpp/MutableRawBuffer.h
@@ -0,0 +1,48 @@
+//
+//  MutableRawBuffer.h
+//  VisionCamera
+//
+//  Created by Marc Rousavy on 17.01.24.
+//  Copyright © 2024 mrousavy. All rights reserved.
+//
+
+#pragma once
+
+#include <jsi/jsi.h>
+#include <memory>
+
+namespace vision {
+
+using namespace facebook;
+
+class MutableRawBuffer : public jsi::MutableBuffer {
+
+public:
+  explicit MutableRawBuffer(uint8_t* data, size_t size, bool freeOnDealloc) {
+    _size = size;
+    _data = data;
+    _freeOnDealloc = freeOnDealloc;
+  }
+  explicit MutableRawBuffer(size_t size) : MutableRawBuffer(new uint8_t[size], size, true) {}
+
+  ~MutableRawBuffer() {
+    if (_freeOnDealloc) {
+      delete[] _data;
+    }
+  }
+
+public:
+  uint8_t* data() override {
+    return _data;
+  }
+  size_t size() const override {
+    return _size;
+  }
+
+private:
+  uint8_t* _data;
+  size_t _size;
+  bool _freeOnDealloc;
+};
+
+} // namespace vision
diff --git a/node_modules/react-native-vision-camera/android/bin/src/main/cpp/VisionCamera.cpp b/node_modules/react-native-vision-camera/android/bin/src/main/cpp/VisionCamera.cpp
new file mode 100644
index 0000000..2d446ca
--- /dev/null
+++ b/node_modules/react-native-vision-camera/android/bin/src/main/cpp/VisionCamera.cpp
@@ -0,0 +1,19 @@
+#include "JFrameProcessor.h"
+#include "JSharedArray.h"
+#include "JVisionCameraProxy.h"
+#include "JVisionCameraScheduler.h"
+#include "VisionCameraProxy.h"
+#include <fbjni/fbjni.h>
+#include <jni.h>
+
+JNIEXPORT jint JNICALL JNI_OnLoad(JavaVM* vm, void*) {
+  return facebook::jni::initialize(vm, [] {
+    vision::VisionCameraInstaller::registerNatives();
+    vision::JVisionCameraProxy::registerNatives();
+    vision::JVisionCameraScheduler::registerNatives();
+#if VISION_CAMERA_ENABLE_FRAME_PROCESSORS
+    vision::JFrameProcessor::registerNatives();
+    vision::JSharedArray::registerNatives();
+#endif
+  });
+}
diff --git a/node_modules/react-native-vision-camera/android/bin/src/main/cpp/frameprocessors/FrameHostObject.cpp b/node_modules/react-native-vision-camera/android/bin/src/main/cpp/frameprocessors/FrameHostObject.cpp
new file mode 100644
index 0000000..09970a9
--- /dev/null
+++ b/node_modules/react-native-vision-camera/android/bin/src/main/cpp/frameprocessors/FrameHostObject.cpp
@@ -0,0 +1,229 @@
+//
+// Created by Marc on 19/06/2021.
+//
+
+#include "FrameHostObject.h"
+
+#include <fbjni/fbjni.h>
+#include <jni.h>
+
+#include "MutableRawBuffer.h"
+
+#include <string>
+#include <vector>
+
+#include <android/hardware_buffer.h>
+#include <android/hardware_buffer_jni.h>
+
+namespace vision {
+
+using namespace facebook;
+
+FrameHostObject::FrameHostObject(const jni::alias_ref<JFrame::javaobject>& frame) : _frame(make_global(frame)), _baseClass(nullptr) {}
+
+FrameHostObject::~FrameHostObject() {
+  // Hermes GC might destroy HostObjects on an arbitrary Thread which might not be
+  // connected to the JNI environment. To make sure fbjni can properly destroy
+  // the Java method, we connect to a JNI environment first.
+  jni::ThreadScope::WithClassLoader([&] { _frame = nullptr; });
+}
+
+std::vector<jsi::PropNameID> FrameHostObject::getPropertyNames(jsi::Runtime& rt) {
+  std::vector<jsi::PropNameID> result;
+  // Ref Management
+  result.push_back(jsi::PropNameID::forUtf8(rt, std::string("isValid")));
+  result.push_back(jsi::PropNameID::forUtf8(rt, std::string("incrementRefCount")));
+  result.push_back(jsi::PropNameID::forUtf8(rt, std::string("decrementRefCount")));
+
+  if (_frame->getIsValid()) {
+    // Frame Properties
+    result.push_back(jsi::PropNameID::forUtf8(rt, std::string("width")));
+    result.push_back(jsi::PropNameID::forUtf8(rt, std::string("height")));
+    result.push_back(jsi::PropNameID::forUtf8(rt, std::string("bytesPerRow")));
+    result.push_back(jsi::PropNameID::forUtf8(rt, std::string("planesCount")));
+    result.push_back(jsi::PropNameID::forUtf8(rt, std::string("orientation")));
+    result.push_back(jsi::PropNameID::forUtf8(rt, std::string("isMirrored")));
+    result.push_back(jsi::PropNameID::forUtf8(rt, std::string("timestamp")));
+    result.push_back(jsi::PropNameID::forUtf8(rt, std::string("pixelFormat")));
+    // Conversion
+    result.push_back(jsi::PropNameID::forUtf8(rt, std::string("toString")));
+    result.push_back(jsi::PropNameID::forUtf8(rt, std::string("toArrayBuffer")));
+    result.push_back(jsi::PropNameID::forUtf8(rt, std::string("getNativeBuffer")));
+    result.push_back(jsi::PropNameID::forUtf8(rt, std::string("withBaseClass")));
+  }
+
+  return result;
+}
+
+#define JSI_FUNC [=](jsi::Runtime & runtime, const jsi::Value& thisValue, const jsi::Value* arguments, size_t count) -> jsi::Value
+
+jsi::Value FrameHostObject::get(jsi::Runtime& runtime, const jsi::PropNameID& propName) {
+  auto name = propName.utf8(runtime);
+
+  // Properties
+  if (name == "isValid") {
+    return jsi::Value(_frame->getIsValid());
+  }
+  if (name == "width") {
+    return jsi::Value(_frame->getWidth());
+  }
+  if (name == "height") {
+    return jsi::Value(_frame->getHeight());
+  }
+  if (name == "isMirrored") {
+    return jsi::Value(_frame->getIsMirrored());
+  }
+  if (name == "orientation") {
+    auto orientation = _frame->getOrientation();
+    auto string = orientation->getUnionValue();
+    return jsi::String::createFromUtf8(runtime, string->toStdString());
+  }
+  if (name == "pixelFormat") {
+    auto pixelFormat = _frame->getPixelFormat();
+    auto string = pixelFormat->getUnionValue();
+    return jsi::String::createFromUtf8(runtime, string->toStdString());
+  }
+  if (name == "timestamp") {
+    return jsi::Value(static_cast<double>(_frame->getTimestamp()));
+  }
+  if (name == "bytesPerRow") {
+    return jsi::Value(_frame->getBytesPerRow());
+  }
+  if (name == "planesCount") {
+    return jsi::Value(_frame->getPlanesCount());
+  }
+
+  // Internal Methods
+  if (name == "incrementRefCount") {
+    jsi::HostFunctionType incrementRefCount = JSI_FUNC {
+      // Increment retain count by one.
+      _frame->incrementRefCount();
+      return jsi::Value::undefined();
+    };
+    return jsi::Function::createFromHostFunction(runtime, jsi::PropNameID::forUtf8(runtime, "incrementRefCount"), 0, incrementRefCount);
+  }
+  if (name == "decrementRefCount") {
+    auto decrementRefCount = JSI_FUNC {
+      // Decrement retain count by one. If the retain count is zero, the Frame gets closed.
+      _frame->decrementRefCount();
+      return jsi::Value::undefined();
+    };
+    return jsi::Function::createFromHostFunction(runtime, jsi::PropNameID::forUtf8(runtime, "decrementRefCount"), 0, decrementRefCount);
+  }
+
+  // Conversion methods
+  if (name == "getNativeBuffer") {
+    jsi::HostFunctionType getNativeBuffer = JSI_FUNC {
+#if __ANDROID_API__ >= 26
+      AHardwareBuffer* hardwareBuffer = _frame->getHardwareBuffer();
+      AHardwareBuffer_acquire(hardwareBuffer);
+      uintptr_t pointer = reinterpret_cast<uintptr_t>(hardwareBuffer);
+      jsi::HostFunctionType deleteFunc = [=](jsi::Runtime& runtime, const jsi::Value& thisArg, const jsi::Value* args,
+                                             size_t count) -> jsi::Value {
+        AHardwareBuffer_release(hardwareBuffer);
+        return jsi::Value::undefined();
+      };
+
+      jsi::Object buffer(runtime);
+      buffer.setProperty(runtime, "pointer", jsi::BigInt::fromUint64(runtime, pointer));
+      buffer.setProperty(runtime, "delete",
+                         jsi::Function::createFromHostFunction(runtime, jsi::PropNameID::forUtf8(runtime, "delete"), 0, deleteFunc));
+      return buffer;
+#else
+      throw jsi::JSError(runtime, "Cannot get Platform Buffer - getNativeBuffer() requires HardwareBuffers, which are "
+                                  "only available on Android API 26 or above. Set your app's minSdk version to 26 and try again.");
+#endif
+    };
+    return jsi::Function::createFromHostFunction(runtime, jsi::PropNameID::forUtf8(runtime, "getNativeBuffer"), 0, getNativeBuffer);
+  }
+  if (name == "toArrayBuffer") {
+    jsi::HostFunctionType toArrayBuffer = JSI_FUNC {
+#if __ANDROID_API__ >= 26
+      AHardwareBuffer* hardwareBuffer = _frame->getHardwareBuffer();
+      AHardwareBuffer_acquire(hardwareBuffer);
+
+      AHardwareBuffer_Desc bufferDescription;
+      AHardwareBuffer_describe(hardwareBuffer, &bufferDescription);
+      __android_log_print(ANDROID_LOG_INFO, "Frame", "Converting %i x %i @ %i HardwareBuffer...", bufferDescription.width,
+                          bufferDescription.height, bufferDescription.stride);
+      size_t size = bufferDescription.height * bufferDescription.stride;
+
+      static constexpr auto ARRAYBUFFER_CACHE_PROP_NAME = "__frameArrayBufferCache";
+      if (!runtime.global().hasProperty(runtime, ARRAYBUFFER_CACHE_PROP_NAME)) {
+        auto mutableBuffer = std::make_shared<vision::MutableRawBuffer>(size);
+        jsi::ArrayBuffer arrayBuffer(runtime, mutableBuffer);
+        runtime.global().setProperty(runtime, ARRAYBUFFER_CACHE_PROP_NAME, arrayBuffer);
+      }
+
+      // Get from global JS cache
+      auto arrayBufferCache = runtime.global().getPropertyAsObject(runtime, ARRAYBUFFER_CACHE_PROP_NAME);
+      auto arrayBuffer = arrayBufferCache.getArrayBuffer(runtime);
+
+      if (arrayBuffer.size(runtime) != size) {
+        auto mutableBuffer = std::make_shared<vision::MutableRawBuffer>(size);
+        arrayBuffer = jsi::ArrayBuffer(runtime, mutableBuffer);
+        runtime.global().setProperty(runtime, ARRAYBUFFER_CACHE_PROP_NAME, arrayBuffer);
+      }
+
+      // Get CPU access to the HardwareBuffer (&buffer is a virtual temporary address)
+      void* buffer;
+      int result = AHardwareBuffer_lock(hardwareBuffer, AHARDWAREBUFFER_USAGE_CPU_READ_MASK, -1, nullptr, &buffer);
+      if (result != 0) {
+        throw jsi::JSError(runtime, "Failed to lock HardwareBuffer for reading!");
+      }
+
+      // directly write to C++ JSI ArrayBuffer
+      auto destinationBuffer = arrayBuffer.data(runtime);
+      memcpy(destinationBuffer, buffer, sizeof(uint8_t) * size);
+
+      // unlock read lock
+      AHardwareBuffer_unlock(hardwareBuffer, nullptr);
+
+      // release JNI reference
+      AHardwareBuffer_release(hardwareBuffer);
+
+      return arrayBuffer;
+#else
+      throw jsi::JSError(runtime, "Frame.toArrayBuffer() is only available if minSdkVersion is set to 26 or higher!");
+#endif
+    };
+    return jsi::Function::createFromHostFunction(runtime, jsi::PropNameID::forUtf8(runtime, "toArrayBuffer"), 0, toArrayBuffer);
+  }
+  if (name == "toString") {
+    jsi::HostFunctionType toString = JSI_FUNC {
+      if (!_frame->getIsValid()) {
+        return jsi::String::createFromUtf8(runtime, "[closed frame]");
+      }
+      auto width = _frame->getWidth();
+      auto height = _frame->getHeight();
+      auto format = _frame->getPixelFormat();
+      auto formatString = format->getUnionValue();
+      auto str = std::to_string(width) + " x " + std::to_string(height) + " " + formatString->toString() + " Frame";
+      return jsi::String::createFromUtf8(runtime, str);
+    };
+    return jsi::Function::createFromHostFunction(runtime, jsi::PropNameID::forUtf8(runtime, "toString"), 0, toString);
+  }
+  if (name == "withBaseClass") {
+    auto withBaseClass = JSI_FUNC {
+      jsi::Object newBaseClass = arguments[0].asObject(runtime);
+      _baseClass = std::make_unique<jsi::Object>(std::move(newBaseClass));
+      return jsi::Object::createFromHostObject(runtime, shared_from_this());
+    };
+    return jsi::Function::createFromHostFunction(runtime, jsi::PropNameID::forUtf8(runtime, "withBaseClass"), 1, withBaseClass);
+  }
+
+  if (_baseClass != nullptr) {
+    // look up value in base class if we have a custom base class
+    jsi::Value value = _baseClass->getProperty(runtime, name.c_str());
+    if (!value.isUndefined()) {
+      return value;
+    }
+  }
+
+  // fallback to base implementation
+  return HostObject::get(runtime, propName);
+}
+
+#undef JSI_FUNC
+
+} // namespace vision
diff --git a/node_modules/react-native-vision-camera/android/bin/src/main/cpp/frameprocessors/FrameHostObject.h b/node_modules/react-native-vision-camera/android/bin/src/main/cpp/frameprocessors/FrameHostObject.h
new file mode 100644
index 0000000..6779e30
--- /dev/null
+++ b/node_modules/react-native-vision-camera/android/bin/src/main/cpp/frameprocessors/FrameHostObject.h
@@ -0,0 +1,39 @@
+//
+// Created by Marc on 19/06/2021.
+//
+
+#pragma once
+
+#include <fbjni/fbjni.h>
+#include <jni.h>
+#include <jsi/jsi.h>
+#include <memory>
+#include <string>
+#include <vector>
+
+#include "JFrame.h"
+
+namespace vision {
+
+using namespace facebook;
+
+class JSI_EXPORT FrameHostObject : public jsi::HostObject, public std::enable_shared_from_this<FrameHostObject> {
+public:
+  explicit FrameHostObject(const jni::alias_ref<JFrame::javaobject>& frame);
+  ~FrameHostObject();
+
+public:
+  jsi::Value get(jsi::Runtime&, const jsi::PropNameID& name) override;
+  std::vector<jsi::PropNameID> getPropertyNames(jsi::Runtime& rt) override;
+
+public:
+  inline jni::global_ref<JFrame> getFrame() const noexcept {
+    return _frame;
+  }
+
+private:
+  jni::global_ref<JFrame> _frame;
+  std::unique_ptr<jsi::Object> _baseClass;
+};
+
+} // namespace vision
diff --git a/node_modules/react-native-vision-camera/android/bin/src/main/cpp/frameprocessors/FrameProcessorPluginHostObject.cpp b/node_modules/react-native-vision-camera/android/bin/src/main/cpp/frameprocessors/FrameProcessorPluginHostObject.cpp
new file mode 100644
index 0000000..4e2d7ba
--- /dev/null
+++ b/node_modules/react-native-vision-camera/android/bin/src/main/cpp/frameprocessors/FrameProcessorPluginHostObject.cpp
@@ -0,0 +1,66 @@
+//
+// Created by Marc Rousavy on 21.07.23.
+//
+
+#include "FrameProcessorPluginHostObject.h"
+#include "FrameHostObject.h"
+#include "JSIJNIConversion.h"
+#include <string>
+#include <vector>
+
+namespace vision {
+
+using namespace facebook;
+
+FrameProcessorPluginHostObject::FrameProcessorPluginHostObject(jni::alias_ref<JFrameProcessorPlugin::javaobject> plugin)
+    : _plugin(make_global(plugin)) {}
+
+FrameProcessorPluginHostObject::~FrameProcessorPluginHostObject() {
+  // Hermes GC might destroy HostObjects on an arbitrary Thread which might not be
+  // connected to the JNI environment. To make sure fbjni can properly destroy
+  // the Java method, we connect to a JNI environment first.
+  jni::ThreadScope::WithClassLoader([&] { _plugin.reset(); });
+}
+
+std::vector<jsi::PropNameID> FrameProcessorPluginHostObject::getPropertyNames(jsi::Runtime& runtime) {
+  return jsi::PropNameID::names(runtime, "call");
+}
+
+jsi::Value FrameProcessorPluginHostObject::get(jsi::Runtime& runtime, const jsi::PropNameID& propName) {
+  auto name = propName.utf8(runtime);
+
+  if (name == "call") {
+    return jsi::Function::createFromHostFunction(
+        runtime, jsi::PropNameID::forUtf8(runtime, "call"), 2,
+        [=](jsi::Runtime& runtime, const jsi::Value& thisValue, const jsi::Value* arguments, size_t count) -> jsi::Value {
+          // Frame is first argument
+          auto frameHolder = arguments[0].asObject(runtime);
+          std::shared_ptr<FrameHostObject> frameHostObject;
+          if (frameHolder.isHostObject<FrameHostObject>(runtime)) {
+            // User directly passed FrameHostObject
+            frameHostObject = frameHolder.getHostObject<FrameHostObject>(runtime);
+          } else {
+            // User passed a wrapper, e.g. DrawableFrame which contains the FrameHostObject as a hidden property
+            jsi::Object actualFrame = frameHolder.getPropertyAsObject(runtime, "__frame");
+            frameHostObject = actualFrame.asHostObject<FrameHostObject>(runtime);
+          }
+          auto frame = frameHostObject->getFrame();
+
+          // Options are second argument (possibly undefined)
+          local_ref<JMap<jstring, jobject>> options = nullptr;
+          if (count > 1) {
+            options = JSIJNIConversion::convertJSIObjectToJNIMap(runtime, arguments[1].asObject(runtime));
+          }
+
+          // Call actual plugin
+          auto result = _plugin->callback(frame, options);
+
+          // Convert result value to jsi::Value (possibly undefined)
+          return JSIJNIConversion::convertJNIObjectToJSIValue(runtime, result);
+        });
+  }
+
+  return jsi::Value::undefined();
+}
+
+} // namespace vision
diff --git a/node_modules/react-native-vision-camera/android/bin/src/main/cpp/frameprocessors/FrameProcessorPluginHostObject.h b/node_modules/react-native-vision-camera/android/bin/src/main/cpp/frameprocessors/FrameProcessorPluginHostObject.h
new file mode 100644
index 0000000..1f2a94f
--- /dev/null
+++ b/node_modules/react-native-vision-camera/android/bin/src/main/cpp/frameprocessors/FrameProcessorPluginHostObject.h
@@ -0,0 +1,30 @@
+//
+// Created by Marc Rousavy on 21.07.23.
+//
+
+#pragma once
+
+#include "JFrameProcessorPlugin.h"
+#include <fbjni/fbjni.h>
+#include <jsi/jsi.h>
+#include <memory>
+#include <vector>
+
+namespace vision {
+
+using namespace facebook;
+
+class FrameProcessorPluginHostObject : public jsi::HostObject {
+public:
+  explicit FrameProcessorPluginHostObject(jni::alias_ref<JFrameProcessorPlugin::javaobject> plugin);
+  ~FrameProcessorPluginHostObject();
+
+public:
+  std::vector<jsi::PropNameID> getPropertyNames(jsi::Runtime& runtime) override;
+  jsi::Value get(jsi::Runtime& runtime, const jsi::PropNameID& name) override;
+
+private:
+  jni::global_ref<JFrameProcessorPlugin::javaobject> _plugin;
+};
+
+} // namespace vision
diff --git a/node_modules/react-native-vision-camera/android/bin/src/main/cpp/frameprocessors/JSIJNIConversion.cpp b/node_modules/react-native-vision-camera/android/bin/src/main/cpp/frameprocessors/JSIJNIConversion.cpp
new file mode 100644
index 0000000..90ef17e
--- /dev/null
+++ b/node_modules/react-native-vision-camera/android/bin/src/main/cpp/frameprocessors/JSIJNIConversion.cpp
@@ -0,0 +1,188 @@
+//
+// Created by Marc Rousavy on 22.06.21.
+//
+
+#include "JSIJNIConversion.h"
+
+#include <android/log.h>
+#include <fbjni/fbjni.h>
+#include <jni.h>
+#include <jsi/jsi.h>
+
+#include <memory>
+#include <string>
+#include <utility>
+
+#include "FrameHostObject.h"
+#include "JFrame.h"
+#include "JSharedArray.h"
+
+namespace vision {
+
+using namespace facebook;
+
+jni::local_ref<jobject> JSIJNIConversion::convertJSIValueToJNIObject(jsi::Runtime& runtime, const jsi::Value& value) {
+  if (value.isNull() || value.isUndefined()) {
+    // null
+
+    return nullptr;
+  } else if (value.isBool()) {
+    // Boolean
+
+    bool boolean = value.getBool();
+    return JBoolean::valueOf(boolean);
+  } else if (value.isNumber()) {
+    // Double
+
+    double number = value.getNumber();
+    return jni::JDouble::valueOf(number);
+  } else if (value.isString()) {
+    // String
+
+    std::string string = value.getString(runtime).utf8(runtime);
+    return jni::make_jstring(string);
+  } else if (value.isObject()) {
+    // Object
+
+    auto valueAsObject = value.getObject(runtime);
+    if (valueAsObject.isArray(runtime)) {
+      // List<Object>
+
+      jsi::Array array = valueAsObject.getArray(runtime);
+      size_t size = array.size(runtime);
+      jni::local_ref<JArrayList<jobject>> arrayList = jni::JArrayList<jobject>::create(static_cast<int>(size));
+      for (size_t i = 0; i < size; i++) {
+        jsi::Value item = array.getValueAtIndex(runtime, i);
+        jni::local_ref<jobject> jniItem = convertJSIValueToJNIObject(runtime, item);
+        arrayList->add(jniItem);
+      }
+      return arrayList;
+    } else if (valueAsObject.isArrayBuffer(runtime)) {
+      // ArrayBuffer/TypedArray
+
+      jsi::ArrayBuffer arrayBuffer = valueAsObject.getArrayBuffer(runtime);
+      return JSharedArray::create(runtime, std::move(arrayBuffer));
+
+    } else if (valueAsObject.isHostObject(runtime)) {
+
+      if (valueAsObject.isHostObject<FrameHostObject>(runtime)) {
+        // Frame
+
+        auto frameHostObject = valueAsObject.getHostObject<FrameHostObject>(runtime);
+        return jni::make_local(frameHostObject->getFrame());
+
+      } else {
+        throw std::runtime_error("The given HostObject is not supported by a Frame Processor Plugin.");
+      }
+
+    } else {
+      // Map<String, Object>
+
+      jsi::Array propertyNames = valueAsObject.getPropertyNames(runtime);
+      size_t size = propertyNames.size(runtime);
+      jni::local_ref<JHashMap<jstring, jobject>> hashMap = jni::JHashMap<jstring, jobject>::create();
+      for (size_t i = 0; i < size; i++) {
+        jsi::String propName = propertyNames.getValueAtIndex(runtime, i).asString(runtime);
+        jsi::Value item = valueAsObject.getProperty(runtime, propName);
+        jni::local_ref<jstring> key = jni::make_jstring(propName.utf8(runtime));
+        jni::local_ref<jobject> jniItem = convertJSIValueToJNIObject(runtime, item);
+        hashMap->put(key, jniItem);
+      }
+      return hashMap;
+    }
+  } else {
+    auto stringRepresentation = value.toString(runtime).utf8(runtime);
+    throw std::runtime_error("Failed to convert jsi::Value to JNI value - unsupported type! " + stringRepresentation);
+  }
+}
+
+jni::local_ref<jni::JMap<jstring, jobject>> JSIJNIConversion::convertJSIObjectToJNIMap(jsi::Runtime& runtime, const jsi::Object& object) {
+  auto propertyNames = object.getPropertyNames(runtime);
+  auto size = propertyNames.size(runtime);
+  auto hashMap = jni::JHashMap<jstring, jobject>::create();
+
+  for (size_t i = 0; i < size; i++) {
+    jsi::String propName = propertyNames.getValueAtIndex(runtime, i).asString(runtime);
+    jsi::Value value = object.getProperty(runtime, propName);
+    jni::local_ref<jstring> key = jni::make_jstring(propName.utf8(runtime));
+    jni::local_ref<jobject> jniValue = convertJSIValueToJNIObject(runtime, value);
+    hashMap->put(key, jniValue);
+  }
+
+  return hashMap;
+}
+
+jsi::Value JSIJNIConversion::convertJNIObjectToJSIValue(jsi::Runtime& runtime, const jni::local_ref<jobject>& object) {
+  if (object == nullptr) {
+    // null
+
+    return jsi::Value::undefined();
+  } else if (object->isInstanceOf(jni::JBoolean::javaClassStatic())) {
+    // Boolean
+
+    auto boxed = static_ref_cast<JBoolean>(object);
+    bool value = boxed->value();
+    return jsi::Value(value);
+  } else if (object->isInstanceOf(jni::JDouble::javaClassStatic())) {
+    // Double
+
+    auto boxed = static_ref_cast<JDouble>(object);
+    double value = boxed->value();
+    return jsi::Value(value);
+  } else if (object->isInstanceOf(jni::JInteger::javaClassStatic())) {
+    // Integer
+
+    auto boxed = static_ref_cast<JInteger>(object);
+    return jsi::Value(boxed->value());
+  } else if (object->isInstanceOf(jni::JString::javaClassStatic())) {
+    // String
+
+    return jsi::String::createFromUtf8(runtime, object->toString());
+  } else if (object->isInstanceOf(JList<jobject>::javaClassStatic())) {
+    // List<E>
+
+    auto arrayList = static_ref_cast<JList<jobject>>(object);
+    auto size = arrayList->size();
+
+    auto result = jsi::Array(runtime, size);
+    size_t i = 0;
+    for (const auto& item : *arrayList) {
+      result.setValueAtIndex(runtime, i, convertJNIObjectToJSIValue(runtime, item));
+      i++;
+    }
+    return result;
+  } else if (object->isInstanceOf(JMap<jstring, jobject>::javaClassStatic())) {
+    // Map<K, V>
+
+    auto map = static_ref_cast<JMap<jstring, jobject>>(object);
+
+    auto result = jsi::Object(runtime);
+    for (const auto& entry : *map) {
+      auto key = entry.first->toString();
+      auto value = entry.second;
+      auto jsiValue = convertJNIObjectToJSIValue(runtime, value);
+      result.setProperty(runtime, key.c_str(), jsiValue);
+    }
+    return result;
+  } else if (object->isInstanceOf(JFrame::javaClassStatic())) {
+    // Frame
+    auto frame = static_ref_cast<JFrame>(object);
+
+    // box into HostObject
+    auto hostObject = std::make_shared<FrameHostObject>(frame);
+    return jsi::Object::createFromHostObject(runtime, hostObject);
+  } else if (object->isInstanceOf(JSharedArray::javaClassStatic())) {
+    // SharedArray
+    auto sharedArray = static_ref_cast<JSharedArray::javaobject>(object);
+
+    std::shared_ptr<jsi::ArrayBuffer> array = sharedArray->cthis()->getArrayBuffer();
+    return array->getArrayBuffer(runtime);
+  }
+
+  auto type = object->getClass()->toString();
+  auto message = "Cannot convert Java type \"" + type + "\" to jsi::Value!";
+  __android_log_write(ANDROID_LOG_ERROR, "VisionCamera", message.c_str());
+  throw std::runtime_error(message);
+}
+
+} // namespace vision
diff --git a/node_modules/react-native-vision-camera/android/bin/src/main/cpp/frameprocessors/JSIJNIConversion.h b/node_modules/react-native-vision-camera/android/bin/src/main/cpp/frameprocessors/JSIJNIConversion.h
new file mode 100644
index 0000000..50b9ea0
--- /dev/null
+++ b/node_modules/react-native-vision-camera/android/bin/src/main/cpp/frameprocessors/JSIJNIConversion.h
@@ -0,0 +1,24 @@
+//
+// Created by Marc Rousavy on 22.06.21.
+//
+
+#pragma once
+
+#include <fbjni/fbjni.h>
+#include <jni.h>
+#include <jsi/jsi.h>
+
+namespace vision {
+
+namespace JSIJNIConversion {
+
+  using namespace facebook;
+
+  jni::local_ref<jobject> convertJSIValueToJNIObject(jsi::Runtime& runtime, const jsi::Value& value);
+  jni::local_ref<jni::JMap<jstring, jobject>> convertJSIObjectToJNIMap(jsi::Runtime& runtime, const jsi::Object& object);
+
+  jsi::Value convertJNIObjectToJSIValue(jsi::Runtime& runtime, const jni::local_ref<jobject>& object);
+
+} // namespace JSIJNIConversion
+
+} // namespace vision
diff --git a/node_modules/react-native-vision-camera/android/bin/src/main/cpp/frameprocessors/VisionCameraProxy.cpp b/node_modules/react-native-vision-camera/android/bin/src/main/cpp/frameprocessors/VisionCameraProxy.cpp
new file mode 100644
index 0000000..708ae86
--- /dev/null
+++ b/node_modules/react-native-vision-camera/android/bin/src/main/cpp/frameprocessors/VisionCameraProxy.cpp
@@ -0,0 +1,118 @@
+//
+// Created by Marc Rousavy on 21.07.23.
+//
+
+#include "VisionCameraProxy.h"
+#include <jsi/jsi.h>
+
+#include "JFrameProcessor.h"
+#include "JFrameProcessorPlugin.h"
+#include "JSIJNIConversion.h"
+
+#include <android/log.h>
+#include <fbjni/fbjni.h>
+
+#include "FrameProcessorPluginHostObject.h"
+
+#include <memory>
+#include <string>
+#include <vector>
+
+#if VISION_CAMERA_ENABLE_FRAME_PROCESSORS
+#include <react-native-worklets-core/WKTJsiWorkletContext.h>
+#endif
+
+namespace vision {
+
+using namespace facebook;
+
+VisionCameraProxy::VisionCameraProxy(const jni::alias_ref<JVisionCameraProxy::javaobject>& javaProxy) {
+  _javaProxy = make_global(javaProxy);
+}
+
+VisionCameraProxy::~VisionCameraProxy() {
+  // Hermes GC might destroy HostObjects on an arbitrary Thread which might not be
+  // connected to the JNI environment. To make sure fbjni can properly destroy
+  // the Java method, we connect to a JNI environment first.
+  jni::ThreadScope::WithClassLoader([&] { _javaProxy.reset(); });
+}
+
+std::vector<jsi::PropNameID> VisionCameraProxy::getPropertyNames(jsi::Runtime& runtime) {
+  return jsi::PropNameID::names(runtime, "setFrameProcessor", "removeFrameProcessor", "initFrameProcessorPlugin", "workletContext");
+}
+
+void VisionCameraProxy::setFrameProcessor(int viewTag, jsi::Runtime& runtime, const std::shared_ptr<jsi::Function>& function) {
+  _javaProxy->cthis()->setFrameProcessor(viewTag, runtime, function);
+}
+
+void VisionCameraProxy::removeFrameProcessor(int viewTag) {
+  _javaProxy->cthis()->removeFrameProcessor(viewTag);
+}
+
+jsi::Value VisionCameraProxy::initFrameProcessorPlugin(jsi::Runtime& runtime, const std::string& name, const jsi::Object& jsOptions) {
+  auto options = JSIJNIConversion::convertJSIObjectToJNIMap(runtime, jsOptions);
+
+  auto plugin = _javaProxy->cthis()->initFrameProcessorPlugin(name, options);
+  if (plugin == nullptr) {
+    return jsi::Value::undefined();
+  }
+
+  auto pluginHostObject = std::make_shared<FrameProcessorPluginHostObject>(plugin);
+  return jsi::Object::createFromHostObject(runtime, pluginHostObject);
+}
+
+jsi::Value VisionCameraProxy::get(jsi::Runtime& runtime, const jsi::PropNameID& propName) {
+  auto name = propName.utf8(runtime);
+
+  if (name == "setFrameProcessor") {
+    return jsi::Function::createFromHostFunction(
+        runtime, jsi::PropNameID::forUtf8(runtime, "setFrameProcessor"), 1,
+        [this](jsi::Runtime& runtime, const jsi::Value& thisValue, const jsi::Value* arguments, size_t count) -> jsi::Value {
+          auto viewTag = arguments[0].asNumber();
+          auto frameProcessor = arguments[1].asObject(runtime).asFunction(runtime);
+          auto sharedFunction = std::make_shared<jsi::Function>(std::move(frameProcessor));
+          this->setFrameProcessor(static_cast<int>(viewTag), runtime, sharedFunction);
+          return jsi::Value::undefined();
+        });
+  } else if (name == "removeFrameProcessor") {
+    return jsi::Function::createFromHostFunction(
+        runtime, jsi::PropNameID::forUtf8(runtime, "removeFrameProcessor"), 1,
+        [this](jsi::Runtime& runtime, const jsi::Value& thisValue, const jsi::Value* arguments, size_t count) -> jsi::Value {
+          auto viewTag = arguments[0].asNumber();
+          this->removeFrameProcessor(static_cast<int>(viewTag));
+          return jsi::Value::undefined();
+        });
+  } else if (name == "initFrameProcessorPlugin") {
+    return jsi::Function::createFromHostFunction(
+        runtime, jsi::PropNameID::forUtf8(runtime, "initFrameProcessorPlugin"), 1,
+        [this](jsi::Runtime& runtime, const jsi::Value& thisValue, const jsi::Value* arguments, size_t count) -> jsi::Value {
+          if (count < 1 || !arguments[0].isString()) {
+            throw jsi::JSError(runtime, "First argument needs to be a string (pluginName)!");
+          }
+          auto pluginName = arguments[0].asString(runtime).utf8(runtime);
+          auto options = count > 1 ? arguments[1].asObject(runtime) : jsi::Object(runtime);
+
+          return this->initFrameProcessorPlugin(runtime, pluginName, options);
+        });
+  } else if (name == "workletContext") {
+#if VISION_CAMERA_ENABLE_FRAME_PROCESSORS
+    std::shared_ptr<RNWorklet::JsiWorkletContext> context = _javaProxy->cthis()->getWorkletContext();
+    return jsi::Object::createFromHostObject(runtime, context);
+#endif
+  }
+
+  return jsi::Value::undefined();
+}
+
+void VisionCameraInstaller::registerNatives() {
+  javaClassStatic()->registerNatives({makeNativeMethod("install", VisionCameraInstaller::install)});
+}
+
+void VisionCameraInstaller::install(jni::alias_ref<jni::JClass>, jni::alias_ref<JVisionCameraProxy::javaobject> proxy) {
+  // global.VisionCameraProxy
+  auto visionCameraProxy = std::make_shared<VisionCameraProxy>(proxy);
+  jsi::Runtime& runtime = *proxy->cthis()->getJSRuntime();
+  runtime.global().setProperty(runtime, "VisionCameraProxy", jsi::Object::createFromHostObject(runtime, visionCameraProxy));
+}
+
+} // namespace vision
diff --git a/node_modules/react-native-vision-camera/android/bin/src/main/cpp/frameprocessors/VisionCameraProxy.h b/node_modules/react-native-vision-camera/android/bin/src/main/cpp/frameprocessors/VisionCameraProxy.h
new file mode 100644
index 0000000..6dc8fde
--- /dev/null
+++ b/node_modules/react-native-vision-camera/android/bin/src/main/cpp/frameprocessors/VisionCameraProxy.h
@@ -0,0 +1,45 @@
+//
+// Created by Marc Rousavy on 21.07.23.
+//
+
+#pragma once
+
+#include <jsi/jsi.h>
+
+#include "JVisionCameraProxy.h"
+#include "JVisionCameraScheduler.h"
+
+#include <string>
+#include <vector>
+
+namespace vision {
+
+using namespace facebook;
+
+class VisionCameraProxy : public jsi::HostObject {
+public:
+  explicit VisionCameraProxy(const jni::alias_ref<JVisionCameraProxy::javaobject>& javaProxy);
+  ~VisionCameraProxy();
+
+public:
+  std::vector<jsi::PropNameID> getPropertyNames(jsi::Runtime& runtime) override;
+  jsi::Value get(jsi::Runtime& runtime, const jsi::PropNameID& name) override;
+
+private:
+  void setFrameProcessor(int viewTag, jsi::Runtime& runtime, const std::shared_ptr<jsi::Function>& frameProcessor);
+  void removeFrameProcessor(int viewTag);
+  jsi::Value initFrameProcessorPlugin(jsi::Runtime& runtime, const std::string& name, const jsi::Object& options);
+
+private:
+  jni::global_ref<JVisionCameraProxy::javaobject> _javaProxy;
+  static constexpr const char* TAG = "VisionCameraProxy";
+};
+
+class VisionCameraInstaller : public jni::JavaClass<VisionCameraInstaller> {
+public:
+  static auto constexpr kJavaDescriptor = "Lcom/mrousavy/camera/frameprocessors/VisionCameraInstaller;";
+  static void registerNatives();
+  static void install(jni::alias_ref<jni::JClass> clazz, jni::alias_ref<JVisionCameraProxy::javaobject> proxy);
+};
+
+} // namespace vision
diff --git a/node_modules/react-native-vision-camera/android/bin/src/main/cpp/frameprocessors/java-bindings/JFrame.cpp b/node_modules/react-native-vision-camera/android/bin/src/main/cpp/frameprocessors/java-bindings/JFrame.cpp
new file mode 100644
index 0000000..ceebeb1
--- /dev/null
+++ b/node_modules/react-native-vision-camera/android/bin/src/main/cpp/frameprocessors/java-bindings/JFrame.cpp
@@ -0,0 +1,82 @@
+//
+// Created by Marc on 21.07.2023.
+//
+
+#include "JFrame.h"
+
+#include "JOrientation.h"
+#include "JPixelFormat.h"
+#include <fbjni/fbjni.h>
+#include <jni.h>
+
+#include <android/hardware_buffer_jni.h>
+
+namespace vision {
+
+using namespace facebook;
+using namespace jni;
+
+int JFrame::getWidth() const {
+  static const auto getWidthMethod = getClass()->getMethod<jint()>("getWidth");
+  return getWidthMethod(self());
+}
+
+int JFrame::getHeight() const {
+  static const auto getWidthMethod = getClass()->getMethod<jint()>("getHeight");
+  return getWidthMethod(self());
+}
+
+bool JFrame::getIsValid() const {
+  static const auto getIsValidMethod = getClass()->getMethod<jboolean()>("getIsValid");
+  return getIsValidMethod(self());
+}
+
+bool JFrame::getIsMirrored() const {
+  static const auto getIsMirroredMethod = getClass()->getMethod<jboolean()>("getIsMirrored");
+  return getIsMirroredMethod(self());
+}
+
+jlong JFrame::getTimestamp() const {
+  static const auto getTimestampMethod = getClass()->getMethod<jlong()>("getTimestamp");
+  return getTimestampMethod(self());
+}
+
+local_ref<JOrientation> JFrame::getOrientation() const {
+  static const auto getOrientationMethod = getClass()->getMethod<JOrientation()>("getOrientation");
+  return getOrientationMethod(self());
+}
+
+local_ref<JPixelFormat> JFrame::getPixelFormat() const {
+  static const auto getPixelFormatMethod = getClass()->getMethod<JPixelFormat()>("getPixelFormat");
+  return getPixelFormatMethod(self());
+}
+
+int JFrame::getPlanesCount() const {
+  static const auto getPlanesCountMethod = getClass()->getMethod<jint()>("getPlanesCount");
+  return getPlanesCountMethod(self());
+}
+
+int JFrame::getBytesPerRow() const {
+  static const auto getBytesPerRowMethod = getClass()->getMethod<jint()>("getBytesPerRow");
+  return getBytesPerRowMethod(self());
+}
+
+#if __ANDROID_API__ >= 26
+AHardwareBuffer* JFrame::getHardwareBuffer() const {
+  static const auto getHardwareBufferMethod = getClass()->getMethod<jobject()>("getHardwareBufferBoxed");
+  auto hardwareBuffer = getHardwareBufferMethod(self());
+  return AHardwareBuffer_fromHardwareBuffer(jni::Environment::current(), hardwareBuffer.get());
+}
+#endif
+
+void JFrame::incrementRefCount() {
+  static const auto incrementRefCountMethod = getClass()->getMethod<void()>("incrementRefCount");
+  incrementRefCountMethod(self());
+}
+
+void JFrame::decrementRefCount() {
+  static const auto decrementRefCountMethod = getClass()->getMethod<void()>("decrementRefCount");
+  decrementRefCountMethod(self());
+}
+
+} // namespace vision
diff --git a/node_modules/react-native-vision-camera/android/bin/src/main/cpp/frameprocessors/java-bindings/JFrame.h b/node_modules/react-native-vision-camera/android/bin/src/main/cpp/frameprocessors/java-bindings/JFrame.h
new file mode 100644
index 0000000..802b575
--- /dev/null
+++ b/node_modules/react-native-vision-camera/android/bin/src/main/cpp/frameprocessors/java-bindings/JFrame.h
@@ -0,0 +1,40 @@
+//
+// Created by Marc on 21.07.2023.
+//
+
+#pragma once
+
+#include "JOrientation.h"
+#include "JPixelFormat.h"
+#include <fbjni/fbjni.h>
+#include <jni.h>
+
+#include <android/hardware_buffer.h>
+
+namespace vision {
+
+using namespace facebook;
+using namespace jni;
+
+struct JFrame : public JavaClass<JFrame> {
+  static constexpr auto kJavaDescriptor = "Lcom/mrousavy/camera/frameprocessors/Frame;";
+
+public:
+  int getWidth() const;
+  int getHeight() const;
+  bool getIsValid() const;
+  bool getIsMirrored() const;
+  int getPlanesCount() const;
+  int getBytesPerRow() const;
+  jlong getTimestamp() const;
+  local_ref<JOrientation> getOrientation() const;
+  local_ref<JPixelFormat> getPixelFormat() const;
+#if __ANDROID_API__ >= 26
+  AHardwareBuffer* getHardwareBuffer() const;
+#endif
+
+  void incrementRefCount();
+  void decrementRefCount();
+};
+
+} // namespace vision
diff --git a/node_modules/react-native-vision-camera/android/bin/src/main/cpp/frameprocessors/java-bindings/JFrameProcessor.cpp b/node_modules/react-native-vision-camera/android/bin/src/main/cpp/frameprocessors/java-bindings/JFrameProcessor.cpp
new file mode 100644
index 0000000..b755c6d
--- /dev/null
+++ b/node_modules/react-native-vision-camera/android/bin/src/main/cpp/frameprocessors/java-bindings/JFrameProcessor.cpp
@@ -0,0 +1,55 @@
+//
+// Created by Marc Rousavy on 29.09.21.
+//
+
+#if VISION_CAMERA_ENABLE_FRAME_PROCESSORS
+
+#include "JFrameProcessor.h"
+#include <fbjni/fbjni.h>
+#include <jni.h>
+
+#include "JFrame.h"
+#include <utility>
+
+namespace vision {
+
+using namespace facebook;
+using namespace jni;
+
+void JFrameProcessor::registerNatives() {
+  registerHybrid({makeNativeMethod("call", JFrameProcessor::call)});
+}
+
+using TSelf = jni::local_ref<JFrameProcessor::javaobject>;
+
+JFrameProcessor::JFrameProcessor(std::shared_ptr<RNWorklet::JsiWorklet> worklet, std::shared_ptr<RNWorklet::JsiWorkletContext> context) {
+  _workletContext = std::move(context);
+  _workletInvoker = std::make_shared<RNWorklet::WorkletInvoker>(worklet);
+}
+
+TSelf JFrameProcessor::create(const std::shared_ptr<RNWorklet::JsiWorklet>& worklet,
+                              const std::shared_ptr<RNWorklet::JsiWorkletContext>& context) {
+  return JFrameProcessor::newObjectCxxArgs(worklet, context);
+}
+
+void JFrameProcessor::callWithFrameHostObject(const std::shared_ptr<FrameHostObject>& frameHostObject) const {
+  // Call the Frame Processor on the Worklet Runtime
+  jsi::Runtime& runtime = _workletContext->getWorkletRuntime();
+
+  // Wrap HostObject as JSI Value
+  auto argument = jsi::Object::createFromHostObject(runtime, frameHostObject);
+  jsi::Value jsValue(std::move(argument));
+
+  // Call the Worklet with the Frame JS Host Object as an argument
+  _workletInvoker->call(runtime, jsi::Value::undefined(), &jsValue, 1);
+}
+
+void JFrameProcessor::call(jni::alias_ref<JFrame::javaobject> frame) {
+  // Create the Frame Host Object wrapping the internal Frame
+  auto frameHostObject = std::make_shared<FrameHostObject>(frame);
+  callWithFrameHostObject(frameHostObject);
+}
+
+} // namespace vision
+
+#endif
diff --git a/node_modules/react-native-vision-camera/android/bin/src/main/cpp/frameprocessors/java-bindings/JFrameProcessor.h b/node_modules/react-native-vision-camera/android/bin/src/main/cpp/frameprocessors/java-bindings/JFrameProcessor.h
new file mode 100644
index 0000000..c164290
--- /dev/null
+++ b/node_modules/react-native-vision-camera/android/bin/src/main/cpp/frameprocessors/java-bindings/JFrameProcessor.h
@@ -0,0 +1,52 @@
+//
+// Created by Marc Rousavy on 29.09.21
+//
+
+#pragma once
+
+#if VISION_CAMERA_ENABLE_FRAME_PROCESSORS
+
+#include <fbjni/fbjni.h>
+#include <jni.h>
+#include <memory>
+#include <string>
+
+#include <react-native-worklets-core/WKTJsiHostObject.h>
+#include <react-native-worklets-core/WKTJsiWorklet.h>
+
+#include "FrameHostObject.h"
+#include "JFrame.h"
+
+namespace vision {
+
+using namespace facebook;
+
+struct JFrameProcessor : public jni::HybridClass<JFrameProcessor> {
+public:
+  static auto constexpr kJavaDescriptor = "Lcom/mrousavy/camera/frameprocessors/FrameProcessor;";
+  static void registerNatives();
+  static jni::local_ref<JFrameProcessor::javaobject> create(const std::shared_ptr<RNWorklet::JsiWorklet>& worklet,
+                                                            const std::shared_ptr<RNWorklet::JsiWorkletContext>& context);
+
+public:
+  /**
+   * Call the JS Frame Processor.
+   */
+  void call(alias_ref<JFrame::javaobject> frame);
+
+private:
+  // Private constructor. Use `create(..)` to create new instances.
+  explicit JFrameProcessor(std::shared_ptr<RNWorklet::JsiWorklet> worklet, std::shared_ptr<RNWorklet::JsiWorkletContext> context);
+
+private:
+  void callWithFrameHostObject(const std::shared_ptr<FrameHostObject>& frameHostObject) const;
+
+private:
+  friend HybridBase;
+  std::shared_ptr<RNWorklet::WorkletInvoker> _workletInvoker;
+  std::shared_ptr<RNWorklet::JsiWorkletContext> _workletContext;
+};
+
+} // namespace vision
+
+#endif
diff --git a/node_modules/react-native-vision-camera/android/bin/src/main/cpp/frameprocessors/java-bindings/JFrameProcessorPlugin.cpp b/node_modules/react-native-vision-camera/android/bin/src/main/cpp/frameprocessors/java-bindings/JFrameProcessorPlugin.cpp
new file mode 100644
index 0000000..5627446
--- /dev/null
+++ b/node_modules/react-native-vision-camera/android/bin/src/main/cpp/frameprocessors/java-bindings/JFrameProcessorPlugin.cpp
@@ -0,0 +1,25 @@
+//
+// Created by Marc Rousavy on 29.09.21.
+//
+
+#include "JFrameProcessorPlugin.h"
+
+#include <fbjni/fbjni.h>
+#include <jni.h>
+
+namespace vision {
+
+using namespace facebook;
+using namespace jni;
+
+using TCallback = jobject(alias_ref<JFrame::javaobject>, alias_ref<JMap<jstring, jobject>> params);
+
+local_ref<jobject> JFrameProcessorPlugin::callback(const alias_ref<JFrame::javaobject>& frame,
+                                                   const alias_ref<JMap<jstring, jobject>>& params) const {
+  auto callbackMethod = getClass()->getMethod<TCallback>("callback");
+
+  auto result = callbackMethod(self(), frame, params);
+  return make_local(result);
+}
+
+} // namespace vision
diff --git a/node_modules/react-native-vision-camera/android/bin/src/main/cpp/frameprocessors/java-bindings/JFrameProcessorPlugin.h b/node_modules/react-native-vision-camera/android/bin/src/main/cpp/frameprocessors/java-bindings/JFrameProcessorPlugin.h
new file mode 100644
index 0000000..4d07c29
--- /dev/null
+++ b/node_modules/react-native-vision-camera/android/bin/src/main/cpp/frameprocessors/java-bindings/JFrameProcessorPlugin.h
@@ -0,0 +1,28 @@
+//
+// Created by Marc Rousavy on 29.09.21
+//
+
+#pragma once
+
+#include <fbjni/fbjni.h>
+#include <jni.h>
+#include <string>
+
+#include "JFrame.h"
+
+namespace vision {
+
+using namespace facebook;
+using namespace jni;
+
+struct JFrameProcessorPlugin : public JavaClass<JFrameProcessorPlugin> {
+  static constexpr auto kJavaDescriptor = "Lcom/mrousavy/camera/frameprocessors/FrameProcessorPlugin;";
+
+public:
+  /**
+   * Call the plugin.
+   */
+  local_ref<jobject> callback(const alias_ref<JFrame::javaobject>& frame, const alias_ref<JMap<jstring, jobject>>& params) const;
+};
+
+} // namespace vision
diff --git a/node_modules/react-native-vision-camera/android/bin/src/main/cpp/frameprocessors/java-bindings/JJSUnionValue.h b/node_modules/react-native-vision-camera/android/bin/src/main/cpp/frameprocessors/java-bindings/JJSUnionValue.h
new file mode 100644
index 0000000..4e82ab8
--- /dev/null
+++ b/node_modules/react-native-vision-camera/android/bin/src/main/cpp/frameprocessors/java-bindings/JJSUnionValue.h
@@ -0,0 +1,24 @@
+//
+// Created by Marc Rousavy on 29.12.23.
+//
+
+#pragma once
+
+#include <fbjni/fbjni.h>
+#include <jni.h>
+
+namespace vision {
+
+using namespace facebook;
+using namespace jni;
+
+struct JJSUnionValue : public JavaClass<JJSUnionValue> {
+  static constexpr auto kJavaDescriptor = "Lcom/mrousavy/camera/core/types/JSUnionValue;";
+
+  local_ref<JString> getUnionValue() {
+    const auto getUnionValueMethod = getClass()->getMethod<JString()>("getUnionValue");
+    return getUnionValueMethod(self());
+  }
+};
+
+} // namespace vision
diff --git a/node_modules/react-native-vision-camera/android/bin/src/main/cpp/frameprocessors/java-bindings/JOrientation.h b/node_modules/react-native-vision-camera/android/bin/src/main/cpp/frameprocessors/java-bindings/JOrientation.h
new file mode 100644
index 0000000..971351b
--- /dev/null
+++ b/node_modules/react-native-vision-camera/android/bin/src/main/cpp/frameprocessors/java-bindings/JOrientation.h
@@ -0,0 +1,20 @@
+//
+// Created by Marc Rousavy on 29.12.23.
+//
+
+#pragma once
+
+#include "JJSUnionValue.h"
+#include <fbjni/fbjni.h>
+#include <jni.h>
+
+namespace vision {
+
+using namespace facebook;
+using namespace jni;
+
+struct JOrientation : public JavaClass<JOrientation, JJSUnionValue> {
+  static constexpr auto kJavaDescriptor = "Lcom/mrousavy/camera/core/types/Orientation;";
+};
+
+} // namespace vision
diff --git a/node_modules/react-native-vision-camera/android/bin/src/main/cpp/frameprocessors/java-bindings/JPixelFormat.h b/node_modules/react-native-vision-camera/android/bin/src/main/cpp/frameprocessors/java-bindings/JPixelFormat.h
new file mode 100644
index 0000000..af2a61b
--- /dev/null
+++ b/node_modules/react-native-vision-camera/android/bin/src/main/cpp/frameprocessors/java-bindings/JPixelFormat.h
@@ -0,0 +1,20 @@
+//
+// Created by Marc Rousavy on 29.12.23.
+//
+
+#pragma once
+
+#include "JJSUnionValue.h"
+#include <fbjni/fbjni.h>
+#include <jni.h>
+
+namespace vision {
+
+using namespace facebook;
+using namespace jni;
+
+struct JPixelFormat : public JavaClass<JPixelFormat, JJSUnionValue> {
+  static constexpr auto kJavaDescriptor = "Lcom/mrousavy/camera/core/types/PixelFormat;";
+};
+
+} // namespace vision
diff --git a/node_modules/react-native-vision-camera/android/bin/src/main/cpp/frameprocessors/java-bindings/JSharedArray.cpp b/node_modules/react-native-vision-camera/android/bin/src/main/cpp/frameprocessors/java-bindings/JSharedArray.cpp
new file mode 100644
index 0000000..46f94f8
--- /dev/null
+++ b/node_modules/react-native-vision-camera/android/bin/src/main/cpp/frameprocessors/java-bindings/JSharedArray.cpp
@@ -0,0 +1,83 @@
+//
+// Created by Marc Rousavy on 12.01.24.
+//
+
+#include "JSharedArray.h"
+#include <android/log.h>
+
+namespace vision {
+
+using namespace facebook;
+
+jni::local_ref<JSharedArray::javaobject> JSharedArray::create(jsi::Runtime& runtime, jsi::ArrayBuffer arrayBuffer) {
+  jni::local_ref<JSharedArray::javaobject> instance = newObjectCxxArgs(runtime, std::make_shared<jsi::ArrayBuffer>(std::move(arrayBuffer)));
+  instance->cthis()->_javaPart = jni::make_global(instance);
+  return instance;
+}
+
+JSharedArray::JSharedArray(jsi::Runtime& runtime, std::shared_ptr<jsi::ArrayBuffer> arrayBuffer) {
+  size_t size = arrayBuffer->size(runtime);
+  __android_log_print(ANDROID_LOG_INFO, TAG, "Wrapping JSI ArrayBuffer with size %zu...", size);
+  jni::local_ref<JByteBuffer> byteBuffer = JByteBuffer::wrapBytes(arrayBuffer->data(runtime), size);
+
+  _arrayBuffer = arrayBuffer;
+  _byteBuffer = jni::make_global(byteBuffer);
+  _size = size;
+}
+
+JSharedArray::JSharedArray(const jni::alias_ref<jhybridobject>& javaThis, const jni::alias_ref<JVisionCameraProxy::javaobject>& proxy,
+                           jni::alias_ref<JByteBuffer> byteBuffer) {
+  _javaPart = jni::make_global(javaThis);
+
+#if VISION_CAMERA_ENABLE_FRAME_PROCESSORS
+  jsi::Runtime& runtime = proxy->cthis()->getWorkletRuntime();
+#else
+  jsi::Runtime& runtime = *proxy->cthis()->getJSRuntime();
+#endif
+  __android_log_print(ANDROID_LOG_INFO, TAG, "Wrapping Java ByteBuffer with size %zu...", byteBuffer->getDirectSize());
+  _byteBuffer = jni::make_global(byteBuffer);
+  _size = _byteBuffer->getDirectSize();
+
+  auto mutableByteBuffer = std::make_shared<MutableJByteBuffer>(byteBuffer);
+  _arrayBuffer = std::make_shared<jsi::ArrayBuffer>(runtime, std::move(mutableByteBuffer));
+}
+
+JSharedArray::JSharedArray(const jni::alias_ref<JSharedArray::jhybridobject>& javaThis,
+                           const jni::alias_ref<JVisionCameraProxy::javaobject>& proxy, int size)
+    : JSharedArray(javaThis, proxy, JByteBuffer::allocateDirect(size)) {
+  __android_log_print(ANDROID_LOG_INFO, TAG, "Allocating SharedArray with size %i...", size);
+}
+
+void JSharedArray::registerNatives() {
+  registerHybrid({
+      makeNativeMethod("initHybrid", JSharedArray::initHybridAllocate),
+      makeNativeMethod("initHybrid", JSharedArray::initHybridWrap),
+      makeNativeMethod("getByteBuffer", JSharedArray::getByteBuffer),
+      makeNativeMethod("getSize", JSharedArray::getSize),
+  });
+}
+
+jni::global_ref<jni::JByteBuffer> JSharedArray::getByteBuffer() {
+  return _byteBuffer;
+}
+
+std::shared_ptr<jsi::ArrayBuffer> JSharedArray::getArrayBuffer() {
+  return _arrayBuffer;
+}
+
+jint JSharedArray::getSize() {
+  return _size;
+}
+
+jni::local_ref<JSharedArray::jhybriddata>
+JSharedArray::initHybridAllocate(jni::alias_ref<jhybridobject> javaThis, jni::alias_ref<JVisionCameraProxy::javaobject> proxy, jint size) {
+  return makeCxxInstance(javaThis, proxy, size);
+}
+
+jni::local_ref<JSharedArray::jhybriddata> JSharedArray::initHybridWrap(jni::alias_ref<jhybridobject> javaThis,
+                                                                       jni::alias_ref<JVisionCameraProxy::javaobject> proxy,
+                                                                       jni::alias_ref<JByteBuffer> byteBuffer) {
+  return makeCxxInstance(javaThis, proxy, byteBuffer);
+}
+
+} // namespace vision
diff --git a/node_modules/react-native-vision-camera/android/bin/src/main/cpp/frameprocessors/java-bindings/JSharedArray.h b/node_modules/react-native-vision-camera/android/bin/src/main/cpp/frameprocessors/java-bindings/JSharedArray.h
new file mode 100644
index 0000000..4069c2d
--- /dev/null
+++ b/node_modules/react-native-vision-camera/android/bin/src/main/cpp/frameprocessors/java-bindings/JSharedArray.h
@@ -0,0 +1,51 @@
+//
+// Created by Marc Rousavy on 12.01.24.
+//
+
+#pragma once
+
+#include "JVisionCameraProxy.h"
+#include "MutableJByteBuffer.h"
+#include <fbjni/ByteBuffer.h>
+#include <fbjni/fbjni.h>
+#include <jni.h>
+
+namespace vision {
+
+using namespace facebook;
+
+class JSharedArray : public jni::HybridClass<JSharedArray> {
+public:
+  static auto constexpr kJavaDescriptor = "Lcom/mrousavy/camera/frameprocessors/SharedArray;";
+  static void registerNatives();
+
+public:
+  static jni::local_ref<JSharedArray::javaobject> create(jsi::Runtime& runtime, jsi::ArrayBuffer arrayBuffer);
+
+public:
+  jint getSize();
+  jni::global_ref<jni::JByteBuffer> getByteBuffer();
+  std::shared_ptr<jsi::ArrayBuffer> getArrayBuffer();
+
+private:
+  static auto constexpr TAG = "SharedArray";
+  friend HybridBase;
+  jni::global_ref<javaobject> _javaPart;
+  jni::global_ref<jni::JByteBuffer> _byteBuffer;
+  std::shared_ptr<jsi::ArrayBuffer> _arrayBuffer;
+  int _size;
+
+private:
+  explicit JSharedArray(jsi::Runtime& runtime, std::shared_ptr<jsi::ArrayBuffer> arrayBuffer);
+  explicit JSharedArray(const jni::alias_ref<jhybridobject>& javaThis, const jni::alias_ref<JVisionCameraProxy::javaobject>& proxy,
+                        int size);
+  explicit JSharedArray(const jni::alias_ref<jhybridobject>& javaThis, const jni::alias_ref<JVisionCameraProxy::javaobject>& proxy,
+                        jni::alias_ref<JByteBuffer> byteBuffer);
+  static jni::local_ref<jhybriddata> initHybridAllocate(jni::alias_ref<jhybridobject> javaThis,
+                                                        jni::alias_ref<JVisionCameraProxy::javaobject> proxy, jint size);
+  static jni::local_ref<jhybriddata> initHybridWrap(jni::alias_ref<jhybridobject> javaThis,
+                                                    jni::alias_ref<JVisionCameraProxy::javaobject> proxy,
+                                                    jni::alias_ref<JByteBuffer> byteBuffer);
+};
+
+} // namespace vision
diff --git a/node_modules/react-native-vision-camera/android/bin/src/main/cpp/frameprocessors/java-bindings/JVisionCameraProxy.cpp b/node_modules/react-native-vision-camera/android/bin/src/main/cpp/frameprocessors/java-bindings/JVisionCameraProxy.cpp
new file mode 100644
index 0000000..94fba4e
--- /dev/null
+++ b/node_modules/react-native-vision-camera/android/bin/src/main/cpp/frameprocessors/java-bindings/JVisionCameraProxy.cpp
@@ -0,0 +1,97 @@
+//
+// Created by Marc Rousavy on 21.07.23.
+//
+
+#include "JVisionCameraProxy.h"
+
+#include <memory>
+#include <string>
+#include <utility>
+
+#include <jsi/jsi.h>
+
+#include "FrameProcessorPluginHostObject.h"
+
+#if VISION_CAMERA_ENABLE_FRAME_PROCESSORS
+#include <react-native-worklets-core/WKTJsiWorklet.h>
+#include <react-native-worklets-core/WKTJsiWorkletContext.h>
+#endif
+
+namespace vision {
+
+using TSelf = local_ref<HybridClass<JVisionCameraProxy>::jhybriddata>;
+using TJSCallInvokerHolder = jni::alias_ref<facebook::react::CallInvokerHolder::javaobject>;
+using TScheduler = jni::alias_ref<JVisionCameraScheduler::javaobject>;
+using TOptions = jni::local_ref<JMap<jstring, jobject>>;
+
+JVisionCameraProxy::JVisionCameraProxy(const jni::alias_ref<JVisionCameraProxy::jhybridobject>& javaThis, jsi::Runtime* runtime,
+                                       const std::shared_ptr<facebook::react::CallInvoker>& callInvoker,
+                                       const jni::global_ref<JVisionCameraScheduler::javaobject>& scheduler) {
+  _javaPart = make_global(javaThis);
+  _runtime = runtime;
+
+#if VISION_CAMERA_ENABLE_FRAME_PROCESSORS
+  __android_log_write(ANDROID_LOG_INFO, TAG, "Creating Worklet Context...");
+
+  auto runOnJS = [callInvoker](std::function<void()>&& f) {
+    // Run on React JS Runtime
+    callInvoker->invokeAsync(std::move(f));
+  };
+  auto runOnWorklet = [scheduler](std::function<void()>&& f) {
+    // Run on Frame Processor Worklet Runtime
+    scheduler->cthis()->dispatchAsync([f = std::move(f)]() { f(); });
+  };
+  _workletContext = std::make_shared<RNWorklet::JsiWorkletContext>("VisionCamera");
+  _workletContext->initialize("VisionCamera", runtime, runOnJS, runOnWorklet);
+  __android_log_write(ANDROID_LOG_INFO, TAG, "Worklet Context created!");
+#else
+  __android_log_write(ANDROID_LOG_INFO, TAG, "Frame Processors are disabled!");
+#endif
+}
+
+JVisionCameraProxy::~JVisionCameraProxy() {
+#if VISION_CAMERA_ENABLE_FRAME_PROCESSORS
+  __android_log_write(ANDROID_LOG_INFO, TAG, "Destroying JVisionCameraProxy...");
+#endif
+}
+
+void JVisionCameraProxy::setFrameProcessor(int viewTag, jsi::Runtime& runtime, const std::shared_ptr<jsi::Function>& function) {
+#if VISION_CAMERA_ENABLE_FRAME_PROCESSORS
+  auto worklet = std::make_shared<RNWorklet::JsiWorklet>(runtime, function);
+  jni::local_ref<JFrameProcessor::javaobject> frameProcessor = JFrameProcessor::create(worklet, _workletContext);
+
+  auto setFrameProcessorMethod = javaClassLocal()->getMethod<void(int, alias_ref<JFrameProcessor::javaobject>)>("setFrameProcessor");
+  setFrameProcessorMethod(_javaPart, viewTag, frameProcessor);
+#else
+  throw std::runtime_error("system/frame-processors-unavailable: Frame Processors are disabled!");
+#endif
+}
+
+void JVisionCameraProxy::removeFrameProcessor(int viewTag) {
+  auto removeFrameProcessorMethod = javaClassLocal()->getMethod<void(int)>("removeFrameProcessor");
+  removeFrameProcessorMethod(_javaPart, viewTag);
+}
+
+local_ref<JFrameProcessorPlugin::javaobject> JVisionCameraProxy::initFrameProcessorPlugin(const std::string& name, TOptions options) {
+  auto initFrameProcessorPluginMethod =
+      javaClassLocal()->getMethod<JFrameProcessorPlugin(local_ref<jstring>, TOptions)>("initFrameProcessorPlugin");
+  return initFrameProcessorPluginMethod(_javaPart, make_jstring(name), std::move(options));
+}
+
+void JVisionCameraProxy::registerNatives() {
+  registerHybrid({makeNativeMethod("initHybrid", JVisionCameraProxy::initHybrid)});
+}
+
+TSelf JVisionCameraProxy::initHybrid(alias_ref<jhybridobject> jThis, jlong jsRuntimePointer, TJSCallInvokerHolder jsCallInvokerHolder,
+                                     const TScheduler& scheduler) {
+  __android_log_write(ANDROID_LOG_INFO, TAG, "Initializing VisionCameraProxy...");
+
+  // cast from JNI hybrid objects to C++ instances
+  auto jsRuntime = reinterpret_cast<jsi::Runtime*>(jsRuntimePointer);
+  auto jsCallInvoker = jsCallInvokerHolder->cthis()->getCallInvoker();
+  auto sharedScheduler = make_global(scheduler);
+
+  return makeCxxInstance(jThis, jsRuntime, jsCallInvoker, sharedScheduler);
+}
+
+} // namespace vision
diff --git a/node_modules/react-native-vision-camera/android/bin/src/main/cpp/frameprocessors/java-bindings/JVisionCameraProxy.h b/node_modules/react-native-vision-camera/android/bin/src/main/cpp/frameprocessors/java-bindings/JVisionCameraProxy.h
new file mode 100644
index 0000000..d06eaa8
--- /dev/null
+++ b/node_modules/react-native-vision-camera/android/bin/src/main/cpp/frameprocessors/java-bindings/JVisionCameraProxy.h
@@ -0,0 +1,69 @@
+//
+// Created by Marc Rousavy on 21.07.23.
+//
+
+#pragma once
+
+#include <ReactCommon/CallInvokerHolder.h>
+#include <fbjni/fbjni.h>
+#include <jsi/jsi.h>
+
+#include "JFrameProcessor.h"
+#include "JFrameProcessorPlugin.h"
+#include "JVisionCameraScheduler.h"
+
+#include <memory>
+#include <string>
+
+#if VISION_CAMERA_ENABLE_FRAME_PROCESSORS
+#include <react-native-worklets-core/WKTJsiWorkletContext.h>
+#endif
+
+namespace vision {
+
+using namespace facebook;
+
+class JVisionCameraProxy : public jni::HybridClass<JVisionCameraProxy> {
+public:
+  ~JVisionCameraProxy();
+  static void registerNatives();
+
+  void setFrameProcessor(int viewTag, jsi::Runtime& runtime, const std::shared_ptr<jsi::Function>& frameProcessor);
+  void removeFrameProcessor(int viewTag);
+  jni::local_ref<JFrameProcessorPlugin::javaobject> initFrameProcessorPlugin(const std::string& name,
+                                                                             jni::local_ref<JMap<jstring, jobject>> options);
+
+  jsi::Runtime* getJSRuntime() {
+    return _runtime;
+  }
+
+#if VISION_CAMERA_ENABLE_FRAME_PROCESSORS
+  jsi::Runtime& getWorkletRuntime() {
+    return _workletContext->getWorkletRuntime();
+  }
+
+  std::shared_ptr<RNWorklet::JsiWorkletContext> getWorkletContext() {
+    return _workletContext;
+  }
+#endif
+
+private:
+  friend HybridBase;
+  jni::global_ref<JVisionCameraProxy::javaobject> _javaPart;
+  jsi::Runtime* _runtime;
+#if VISION_CAMERA_ENABLE_FRAME_PROCESSORS
+  std::shared_ptr<RNWorklet::JsiWorkletContext> _workletContext;
+#endif
+
+  static auto constexpr TAG = "VisionCameraProxy";
+  static auto constexpr kJavaDescriptor = "Lcom/mrousavy/camera/frameprocessors/VisionCameraProxy;";
+
+  explicit JVisionCameraProxy(const jni::alias_ref<JVisionCameraProxy::jhybridobject>& javaThis, jsi::Runtime* jsRuntime,
+                              const std::shared_ptr<facebook::react::CallInvoker>& jsCallInvoker,
+                              const jni::global_ref<JVisionCameraScheduler::javaobject>& scheduler);
+  static jni::local_ref<jhybriddata> initHybrid(jni::alias_ref<jhybridobject> javaThis, jlong jsRuntimePointer,
+                                                jni::alias_ref<facebook::react::CallInvokerHolder::javaobject> jsCallInvokerHolder,
+                                                const jni::alias_ref<JVisionCameraScheduler::javaobject>& scheduler);
+};
+
+} // namespace vision
diff --git a/node_modules/react-native-vision-camera/android/bin/src/main/cpp/frameprocessors/java-bindings/JVisionCameraScheduler.cpp b/node_modules/react-native-vision-camera/android/bin/src/main/cpp/frameprocessors/java-bindings/JVisionCameraScheduler.cpp
new file mode 100644
index 0000000..816b0af
--- /dev/null
+++ b/node_modules/react-native-vision-camera/android/bin/src/main/cpp/frameprocessors/java-bindings/JVisionCameraScheduler.cpp
@@ -0,0 +1,48 @@
+//
+// Created by Marc Rousavy on 25.07.21.
+//
+
+#include "JVisionCameraScheduler.h"
+#include <fbjni/fbjni.h>
+
+namespace vision {
+
+using namespace facebook;
+using TSelf = jni::local_ref<JVisionCameraScheduler::jhybriddata>;
+
+TSelf JVisionCameraScheduler::initHybrid(jni::alias_ref<jhybridobject> jThis) {
+  return makeCxxInstance(jThis);
+}
+
+void JVisionCameraScheduler::dispatchAsync(const std::function<void()>& job) {
+  std::unique_lock<std::mutex> lock(_mutex);
+  // 1. add job to queue
+  _jobs.push(job);
+  scheduleTrigger();
+}
+
+void JVisionCameraScheduler::scheduleTrigger() {
+  // 2.1 Open a JNI Thread scope because this might be called from a C++ background Thread
+  jni::ThreadScope::WithClassLoader([&]() {
+    // 2.2 schedule `triggerUI` to be called on the java thread
+    static auto method = _javaPart->getClass()->getMethod<void()>("scheduleTrigger");
+    method(_javaPart.get());
+  });
+}
+
+void JVisionCameraScheduler::trigger() {
+  std::unique_lock<std::mutex> lock(_mutex);
+  // 3. call job we enqueued in step 1.
+  auto job = _jobs.front();
+  job();
+  _jobs.pop();
+}
+
+void JVisionCameraScheduler::registerNatives() {
+  registerHybrid({
+      makeNativeMethod("initHybrid", JVisionCameraScheduler::initHybrid),
+      makeNativeMethod("trigger", JVisionCameraScheduler::trigger),
+  });
+}
+
+} // namespace vision
diff --git a/node_modules/react-native-vision-camera/android/bin/src/main/cpp/frameprocessors/java-bindings/JVisionCameraScheduler.h b/node_modules/react-native-vision-camera/android/bin/src/main/cpp/frameprocessors/java-bindings/JVisionCameraScheduler.h
new file mode 100644
index 0000000..3c153fd
--- /dev/null
+++ b/node_modules/react-native-vision-camera/android/bin/src/main/cpp/frameprocessors/java-bindings/JVisionCameraScheduler.h
@@ -0,0 +1,49 @@
+//
+// Created by Marc Rousavy on 25.07.21.
+//
+
+#pragma once
+
+#include <fbjni/fbjni.h>
+#include <jni.h>
+#include <mutex>
+#include <queue>
+
+namespace vision {
+
+using namespace facebook;
+
+/**
+ * A Scheduler that runs methods on the Frame Processor Thread (which is a Java Thread).
+ * In order to call something on the Java Frame Processor Thread, you have to:
+ *
+ * 1. Call `dispatchAsync(..)` with the given C++ Method.
+ * 2. Internally, `scheduleTrigger()` will get called, which is a Java Method.
+ * 3. The `scheduleTrigger()` Java Method will switch to the Frame Processor Java Thread and call
+ * `trigger()` on there
+ * 4. `trigger()` is a C++ function here that just calls the passed C++ Method from step 1.
+ */
+class JVisionCameraScheduler : public jni::HybridClass<JVisionCameraScheduler> {
+public:
+  static auto constexpr kJavaDescriptor = "Lcom/mrousavy/camera/frameprocessors/VisionCameraScheduler;";
+  static jni::local_ref<jhybriddata> initHybrid(jni::alias_ref<jhybridobject> jThis);
+  static void registerNatives();
+
+  // schedules the given job to be run on the VisionCamera FP Thread at some future point in time
+  void dispatchAsync(const std::function<void()>& job);
+
+private:
+  friend HybridBase;
+  jni::global_ref<JVisionCameraScheduler::javaobject> _javaPart;
+  std::queue<std::function<void()>> _jobs;
+  std::mutex _mutex;
+
+  explicit JVisionCameraScheduler(jni::alias_ref<JVisionCameraScheduler::jhybridobject> jThis) : _javaPart(jni::make_global(jThis)) {}
+
+  // Schedules a call to `trigger` on the VisionCamera FP Thread
+  void scheduleTrigger();
+  // Calls the latest job in the job queue
+  void trigger();
+};
+
+} // namespace vision
diff --git a/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/core/CameraConfiguration.kt b/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/core/CameraConfiguration.kt
new file mode 100644
index 0000000..f91ce83
--- /dev/null
+++ b/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/core/CameraConfiguration.kt
@@ -0,0 +1,161 @@
+package com.mrousavy.camera.core
+
+import android.util.Range
+import androidx.camera.core.Preview.SurfaceProvider
+import com.mrousavy.camera.core.types.CameraDeviceFormat
+import com.mrousavy.camera.core.types.CodeType
+import com.mrousavy.camera.core.types.OutputOrientation
+import com.mrousavy.camera.core.types.PixelFormat
+import com.mrousavy.camera.core.types.QualityBalance
+import com.mrousavy.camera.core.types.Torch
+import com.mrousavy.camera.core.types.VideoStabilizationMode
+
+data class CameraConfiguration(
+  // Input
+  var cameraId: String? = null,
+
+  // Outputs
+  var preview: Output<Preview> = Output.Disabled.create(),
+  var photo: Output<Photo> = Output.Disabled.create(),
+  var video: Output<Video> = Output.Disabled.create(),
+  var frameProcessor: Output<FrameProcessor> = Output.Disabled.create(),
+  var codeScanner: Output<CodeScanner> = Output.Disabled.create(),
+  var minFps: Int? = null,
+  var maxFps: Int? = null,
+  var enableLocation: Boolean = false,
+
+  // Orientation
+  var outputOrientation: OutputOrientation = OutputOrientation.DEVICE,
+
+  // Format
+  var format: CameraDeviceFormat? = null,
+
+  // Side-Props
+  var enableLowLightBoost: Boolean = false,
+  var torch: Torch = Torch.OFF,
+  var videoStabilizationMode: VideoStabilizationMode = VideoStabilizationMode.OFF,
+  var exposure: Double? = null,
+
+  // Zoom
+  var zoom: Float = 1f,
+
+  // isActive (Start/Stop)
+  var isActive: Boolean = false,
+
+  // Audio Session
+  var audio: Output<Audio> = Output.Disabled.create()
+) {
+  // Output<T> types, those need to be comparable
+  data class CodeScanner(val codeTypes: List<CodeType>)
+  data class Photo(val isMirrored: Boolean, val enableHdr: Boolean, val photoQualityBalance: QualityBalance)
+  data class Video(val isMirrored: Boolean, val enableHdr: Boolean, val bitRateOverride: Double?, val bitRateMultiplier: Double?)
+  data class FrameProcessor(val isMirrored: Boolean, val pixelFormat: PixelFormat)
+  data class Audio(val nothing: Unit)
+  data class Preview(val surfaceProvider: SurfaceProvider)
+
+  val targetFpsRange: Range<Int>?
+    get() {
+      val minFps = minFps ?: return null
+      val maxFps = maxFps ?: return null
+      return Range(minFps, maxFps)
+    }
+
+  val targetPreviewAspectRatio: Float?
+    get() {
+      val format = format ?: return null
+      val video = video as? Output.Enabled<Video>
+      val photo = photo as? Output.Enabled<Photo>
+      return if (video != null) {
+        // Video capture is enabled, use video aspect ratio
+        format.videoWidth.toFloat() / format.videoHeight.toFloat()
+      } else if (photo != null) {
+        // Photo capture is enabled, use photo aspect ratio
+        format.photoWidth.toFloat() / format.photoHeight.toFloat()
+      } else {
+        null
+      }
+    }
+
+  @Suppress("EqualsOrHashCode")
+  sealed class Output<T> {
+    val isEnabled: Boolean
+      get() = this is Enabled<*>
+    class Disabled<T> private constructor() : Output<T>() {
+      override fun equals(other: Any?): Boolean = other is Disabled<*>
+      companion object {
+        fun <T> create(): Disabled<T> = Disabled()
+      }
+    }
+    class Enabled<T> private constructor(val config: T) : Output<T>() {
+      override fun equals(other: Any?): Boolean = other is Enabled<*> && config == other.config
+      companion object {
+        fun <T> create(config: T): Enabled<T> = Enabled(config)
+      }
+    }
+  }
+
+  data class Difference(
+    // Input Camera (cameraId)
+    val deviceChanged: Boolean,
+    // Outputs & Session (Photo, Video, CodeScanner, HDR, Format)
+    val outputsChanged: Boolean,
+    // Side-Props for CaptureRequest (fps, low-light-boost, torch, zoom, videoStabilization)
+    val sidePropsChanged: Boolean,
+    // (isActive) changed
+    val isActiveChanged: Boolean,
+    // (outputOrientation) changed
+    val orientationChanged: Boolean,
+    // (locationChanged) changed
+    val locationChanged: Boolean
+  ) {
+    val hasChanges: Boolean
+      get() = deviceChanged || outputsChanged || sidePropsChanged || isActiveChanged || orientationChanged || locationChanged
+  }
+
+  /**
+   * Throw this to abort a call to configure { ... } and apply no changes.
+   */
+  class AbortThrow : Throwable()
+
+  companion object {
+    fun copyOf(other: CameraConfiguration?): CameraConfiguration = other?.copy() ?: CameraConfiguration()
+
+    fun difference(left: CameraConfiguration?, right: CameraConfiguration): Difference {
+      // outputs
+      val outputsChanged = left?.photo != right.photo ||
+        left.video != right.video ||
+        left.enableLowLightBoost != right.enableLowLightBoost ||
+        left.videoStabilizationMode != right.videoStabilizationMode ||
+        left.frameProcessor != right.frameProcessor ||
+        left.codeScanner != right.codeScanner ||
+        left.preview != right.preview ||
+        left.format != right.format ||
+        left.minFps != right.minFps ||
+        left.maxFps != right.maxFps
+
+      // input device
+      val deviceChanged = outputsChanged || left?.cameraId != right.cameraId
+
+      // repeating request
+      val sidePropsChanged = deviceChanged ||
+        left?.torch != right.torch ||
+        left.zoom != right.zoom ||
+        left.exposure != right.exposure
+
+      val isActiveChanged = left?.isActive != right.isActive
+
+      val orientationChanged = left?.outputOrientation != right.outputOrientation
+
+      val locationChanged = left?.enableLocation != right.enableLocation
+
+      return Difference(
+        deviceChanged,
+        outputsChanged,
+        sidePropsChanged,
+        isActiveChanged,
+        orientationChanged,
+        locationChanged
+      )
+    }
+  }
+}
diff --git a/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/core/CameraDeviceDetails.kt b/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/core/CameraDeviceDetails.kt
new file mode 100644
index 0000000..76b6ab0
--- /dev/null
+++ b/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/core/CameraDeviceDetails.kt
@@ -0,0 +1,271 @@
+package com.mrousavy.camera.core
+
+import android.annotation.SuppressLint
+import android.graphics.ImageFormat
+import android.hardware.camera2.CameraCharacteristics
+import android.util.Log
+import android.util.Range
+import android.util.Size
+import android.util.SizeF
+import androidx.camera.camera2.internal.Camera2CameraInfoImpl
+import androidx.camera.core.CameraInfo
+import androidx.camera.core.DynamicRange
+import androidx.camera.core.FocusMeteringAction
+import androidx.camera.core.SurfaceOrientedMeteringPointFactory
+import androidx.camera.core.impl.CameraInfoInternal
+import androidx.camera.core.impl.capability.PreviewCapabilitiesImpl
+import androidx.camera.extensions.ExtensionMode
+import androidx.camera.extensions.ExtensionsManager
+import androidx.camera.video.Quality.ConstantQuality
+import androidx.camera.video.Recorder
+import com.facebook.react.bridge.Arguments
+import com.facebook.react.bridge.ReadableArray
+import com.facebook.react.bridge.ReadableMap
+import com.mrousavy.camera.core.extensions.id
+import com.mrousavy.camera.core.types.AutoFocusSystem
+import com.mrousavy.camera.core.types.DeviceType
+import com.mrousavy.camera.core.types.HardwareLevel
+import com.mrousavy.camera.core.types.Orientation
+import com.mrousavy.camera.core.types.Position
+import com.mrousavy.camera.core.types.VideoStabilizationMode
+import com.mrousavy.camera.core.utils.CamcorderProfileUtils
+import com.mrousavy.camera.react.extensions.toJSValue
+import kotlin.math.atan2
+import kotlin.math.min
+import kotlin.math.sqrt
+
+@SuppressLint("RestrictedApi")
+@Suppress("FoldInitializerAndIfToElvis")
+class CameraDeviceDetails(private val cameraInfo: CameraInfo, extensionsManager: ExtensionsManager) {
+  companion object {
+    private const val TAG = "CameraDeviceDetails"
+  }
+
+  // Generic props available on all implementations
+  private val cameraId = cameraInfo.id ?: throw NoCameraDeviceError()
+  private val position = Position.fromLensFacing(cameraInfo.lensFacing)
+  private val name = "$cameraId ($position) ${cameraInfo.implementationType}"
+  private val hasFlash = cameraInfo.hasFlashUnit()
+  private val minZoom = cameraInfo.zoomState.value?.minZoomRatio ?: 0f
+  private val maxZoom = cameraInfo.zoomState.value?.maxZoomRatio ?: 1f
+  private val minExposure = cameraInfo.exposureState.exposureCompensationRange.lower
+  private val maxExposure = cameraInfo.exposureState.exposureCompensationRange.upper
+  private val supportsFocus = getSupportsFocus()
+  private val supportsRawCapture = false
+  private val supportsDepthCapture = false
+  private val autoFocusSystem = if (supportsFocus) AutoFocusSystem.CONTRAST_DETECTION else AutoFocusSystem.NONE
+  private val previewCapabilities = PreviewCapabilitiesImpl.from(cameraInfo)
+  private val videoCapabilities = Recorder.getVideoCapabilities(cameraInfo, Recorder.VIDEO_CAPABILITIES_SOURCE_CAMCORDER_PROFILE)
+  private val supports10BitHdr = getSupports10BitHDR()
+  private val sensorRotationDegrees = cameraInfo.sensorRotationDegrees
+  private val sensorOrientation = Orientation.fromRotationDegrees(sensorRotationDegrees)
+
+  // CameraX internal props
+  private val cameraInfoInternal = cameraInfo as CameraInfoInternal
+
+  // Camera2 specific props
+  private val camera2Details = cameraInfo as? Camera2CameraInfoImpl
+  private val physicalDeviceIds = camera2Details?.cameraCharacteristicsMap?.keys ?: emptySet()
+  private val isMultiCam = physicalDeviceIds.size > 1
+  private val cameraHardwareLevel = camera2Details?.cameraCharacteristicsCompat?.get(CameraCharacteristics.INFO_SUPPORTED_HARDWARE_LEVEL)
+  private val hardwareLevel = HardwareLevel.fromCameraHardwareLevel(
+    cameraHardwareLevel ?: CameraCharacteristics.INFO_SUPPORTED_HARDWARE_LEVEL_LEGACY
+  )
+  private val minFocusDistance = getMinFocusDistanceCm()
+  private val isoRange = getIsoRange()
+  private val maxFieldOfView = getMaxFieldOfView()
+
+  // Extensions
+  private val supportsHdrExtension = extensionsManager.isExtensionAvailable(cameraInfo.cameraSelector, ExtensionMode.HDR)
+  private val supportsLowLightBoostExtension = extensionsManager.isExtensionAvailable(cameraInfo.cameraSelector, ExtensionMode.NIGHT)
+
+  fun toMap(): ReadableMap {
+    val deviceTypes = getDeviceTypes()
+    val formats = getFormats()
+
+    val map = Arguments.createMap()
+    map.putString("id", cameraId)
+    map.putArray("physicalDevices", deviceTypes.toJSValue())
+    map.putString("position", position.unionValue)
+    map.putString("name", name)
+    map.putBoolean("hasFlash", hasFlash)
+    map.putBoolean("hasTorch", hasFlash)
+    map.putDouble("minFocusDistance", minFocusDistance)
+    map.putBoolean("isMultiCam", isMultiCam)
+    map.putBoolean("supportsRawCapture", supportsRawCapture)
+    map.putBoolean("supportsLowLightBoost", supportsLowLightBoostExtension)
+    map.putBoolean("supportsFocus", supportsFocus)
+    map.putDouble("minZoom", minZoom.toDouble())
+    map.putDouble("maxZoom", maxZoom.toDouble())
+    map.putDouble("neutralZoom", 1.0) // Zoom is always relative to 1.0 on Android
+    map.putInt("minExposure", minExposure)
+    map.putInt("maxExposure", maxExposure)
+    map.putString("hardwareLevel", hardwareLevel.unionValue)
+    map.putString("sensorOrientation", sensorOrientation.unionValue)
+    map.putArray("formats", formats)
+    return map
+  }
+
+  /**
+   * Get a list of formats (or "possible stream resolution combinations") that this device supports.
+   *
+   * This filters all resolutions according to the
+   * [Camera2 "StreamConfigurationMap" documentation](https://developer.android.com/reference/android/hardware/camera2/params/StreamConfigurationMap)
+   */
+  private fun getFormats(): ReadableArray {
+    val array = Arguments.createArray()
+
+    val dynamicRangeProfiles = videoCapabilities.supportedDynamicRanges
+
+    dynamicRangeProfiles.forEach { dynamicRange ->
+      try {
+        val qualities = videoCapabilities.getSupportedQualities(dynamicRange)
+        val videoSizes = qualities.map { it as ConstantQuality }.flatMap { it.typicalSizes }
+        val photoSizes = (
+          cameraInfoInternal.getSupportedHighResolutions(ImageFormat.JPEG) union
+            cameraInfoInternal.getSupportedResolutions(ImageFormat.JPEG)
+          ).toList()
+        val fpsRanges = cameraInfo.supportedFrameRateRanges
+        val minFps = fpsRanges.minOf { it.lower }
+        val maxFps = fpsRanges.maxOf { it.upper }
+
+        videoSizes.forEach { videoSize ->
+          try {
+            // not every size supports the maximum FPS range
+            val maxFpsForSize = CamcorderProfileUtils.getMaximumFps(cameraId, videoSize) ?: maxFps
+            // if the FPS range for this size is even smaller than min FPS, we need to clamp that as well.
+            val minFpsForSize = min(minFps, maxFpsForSize)
+            val fpsRange = Range(minFpsForSize, maxFpsForSize)
+
+            photoSizes.forEach { photoSize ->
+              try {
+                val map = buildFormatMap(photoSize, videoSize, fpsRange)
+                array.pushMap(map)
+              } catch (error: Throwable) {
+                Log.w(TAG, "Photo size ${photoSize.width}x${photoSize.height} cannot be used as a format!", error)
+              }
+            }
+          } catch (error: Throwable) {
+            Log.w(TAG, "Video size ${videoSize.width}x${videoSize.height} cannot be used as a format!", error)
+          }
+        }
+      } catch (error: Throwable) {
+        Log.w(TAG, "Dynamic Range Profile $dynamicRange cannot be used as a format!", error)
+      }
+    }
+
+    return array
+  }
+
+  private fun buildFormatMap(photoSize: Size, videoSize: Size, fpsRange: Range<Int>): ReadableMap {
+    val map = Arguments.createMap()
+    map.putInt("photoHeight", photoSize.height)
+    map.putInt("photoWidth", photoSize.width)
+    map.putInt("videoHeight", videoSize.height)
+    map.putInt("videoWidth", videoSize.width)
+    map.putInt("minFps", fpsRange.lower)
+    map.putInt("maxFps", fpsRange.upper)
+    map.putInt("minISO", isoRange.lower)
+    map.putInt("maxISO", isoRange.upper)
+    map.putDouble("fieldOfView", maxFieldOfView)
+    map.putBoolean("supportsVideoHdr", supports10BitHdr)
+    map.putBoolean("supportsPhotoHdr", supportsHdrExtension)
+    map.putBoolean("supportsDepthCapture", supportsDepthCapture)
+    map.putString("autoFocusSystem", autoFocusSystem.unionValue)
+    map.putArray("videoStabilizationModes", createStabilizationModes())
+    return map
+  }
+
+  private fun getSupports10BitHDR(): Boolean =
+    videoCapabilities.supportedDynamicRanges.any { range ->
+      range.is10BitHdr || range == DynamicRange.HDR_UNSPECIFIED_10_BIT
+    }
+
+  private fun getSupportsFocus(): Boolean {
+    val point = SurfaceOrientedMeteringPointFactory(1.0f, 1.0f).createPoint(0.5f, 0.5f)
+    val action = FocusMeteringAction.Builder(point)
+    return cameraInfo.isFocusMeteringSupported(action.build())
+  }
+
+  private fun getMinFocusDistanceCm(): Double {
+    val device = cameraInfo as? Camera2CameraInfoImpl
+    if (device == null) {
+      // Device is not a Camera2 device.
+      return 0.0
+    }
+
+    val distance = device.cameraCharacteristicsCompat.get(CameraCharacteristics.LENS_INFO_MINIMUM_FOCUS_DISTANCE)
+    if (distance == null || distance == 0f) return 0.0
+    if (distance.isNaN() || distance.isInfinite()) return 0.0
+    // distance is in "diopters", meaning 1/meter. Convert to meters, then centi-meters
+    return 1.0 / distance * 100.0
+  }
+
+  private fun getIsoRange(): Range<Int> {
+    val device = cameraInfo as? Camera2CameraInfoImpl
+    if (device == null) {
+      // Device is not a Camera2 device.
+      return Range(0, 0)
+    }
+
+    val range = device.cameraCharacteristicsCompat.get(CameraCharacteristics.SENSOR_INFO_SENSITIVITY_RANGE)
+    return range ?: Range(0, 0)
+  }
+
+  private fun createStabilizationModes(): ReadableArray {
+    val modes = mutableSetOf(VideoStabilizationMode.OFF)
+    if (videoCapabilities.isStabilizationSupported) {
+      modes.add(VideoStabilizationMode.CINEMATIC)
+    }
+    if (previewCapabilities.isStabilizationSupported) {
+      modes.add(VideoStabilizationMode.CINEMATIC_EXTENDED)
+    }
+
+    val array = Arguments.createArray()
+    modes.forEach { mode ->
+      array.pushString(mode.unionValue)
+    }
+    return array
+  }
+
+  private fun getDeviceTypes(): List<DeviceType> {
+    val defaultList = listOf(DeviceType.WIDE_ANGLE)
+    val camera2Details = camera2Details ?: return defaultList
+
+    val deviceTypes = camera2Details.cameraCharacteristicsMap.map { (_, characteristics) ->
+      val sensorSize = characteristics.get(CameraCharacteristics.SENSOR_INFO_PHYSICAL_SIZE) ?: return@map DeviceType.WIDE_ANGLE
+      val focalLengths = characteristics.get(CameraCharacteristics.LENS_INFO_AVAILABLE_FOCAL_LENGTHS) ?: return@map DeviceType.WIDE_ANGLE
+      val fov = getMaxFieldOfView(focalLengths, sensorSize)
+
+      return@map when {
+        fov > 94 -> DeviceType.ULTRA_WIDE_ANGLE
+        fov in 60f..94f -> DeviceType.WIDE_ANGLE
+        fov < 60f -> DeviceType.TELEPHOTO
+        else -> throw Error("Invalid Field Of View! ($fov)")
+      }
+    }
+
+    return deviceTypes
+  }
+
+  private fun getFieldOfView(focalLength: Float, sensorSize: SizeF): Double {
+    if ((sensorSize.width == 0f) || (sensorSize.height == 0f)) {
+      return 0.0
+    }
+    val sensorDiagonal = sqrt((sensorSize.width * sensorSize.width + sensorSize.height * sensorSize.height).toDouble())
+    val fovRadians = 2.0 * atan2(sensorDiagonal, (2.0 * focalLength))
+    return Math.toDegrees(fovRadians)
+  }
+
+  private fun getMaxFieldOfView(focalLengths: FloatArray, sensorSize: SizeF): Double {
+    val smallestFocalLength = focalLengths.minOrNull() ?: return 0.0
+    return getFieldOfView(smallestFocalLength, sensorSize)
+  }
+
+  private fun getMaxFieldOfView(): Double {
+    val characteristics = camera2Details?.cameraCharacteristicsCompat ?: return 0.0
+    val sensorSize = characteristics.get(CameraCharacteristics.SENSOR_INFO_PHYSICAL_SIZE) ?: return 0.0
+    val focalLengths = characteristics.get(CameraCharacteristics.LENS_INFO_AVAILABLE_FOCAL_LENGTHS) ?: return 0.0
+    return getMaxFieldOfView(focalLengths, sensorSize)
+  }
+}
diff --git a/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/core/CameraError.kt b/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/core/CameraError.kt
new file mode 100644
index 0000000..3656930
--- /dev/null
+++ b/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/core/CameraError.kt
@@ -0,0 +1,249 @@
+package com.mrousavy.camera.core
+
+import com.mrousavy.camera.core.types.VideoStabilizationMode
+
+abstract class CameraError(
+  /**
+   * The domain of the error. Error domains are used to group errors.
+   *
+   * Example: "permission"
+   */
+  val domain: String,
+  /**
+   * The id of the error. Errors are uniquely identified under a given domain.
+   *
+   * Example: "microphone-permission-denied"
+   */
+  val id: String,
+  /**
+   * A detailed error description of "what went wrong".
+   *
+   * Example: "The microphone permission was denied!"
+   */
+  override val message: String,
+  /**
+   * A throwable that caused this error.
+   */
+  cause: Throwable? = null
+) : Throwable("[$domain/$id] $message", cause) {
+  val code: String
+    get() = "$domain/$id"
+}
+
+class CameraPermissionError : CameraError("permission", "camera-permission-denied", "The Camera permission was denied!")
+class MicrophonePermissionError :
+  CameraError(
+    "permission",
+    "microphone-permission-denied",
+    "The Microphone permission was denied! If you want to record Video without sound, pass `audio={false}`."
+  )
+class LocationPermissionError :
+  CameraError(
+    "permission",
+    "location-permission-denied",
+    "The Location permission was denied! If you want to capture photos or videos without location tags, pass `enableLocation={false}`."
+  )
+
+class InvalidTypeScriptUnionError(unionName: String, unionValue: String?) :
+  CameraError("parameter", "invalid-parameter", "The given value for $unionName could not be parsed! (Received: $unionValue)")
+
+class NoCameraDeviceError :
+  CameraError(
+    "device",
+    "no-device",
+    "No device was set! Use `useCameraDevice(..)` or `Camera.getAvailableCameraDevices()` to select a suitable Camera device."
+  )
+class PixelFormatNotSupportedError(format: String) :
+  CameraError("device", "pixel-format-not-supported", "The pixelFormat $format is not supported on the given Camera Device!")
+class FlashUnavailableError :
+  CameraError(
+    "device",
+    "flash-not-available",
+    "The Camera Device does not have a flash unit! Make sure you select a device where `device.hasFlash`/`device.hasTorch` is true."
+  )
+class FocusNotSupportedError :
+  CameraError("device", "focus-not-supported", "The currently selected camera device does not support focusing!")
+class CameraInUseError(cause: Throwable?) :
+  CameraError("device", "camera-already-in-use", "The given Camera Device is already in use!", cause)
+class FatalCameraError(cause: Throwable?) :
+  CameraError("device", "fatal-error", "An unknown fatal error occurred in the Camera HAL! Try restarting the phone.", cause)
+
+class CameraNotReadyError :
+  CameraError("session", "camera-not-ready", "The Camera is not ready yet! Wait for the onInitialized() callback!")
+class NoOutputsError :
+  CameraError("session", "no-outputs", "Cannot create a CameraCaptureSession without any outputs! (PREVIEW, PHOTO, VIDEO, ...)")
+class RecoverableError(cause: Throwable?) :
+  CameraError(
+    "session",
+    "recoverable-error",
+    "An unknown error occurred while creating the Camera Session, but the Camera can recover from it.",
+    cause
+  )
+class InvalidOutputConfigurationError(cause: Throwable?) :
+  CameraError(
+    "session",
+    "invalid-output-configuration",
+    "Failed to configure the Camera Session because the output/stream configurations are invalid!",
+    cause
+  )
+
+class PropRequiresFormatToBeNonNullError(propName: String) :
+  CameraError("format", "format-required", "The prop \"$propName\" requires a format to be set, but format was null!")
+class InvalidFpsError(fps: Int) :
+  CameraError(
+    "format",
+    "invalid-fps",
+    "The given format cannot run at $fps FPS! Make sure your FPS is lower than `format.maxFps` but higher than `format.minFps`."
+  )
+class InvalidVideoStabilizationMode(mode: VideoStabilizationMode) :
+  CameraError(
+    "format",
+    "invalid-video-stabilization-mode",
+    "The given format does not support the videoStabilizationMode \"${mode.unionValue}\"! " +
+      "Select a format that contains ${mode.unionValue} in `format.supportedVideoStabilizationModes`."
+  )
+class InvalidVideoHdrError :
+  CameraError(
+    "format",
+    "invalid-video-hdr",
+    "The given format does not support videoHdr! Select a format where `format.supportsVideoHdr` is true."
+  )
+class PhotoHdrAndVideoHdrNotSupportedSimultaneously :
+  CameraError(
+    "format",
+    "photo-hdr-and-video-hdr-not-suppoted-simultaneously",
+    "Photo HDR and Video HDR are not supported simultaneously! Disable either `videoHdr` or `photoHdr`."
+  )
+class LowLightBoostNotSupportedWithHdr :
+  CameraError(
+    "format",
+    "low-light-boost-not-supported-with-hdr",
+    "The low light boost extension does not work when HDR is enabled! Disable either `lowLightBoost` or `videoHdr`/`photoHdr`."
+  )
+
+class VideoNotEnabledError :
+  CameraError("capture", "video-not-enabled", "Video capture is disabled! Pass `video={true}` to enable video recordings.")
+class PhotoNotEnabledError :
+  CameraError("capture", "photo-not-enabled", "Photo capture is disabled! Pass `photo={true}` to enable photo capture.")
+class SnapshotFailedError :
+  CameraError("capture", "snapshot-failed", "Failed to take a Snapshot of the Preview View! Try using takePhoto() instead.")
+class SnapshotFailedPreviewNotEnabledError :
+  CameraError(
+    "capture",
+    "snapshot-failed-preview-not-enabled",
+    "Failed to take a Snapshot because preview={...} was disabled! " +
+      "Enable preview and try again."
+  )
+class FocusCanceledError : CameraError("capture", "focus-canceled", "The focus operation has been canceled by a new focus request.")
+class FocusRequiresPreviewError : CameraError("capture", "focus-requires-preview", "Focus requires preview={...} to be enabled!")
+
+private fun getVideoCapturedMessage(wasVideoCaptured: Boolean): String =
+  if (wasVideoCaptured) {
+    "The output file was generated, so the recording may be valid."
+  } else {
+    "The output file was generated but the recording will not be valid, so you should delete the file."
+  }
+
+open class RecorderError(id: String, message: String, val wasVideoRecorded: Boolean, cause: Throwable?) :
+  CameraError("capture", id, message, cause)
+class UnknownRecorderError(wasVideoRecorded: Boolean, cause: Throwable?) :
+  RecorderError(
+    "recorder-error",
+    "An error occurred while recording a video! ${getVideoCapturedMessage(wasVideoRecorded)} ${cause?.message}",
+    wasVideoRecorded,
+    cause
+  )
+class EncoderError(cause: Throwable?) :
+  RecorderError("encoder-error", "The Video Encoder encountered an error occurred while recording a video!", false, cause)
+class NoDataError(cause: Throwable?) :
+  RecorderError(
+    "no-data",
+    "The Video Recording failed because no data was received! (${cause?.message}) " +
+      "Did you stop the recording before any Frames arrived?",
+    false,
+    cause
+  )
+class InvalidRecorderConfigurationError(cause: Throwable?) :
+  RecorderError(
+    "invalid-recorder-configuration",
+    "The Video Recording failed because it was configured with invalid settings! ${cause?.message}",
+    false,
+    cause
+  )
+class FileSizeLimitReachedError(cause: Throwable?) :
+  RecorderError(
+    "file-size-limit-reached",
+    "The Video Recording was stopped because the file size limit was reached. The output file may still be valid.",
+    true,
+    cause
+  )
+class DurationLimitReachedError(cause: Throwable?) :
+  RecorderError(
+    "duration-limit-reached",
+    "The Video Recording was stopped because the duration limit was reached. The output file may still be valid.",
+    true,
+    cause
+  )
+class InsufficientStorageForRecorderError(cause: Throwable?) :
+  RecorderError("insufficient-storage", "There is not enough storage space available for a Video Recording.", false, cause)
+class NoRecordingInProgressError :
+  CameraError("capture", "no-recording-in-progress", "There was no active video recording in progress! Did you call stopRecording() twice?")
+class RecordingCanceledError : CameraError("capture", "recording-canceled", "The active recording was canceled.")
+class FileIOError(throwable: Throwable) :
+  CameraError("capture", "file-io-error", "An unexpected File IO error occurred! Error: ${throwable.message}.", throwable)
+class InvalidPathError(path: String) : CameraError("capture", "invalid-path", "The given path ($path) is invalid, or not writable!")
+class RecordingInProgressError :
+  CameraError(
+    "capture",
+    "recording-in-progress",
+    "There is already an active video recording in progress! Did you call startRecording() twice?"
+  )
+class FrameInvalidError :
+  CameraError(
+    "capture",
+    "frame-invalid",
+    "Trying to access an already closed Frame! " +
+      "Are you trying to access the Image data outside of a Frame Processor's lifetime?\n" +
+      "- If you want to use `console.log(frame)`, use `console.log(frame.toString())` instead.\n" +
+      "- If you want to do async processing, use `runAsync(...)` instead.\n" +
+      "- If you want to use runOnJS, increment it's ref-count: `frame.incrementRefCount()`"
+  )
+class InvalidImageTypeError : CameraError("capture", "invalid-image-type", "Captured an Image with an invalid Image type!")
+
+class CodeTypeNotSupportedError(codeType: String) :
+  CameraError(
+    "code-scanner",
+    "code-type-not-supported",
+    "The codeType \"$codeType\" is not supported by the Code Scanner!"
+  )
+
+class ViewNotFoundError(viewId: Int) :
+  CameraError("system", "view-not-found", "The given view (ID $viewId) was not found in the view manager.")
+class HardwareBuffersNotAvailableError :
+  CameraError("system", "hardware-buffers-unavailable", "HardwareBuffers are only available on API 28 or higher!")
+class MaxCamerasInUseError(cause: Throwable?) :
+  CameraError("system", "max-cameras-in-use", "The maximum amount of Cameras available for simultaneous use has been reached!", cause)
+class CameraIsRestrictedError(cause: Throwable?) :
+  CameraError(
+    "system",
+    "camera-is-restricted",
+    "Camera functionality is not available because it has been restricted by the operating system, possibly due to a device policy.",
+    cause
+  )
+class DoNotDisturbBugError(cause: Throwable?) :
+  CameraError(
+    "system",
+    "do-not-disturb-bug",
+    "The Camera Device could not be opened because of a bug in Android 9 (API 28) when do-not-disturb mode is enabled! " +
+      "Either update your Android version, or disable do-not-disturb.",
+    cause
+  )
+class RecordingWhileFrameProcessingUnavailable :
+  CameraError(
+    "system",
+    "recording-while-frame-processing-unavailable",
+    "Video Recordings are not possible with a Frame Processor running, " +
+      "because the device is running on API 22 or lower and ImageWriters are not available."
+  )
+
+class UnknownCameraError(cause: Throwable?) : CameraError("unknown", "unknown", cause?.message ?: "An unknown camera error occured.", cause)
diff --git a/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/core/CameraQueues.kt b/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/core/CameraQueues.kt
new file mode 100644
index 0000000..d447316
--- /dev/null
+++ b/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/core/CameraQueues.kt
@@ -0,0 +1,37 @@
+package com.mrousavy.camera.core
+
+import android.os.Handler
+import android.os.HandlerThread
+import java.util.concurrent.Executor
+import java.util.concurrent.ExecutorService
+import java.util.concurrent.Executors
+import kotlinx.coroutines.CoroutineDispatcher
+import kotlinx.coroutines.android.asCoroutineDispatcher
+import kotlinx.coroutines.asExecutor
+
+class CameraQueues {
+  companion object {
+    val analyzerExecutor: ExecutorService = Executors.newCachedThreadPool()
+    val cameraExecutor: ExecutorService = Executors.newCachedThreadPool()
+    val videoQueue = CameraQueue("mrousavy/VisionCamera.video")
+  }
+
+  class CameraQueue(name: String) {
+    private val thread: HandlerThread
+    val handler: Handler
+    private val coroutineDispatcher: CoroutineDispatcher
+    val executor: Executor
+
+    init {
+      thread = HandlerThread(name)
+      thread.start()
+      handler = Handler(thread.looper)
+      coroutineDispatcher = handler.asCoroutineDispatcher(name)
+      executor = coroutineDispatcher.asExecutor()
+    }
+
+    protected fun finalize() {
+      thread.quitSafely()
+    }
+  }
+}
diff --git a/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/core/CameraSession+Configuration.kt b/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/core/CameraSession+Configuration.kt
new file mode 100644
index 0000000..1e9c0de
--- /dev/null
+++ b/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/core/CameraSession+Configuration.kt
@@ -0,0 +1,349 @@
+package com.mrousavy.camera.core
+
+import android.annotation.SuppressLint
+import android.util.Log
+import androidx.annotation.OptIn
+import androidx.camera.core.CameraSelector
+import androidx.camera.core.CameraState
+import androidx.camera.core.DynamicRange
+import androidx.camera.core.ExperimentalGetImage
+import androidx.camera.core.ImageAnalysis
+import androidx.camera.core.ImageCapture
+import androidx.camera.core.MirrorMode
+import androidx.camera.core.Preview
+import androidx.camera.core.TorchState
+import androidx.camera.core.resolutionselector.ResolutionSelector
+import androidx.camera.extensions.ExtensionMode
+import androidx.camera.lifecycle.ProcessCameraProvider
+import androidx.camera.video.Recorder
+import androidx.camera.video.VideoCapture
+import androidx.lifecycle.Lifecycle
+import com.mrousavy.camera.core.extensions.*
+import com.mrousavy.camera.core.types.CameraDeviceFormat
+import com.mrousavy.camera.core.types.Torch
+import com.mrousavy.camera.core.types.VideoStabilizationMode
+import com.mrousavy.camera.core.utils.CamcorderProfileUtils
+import kotlin.math.roundToInt
+
+private fun assertFormatRequirement(
+  propName: String,
+  format: CameraDeviceFormat?,
+  throwIfNotMet: CameraError,
+  requirement: (format: CameraDeviceFormat) -> Boolean
+) {
+  if (format == null) {
+    // we need a format for this to work.
+    throw PropRequiresFormatToBeNonNullError(propName)
+  }
+  val isSupported = requirement(format)
+  if (!isSupported) {
+    throw throwIfNotMet
+  }
+}
+
+@OptIn(ExperimentalGetImage::class)
+@SuppressLint("RestrictedApi")
+@Suppress("LiftReturnOrAssignment")
+internal fun CameraSession.configureOutputs(configuration: CameraConfiguration) {
+  val cameraId = configuration.cameraId!!
+  Log.i(CameraSession.TAG, "Creating new Outputs for Camera #$cameraId...")
+  val fpsRange = configuration.targetFpsRange
+  val format = configuration.format
+
+  Log.i(CameraSession.TAG, "Using FPS Range: $fpsRange")
+
+  val photoConfig = configuration.photo as? CameraConfiguration.Output.Enabled<CameraConfiguration.Photo>
+  val videoConfig = configuration.video as? CameraConfiguration.Output.Enabled<CameraConfiguration.Video>
+
+  // 1. Preview
+  val previewConfig = configuration.preview as? CameraConfiguration.Output.Enabled<CameraConfiguration.Preview>
+  if (previewConfig != null) {
+    Log.i(CameraSession.TAG, "Creating Preview output...")
+    val preview = Preview.Builder().also { preview ->
+      // Configure Preview Output
+      if (configuration.videoStabilizationMode.isAtLeast(VideoStabilizationMode.CINEMATIC)) {
+        assertFormatRequirement("videoStabilizationMode", format, InvalidVideoStabilizationMode(configuration.videoStabilizationMode)) {
+          it.videoStabilizationModes.contains(configuration.videoStabilizationMode)
+        }
+        preview.setPreviewStabilizationEnabled(true)
+      }
+      if (fpsRange != null) {
+        assertFormatRequirement("fps", format, InvalidFpsError(fpsRange.upper)) {
+          fpsRange.lower >= it.minFps && fpsRange.upper <= it.maxFps
+        }
+        preview.setTargetFrameRate(fpsRange)
+      }
+
+      if (format != null) {
+        // Preview will follow video size as it's size & aspect ratio, or photo- if video is disabled.
+        val targetSize = if (videoConfig != null) format.videoSize else format.photoSize
+
+        val previewResolutionSelector = ResolutionSelector.Builder()
+          .forSize(targetSize)
+          .setAllowedResolutionMode(ResolutionSelector.PREFER_CAPTURE_RATE_OVER_HIGHER_RESOLUTION)
+          .build()
+        preview.setResolutionSelector(previewResolutionSelector)
+      }
+    }.build()
+    preview.setSurfaceProvider(previewConfig.config.surfaceProvider)
+    previewOutput = preview
+  } else {
+    previewOutput = null
+  }
+
+  // 2. Image Capture
+  if (photoConfig != null) {
+    Log.i(CameraSession.TAG, "Creating Photo output...")
+    val photo = ImageCapture.Builder().also { photo ->
+      // Configure Photo Output
+      photo.setCaptureMode(photoConfig.config.photoQualityBalance.toCaptureMode())
+      if (format != null) {
+        Log.i(CameraSession.TAG, "Photo size: ${format.photoSize}")
+        val resolutionSelector = ResolutionSelector.Builder()
+          .forSize(format.photoSize)
+          .setAllowedResolutionMode(ResolutionSelector.PREFER_HIGHER_RESOLUTION_OVER_CAPTURE_RATE)
+          .build()
+        photo.setResolutionSelector(resolutionSelector)
+      }
+    }.build()
+    photoOutput = photo
+  } else {
+    photoOutput = null
+  }
+
+  // 3. Video Capture
+  if (videoConfig != null) {
+    Log.i(CameraSession.TAG, "Creating Video output...")
+    val currentRecorder = recorderOutput
+    val recorder = if (recording != null && currentRecorder != null) {
+      // If we are currently recording, then don't re-create the recorder instance.
+      // Instead, re-use it so we don't cancel the active recording.
+      Log.i(CameraSession.TAG, "Re-using active Recorder because we are currently recording...")
+      currentRecorder
+    } else {
+      // We are currently not recording, so we can re-create a recorder instance if needed.
+      Log.i(CameraSession.TAG, "Creating new Recorder...")
+      Recorder.Builder().also { recorder ->
+        format?.let { format ->
+          recorder.setQualitySelector(format.videoQualitySelector)
+        }
+        videoConfig.config.bitRateOverride?.let { bitRateOverride ->
+          val bps = bitRateOverride * 1_000_000
+          recorder.setTargetVideoEncodingBitRate(bps.toInt())
+        }
+        videoConfig.config.bitRateMultiplier?.let { bitRateMultiplier ->
+          if (format == null) {
+            // We need to get the videoSize to estimate the bitRate modifier
+            throw PropRequiresFormatToBeNonNullError("videoBitRate")
+          }
+          val recommendedBitRate = CamcorderProfileUtils.getRecommendedBitRate(cameraId, format.videoSize)
+          if (recommendedBitRate != null) {
+            val targetBitRate = recommendedBitRate.toDouble() * bitRateMultiplier
+            recorder.setTargetVideoEncodingBitRate(targetBitRate.toInt())
+          }
+        }
+      }.build()
+    }
+
+    val video = VideoCapture.Builder(recorder).also { video ->
+      // Configure Video Output
+      if (videoConfig.config.isMirrored) {
+        video.setMirrorMode(MirrorMode.MIRROR_MODE_ON)
+      } else {
+        video.setMirrorMode(MirrorMode.MIRROR_MODE_OFF)
+      }
+      if (configuration.videoStabilizationMode.isAtLeast(VideoStabilizationMode.STANDARD)) {
+        assertFormatRequirement("videoStabilizationMode", format, InvalidVideoStabilizationMode(configuration.videoStabilizationMode)) {
+          it.videoStabilizationModes.contains(configuration.videoStabilizationMode)
+        }
+        video.setVideoStabilizationEnabled(true)
+      }
+      if (fpsRange != null) {
+        assertFormatRequirement("fps", format, InvalidFpsError(fpsRange.upper)) {
+          fpsRange.lower >= it.minFps &&
+            fpsRange.upper <= it.maxFps
+        }
+        video.setTargetFrameRate(fpsRange)
+      }
+      if (videoConfig.config.enableHdr) {
+        assertFormatRequirement("videoHdr", format, InvalidVideoHdrError()) { it.supportsVideoHdr }
+        video.setDynamicRange(DynamicRange.HDR_UNSPECIFIED_10_BIT)
+      }
+      if (format != null) {
+        Log.i(CameraSession.TAG, "Video size: ${format.videoSize}")
+        val resolutionSelector = ResolutionSelector.Builder()
+          .forSize(format.videoSize)
+          .setAllowedResolutionMode(ResolutionSelector.PREFER_CAPTURE_RATE_OVER_HIGHER_RESOLUTION)
+          .build()
+        video.setResolutionSelector(resolutionSelector)
+      }
+    }.build()
+    videoOutput = video
+    recorderOutput = recorder
+  } else {
+    videoOutput = null
+    recorderOutput = null
+  }
+
+  // 4. Frame Processor
+  val frameProcessorConfig = configuration.frameProcessor as? CameraConfiguration.Output.Enabled<CameraConfiguration.FrameProcessor>
+  if (frameProcessorConfig != null) {
+    val pixelFormat = frameProcessorConfig.config.pixelFormat
+    Log.i(CameraSession.TAG, "Creating $pixelFormat Frame Processor output...")
+    val analyzer = ImageAnalysis.Builder().also { analysis ->
+      analysis.setBackpressureStrategy(ImageAnalysis.STRATEGY_BLOCK_PRODUCER)
+      analysis.setOutputImageFormat(pixelFormat.toImageAnalysisFormat())
+      if (fpsRange != null) {
+        assertFormatRequirement("fps", format, InvalidFpsError(fpsRange.upper)) {
+          fpsRange.lower >= it.minFps &&
+            fpsRange.upper <= it.maxFps
+        }
+        analysis.setTargetFrameRate(fpsRange)
+      }
+      if (format != null) {
+        Log.i(CameraSession.TAG, "Frame Processor size: ${format.videoSize}")
+        val resolutionSelector = ResolutionSelector.Builder()
+          .forSize(format.videoSize)
+          .setAllowedResolutionMode(ResolutionSelector.PREFER_CAPTURE_RATE_OVER_HIGHER_RESOLUTION)
+          .build()
+        analysis.setResolutionSelector(resolutionSelector)
+      }
+    }.build()
+    val pipeline = FrameProcessorPipeline(callback)
+    analyzer.setAnalyzer(CameraQueues.videoQueue.executor, pipeline)
+    frameProcessorOutput = analyzer
+  } else {
+    frameProcessorOutput = null
+  }
+
+  // 5. Code Scanner
+  val codeScannerConfig = configuration.codeScanner as? CameraConfiguration.Output.Enabled<CameraConfiguration.CodeScanner>
+  if (codeScannerConfig != null) {
+    Log.i(CameraSession.TAG, "Creating CodeScanner output...")
+    val analyzer = ImageAnalysis.Builder().build()
+    val pipeline = CodeScannerPipeline(codeScannerConfig.config, callback)
+    analyzer.setAnalyzer(CameraQueues.analyzerExecutor, pipeline)
+    codeScannerOutput = analyzer
+  } else {
+    codeScannerOutput = null
+  }
+  Log.i(CameraSession.TAG, "Successfully created new Outputs for Camera #${configuration.cameraId}!")
+}
+
+@SuppressLint("RestrictedApi")
+internal suspend fun CameraSession.configureCamera(provider: ProcessCameraProvider, configuration: CameraConfiguration) {
+  Log.i(CameraSession.TAG, "Binding Camera #${configuration.cameraId}...")
+  checkCameraPermission()
+
+  // Outputs
+  val useCases = listOfNotNull(previewOutput, photoOutput, videoOutput, frameProcessorOutput, codeScannerOutput)
+  if (useCases.isEmpty()) {
+    throw NoOutputsError()
+  }
+
+  // Input
+  val cameraId = configuration.cameraId ?: throw NoCameraDeviceError()
+  var cameraSelector = CameraSelector.Builder().byId(cameraId).build()
+
+  // Wrap input with a vendor extension if needed (see https://developer.android.com/media/camera/camera-extensions)
+  val isStreamingHDR = useCases.any { !it.currentConfig.dynamicRange.isSDR }
+  val needsImageAnalysis = codeScannerOutput != null || frameProcessorOutput != null
+  val photoOptions = configuration.photo as? CameraConfiguration.Output.Enabled<CameraConfiguration.Photo>
+  val enableHdrExtension = photoOptions != null && photoOptions.config.enableHdr
+  if (enableHdrExtension) {
+    if (isStreamingHDR) {
+      // extensions don't work if a camera stream is running at 10-bit HDR.
+      throw PhotoHdrAndVideoHdrNotSupportedSimultaneously()
+    }
+    // Load HDR Vendor extension (HDR only applies to image capture)
+    cameraSelector = cameraSelector.withExtension(context, provider, needsImageAnalysis, ExtensionMode.HDR, "HDR")
+  }
+  if (configuration.enableLowLightBoost) {
+    if (isStreamingHDR) {
+      // extensions don't work if a camera stream is running at 10-bit HDR.
+      throw LowLightBoostNotSupportedWithHdr()
+    }
+    if (enableHdrExtension) {
+      // low-light boost does not work when another HDR extension is already applied
+      throw LowLightBoostNotSupportedWithHdr()
+    }
+    // Load night mode Vendor extension (only applies to image capture)
+    cameraSelector = cameraSelector.withExtension(context, provider, needsImageAnalysis, ExtensionMode.NIGHT, "NIGHT")
+  }
+
+  // Unbind all currently bound use-cases before rebinding
+  if (currentUseCases.isNotEmpty()) {
+    Log.i(CameraSession.TAG, "Unbinding ${currentUseCases.size} use-cases for Camera #${camera?.cameraInfo?.id}...")
+    provider.unbind(*currentUseCases.toTypedArray())
+  }
+
+  // Bind it all together (must be on UI Thread)
+  Log.i(CameraSession.TAG, "Binding ${useCases.size} use-cases...")
+  camera = provider.bindToLifecycle(this, cameraSelector, *useCases.toTypedArray())
+  // Notify callback
+  callback.onInitialized()
+
+  // Update currentUseCases for next unbind
+  currentUseCases = useCases
+
+  // Listen to Camera events
+  var lastIsStreaming = false
+  camera!!.cameraInfo.cameraState.observe(this) { state ->
+    Log.i(CameraSession.TAG, "Camera State: ${state.type} (has error: ${state.error != null})")
+
+    val isStreaming = state.type == CameraState.Type.OPEN
+    if (isStreaming != lastIsStreaming) {
+      // Notify callback
+      if (isStreaming) {
+        callback.onStarted()
+      } else {
+        callback.onStopped()
+      }
+      lastIsStreaming = isStreaming
+    }
+
+    val error = state.error
+    if (error != null) {
+      // A Camera error occurred!
+      callback.onError(error.toCameraError())
+    }
+  }
+  Log.i(CameraSession.TAG, "Successfully bound Camera #${configuration.cameraId}!")
+}
+
+internal fun CameraSession.configureSideProps(config: CameraConfiguration) {
+  val camera = camera ?: throw CameraNotReadyError()
+
+  // Zoom
+  val currentZoom = camera.cameraInfo.zoomState.value?.zoomRatio
+  if (currentZoom != config.zoom) {
+    camera.cameraControl.setZoomRatio(config.zoom)
+  }
+
+  // Torch
+  val currentTorch = camera.cameraInfo.torchState.value == TorchState.ON
+  val newTorch = config.torch == Torch.ON
+  if (currentTorch != newTorch) {
+    if (newTorch && !camera.cameraInfo.hasFlashUnit()) {
+      throw FlashUnavailableError()
+    }
+    camera.cameraControl.enableTorch(newTorch)
+  }
+
+  // Exposure
+  val currentExposureCompensation = camera.cameraInfo.exposureState.exposureCompensationIndex
+  val exposureCompensation = config.exposure?.roundToInt() ?: 0
+  if (currentExposureCompensation != exposureCompensation) {
+    camera.cameraControl.setExposureCompensationIndex(exposureCompensation)
+  }
+}
+
+internal fun CameraSession.configureIsActive(config: CameraConfiguration) {
+  if (config.isActive) {
+    lifecycleRegistry.currentState = Lifecycle.State.STARTED
+    lifecycleRegistry.currentState = Lifecycle.State.RESUMED
+  } else {
+    lifecycleRegistry.currentState = Lifecycle.State.STARTED
+    lifecycleRegistry.currentState = Lifecycle.State.CREATED
+  }
+}
diff --git a/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/core/CameraSession+Focus.kt b/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/core/CameraSession+Focus.kt
new file mode 100644
index 0000000..a295fdc
--- /dev/null
+++ b/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/core/CameraSession+Focus.kt
@@ -0,0 +1,31 @@
+package com.mrousavy.camera.core
+
+import android.annotation.SuppressLint
+import android.util.Log
+import androidx.camera.core.CameraControl
+import androidx.camera.core.FocusMeteringAction
+import androidx.camera.core.MeteringPoint
+import com.mrousavy.camera.core.extensions.await
+
+@SuppressLint("RestrictedApi")
+suspend fun CameraSession.focus(meteringPoint: MeteringPoint) {
+  val camera = camera ?: throw CameraNotReadyError()
+
+  val action = FocusMeteringAction.Builder(meteringPoint).build()
+  if (!camera.cameraInfo.isFocusMeteringSupported(action)) {
+    throw FocusNotSupportedError()
+  }
+
+  try {
+    Log.i(CameraSession.TAG, "Focusing to ${action.meteringPointsAf.joinToString { "(${it.x}, ${it.y})" }}...")
+    val future = camera.cameraControl.startFocusAndMetering(action)
+    val result = future.await(CameraQueues.cameraExecutor)
+    if (result.isFocusSuccessful) {
+      Log.i(CameraSession.TAG, "Focused successfully!")
+    } else {
+      Log.i(CameraSession.TAG, "Focus failed.")
+    }
+  } catch (e: CameraControl.OperationCanceledException) {
+    throw FocusCanceledError()
+  }
+}
diff --git a/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/core/CameraSession+Photo.kt b/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/core/CameraSession+Photo.kt
new file mode 100644
index 0000000..6ef88b2
--- /dev/null
+++ b/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/core/CameraSession+Photo.kt
@@ -0,0 +1,45 @@
+package com.mrousavy.camera.core
+
+import android.media.AudioManager
+import com.mrousavy.camera.core.extensions.takePicture
+import com.mrousavy.camera.core.types.Flash
+import com.mrousavy.camera.core.types.Orientation
+import com.mrousavy.camera.core.types.TakePhotoOptions
+import com.mrousavy.camera.core.utils.FileUtils
+
+suspend fun CameraSession.takePhoto(options: TakePhotoOptions): Photo {
+  val camera = camera ?: throw CameraNotReadyError()
+  val configuration = configuration ?: throw CameraNotReadyError()
+  val photoConfig = configuration.photo as? CameraConfiguration.Output.Enabled<CameraConfiguration.Photo> ?: throw PhotoNotEnabledError()
+  val photoOutput = photoOutput ?: throw PhotoNotEnabledError()
+
+  // Flash
+  if (options.flash != Flash.OFF && !camera.cameraInfo.hasFlashUnit()) {
+    throw FlashUnavailableError()
+  }
+  photoOutput.flashMode = options.flash.toFlashMode()
+  // Shutter sound
+  val enableShutterSound = options.enableShutterSound && !audioManager.isSilent
+  // isMirrored (EXIF)
+  val isMirrored = photoConfig.config.isMirrored
+
+  // Shoot photo!
+  val photoFile = photoOutput.takePicture(
+    options.file.file,
+    isMirrored,
+    enableShutterSound,
+    metadataProvider,
+    callback,
+    CameraQueues.cameraExecutor
+  )
+
+  // Parse resulting photo (EXIF data)
+  val size = FileUtils.getImageSize(photoFile.uri.path)
+  val rotation = photoOutput.targetRotation
+  val orientation = Orientation.fromSurfaceRotation(rotation)
+
+  return Photo(photoFile.uri.path, size.width, size.height, orientation, isMirrored)
+}
+
+private val AudioManager.isSilent: Boolean
+  get() = ringerMode != AudioManager.RINGER_MODE_NORMAL
diff --git a/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/core/CameraSession+Video.kt b/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/core/CameraSession+Video.kt
new file mode 100644
index 0000000..fcc54b8
--- /dev/null
+++ b/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/core/CameraSession+Video.kt
@@ -0,0 +1,110 @@
+package com.mrousavy.camera.core
+
+import android.annotation.SuppressLint
+import android.util.Log
+import android.util.Size
+import androidx.annotation.OptIn
+import androidx.camera.video.ExperimentalPersistentRecording
+import androidx.camera.video.FileOutputOptions
+import androidx.camera.video.VideoRecordEvent
+import com.mrousavy.camera.core.extensions.getCameraError
+import com.mrousavy.camera.core.types.RecordVideoOptions
+import com.mrousavy.camera.core.types.Video
+
+@OptIn(ExperimentalPersistentRecording::class)
+@SuppressLint("MissingPermission", "RestrictedApi")
+fun CameraSession.startRecording(
+  enableAudio: Boolean,
+  options: RecordVideoOptions,
+  callback: (video: Video) -> Unit,
+  onError: (error: CameraError) -> Unit
+) {
+  if (camera == null) throw CameraNotReadyError()
+  if (recording != null) throw RecordingInProgressError()
+  val videoOutput = videoOutput ?: throw VideoNotEnabledError()
+
+  // Create output video file
+  val outputOptions = FileOutputOptions.Builder(options.file.file).also { outputOptions ->
+    metadataProvider.location?.let { location ->
+      Log.i(CameraSession.TAG, "Setting Video Location to ${location.latitude}, ${location.longitude}...")
+      outputOptions.setLocation(location)
+    }
+  }.build()
+
+  // TODO: Move this to JS so users can prepare recordings earlier
+  // Prepare recording
+  var pendingRecording = videoOutput.output.prepareRecording(context, outputOptions)
+  if (enableAudio) {
+    checkMicrophonePermission()
+    pendingRecording = pendingRecording.withAudioEnabled()
+  }
+  pendingRecording = pendingRecording.asPersistentRecording()
+
+  isRecordingCanceled = false
+  recording = pendingRecording.start(CameraQueues.cameraExecutor) { event ->
+    when (event) {
+      is VideoRecordEvent.Start -> Log.i(CameraSession.TAG, "Recording started!")
+
+      is VideoRecordEvent.Resume -> Log.i(CameraSession.TAG, "Recording resumed!")
+
+      is VideoRecordEvent.Pause -> Log.i(CameraSession.TAG, "Recording paused!")
+
+      is VideoRecordEvent.Status -> Log.i(CameraSession.TAG, "Status update! Recorded ${event.recordingStats.numBytesRecorded} bytes.")
+
+      is VideoRecordEvent.Finalize -> {
+        if (isRecordingCanceled) {
+          Log.i(CameraSession.TAG, "Recording was canceled, deleting file..")
+          onError(RecordingCanceledError())
+          try {
+            options.file.file.delete()
+          } catch (e: Throwable) {
+            this.callback.onError(FileIOError(e))
+          }
+          return@start
+        }
+
+        Log.i(CameraSession.TAG, "Recording stopped!")
+        val error = event.getCameraError()
+        if (error != null) {
+          if (error.wasVideoRecorded) {
+            Log.e(CameraSession.TAG, "Video Recorder encountered an error, but the video was recorded anyways.", error)
+          } else {
+            Log.e(CameraSession.TAG, "Video Recorder encountered a fatal error!", error)
+            onError(error)
+            return@start
+          }
+        }
+
+        // Prepare output result
+        val durationMs = event.recordingStats.recordedDurationNanos / 1_000_000
+        Log.i(CameraSession.TAG, "Successfully completed video recording! Captured ${durationMs.toDouble() / 1_000.0} seconds.")
+        val path = event.outputResults.outputUri.path ?: throw UnknownRecorderError(false, null)
+        val size = videoOutput.attachedSurfaceResolution ?: Size(0, 0)
+        val video = Video(path, durationMs, size)
+        callback(video)
+      }
+    }
+  }
+}
+
+fun CameraSession.stopRecording() {
+  val recording = recording ?: throw NoRecordingInProgressError()
+
+  recording.stop()
+  this.recording = null
+}
+
+fun CameraSession.cancelRecording() {
+  isRecordingCanceled = true
+  stopRecording()
+}
+
+fun CameraSession.pauseRecording() {
+  val recording = recording ?: throw NoRecordingInProgressError()
+  recording.pause()
+}
+
+fun CameraSession.resumeRecording() {
+  val recording = recording ?: throw NoRecordingInProgressError()
+  recording.resume()
+}
diff --git a/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/core/CameraSession.kt b/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/core/CameraSession.kt
new file mode 100644
index 0000000..13f6a76
--- /dev/null
+++ b/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/core/CameraSession.kt
@@ -0,0 +1,225 @@
+package com.mrousavy.camera.core
+
+import android.Manifest
+import android.content.Context
+import android.content.pm.PackageManager
+import android.media.AudioManager
+import android.util.Log
+import androidx.annotation.MainThread
+import androidx.camera.core.Camera
+import androidx.camera.core.ImageAnalysis
+import androidx.camera.core.ImageCapture
+import androidx.camera.core.Preview
+import androidx.camera.core.UseCase
+import androidx.camera.lifecycle.ProcessCameraProvider
+import androidx.camera.video.Recorder
+import androidx.camera.video.Recording
+import androidx.camera.video.VideoCapture
+import androidx.core.content.ContextCompat
+import androidx.lifecycle.Lifecycle
+import androidx.lifecycle.LifecycleEventObserver
+import androidx.lifecycle.LifecycleOwner
+import androidx.lifecycle.LifecycleRegistry
+import com.facebook.react.bridge.UiThreadUtil
+import com.google.mlkit.vision.barcode.common.Barcode
+import com.mrousavy.camera.core.extensions.await
+import com.mrousavy.camera.core.types.Orientation
+import com.mrousavy.camera.core.types.ShutterType
+import com.mrousavy.camera.core.utils.runOnUiThread
+import com.mrousavy.camera.frameprocessors.Frame
+import java.io.Closeable
+import kotlinx.coroutines.sync.Mutex
+import kotlinx.coroutines.sync.withLock
+
+class CameraSession(internal val context: Context, internal val callback: Callback) :
+  Closeable,
+  LifecycleOwner,
+  OrientationManager.Callback {
+  companion object {
+    internal const val TAG = "CameraSession"
+  }
+
+  // Camera Configuration
+  internal var configuration: CameraConfiguration? = null
+  internal val cameraProvider = ProcessCameraProvider.getInstance(context)
+  internal var camera: Camera? = null
+
+  // Camera Outputs
+  internal var previewOutput: Preview? = null
+  internal var photoOutput: ImageCapture? = null
+  internal var videoOutput: VideoCapture<Recorder>? = null
+  internal var frameProcessorOutput: ImageAnalysis? = null
+  internal var codeScannerOutput: ImageAnalysis? = null
+  internal var currentUseCases: List<UseCase> = emptyList()
+
+  // Camera Outputs State
+  internal val metadataProvider = MetadataProvider(context)
+  internal val orientationManager = OrientationManager(context, this)
+  internal var recorderOutput: Recorder? = null
+
+  // Camera State
+  internal val mutex = Mutex()
+  internal var isDestroyed = false
+  internal val lifecycleRegistry = LifecycleRegistry(this)
+  internal var recording: Recording? = null
+  internal var isRecordingCanceled = false
+  internal val audioManager = context.getSystemService(Context.AUDIO_SERVICE) as AudioManager
+
+  // Threading
+  internal val mainExecutor = ContextCompat.getMainExecutor(context)
+
+  // Orientation
+  val outputOrientation: Orientation
+    get() = orientationManager.outputOrientation
+
+  init {
+    lifecycleRegistry.currentState = Lifecycle.State.CREATED
+    lifecycle.addObserver(object : LifecycleEventObserver {
+      override fun onStateChanged(source: LifecycleOwner, event: Lifecycle.Event) {
+        Log.i(TAG, "Camera Lifecycle changed to ${event.targetState}!")
+      }
+    })
+  }
+
+  override fun close() {
+    Log.i(TAG, "Closing CameraSession...")
+    isDestroyed = true
+    orientationManager.stopOrientationUpdates()
+    runOnUiThread {
+      lifecycleRegistry.currentState = Lifecycle.State.DESTROYED
+    }
+  }
+
+  override val lifecycle: Lifecycle
+    get() = lifecycleRegistry
+
+  /**
+   * Configures the [CameraSession] with new values in one batch.
+   * This must be called from the Main UI Thread.
+   */
+  @MainThread
+  suspend fun configure(lambda: (configuration: CameraConfiguration) -> Unit) {
+    if (!UiThreadUtil.isOnUiThread()) {
+      throw Error("configure { ... } must be called from the Main UI Thread!")
+    }
+    Log.i(TAG, "configure { ... }: Waiting for lock...")
+
+    val provider = try {
+      cameraProvider.await(mainExecutor)
+    } catch (error: Throwable) {
+      Log.e(TAG, "Failed to get CameraProvider! Error: ${error.message}", error)
+      callback.onError(error)
+      return
+    }
+
+    mutex.withLock {
+      // Let caller configure a new configuration for the Camera.
+      val config = CameraConfiguration.copyOf(this.configuration)
+      try {
+        lambda(config)
+      } catch (e: CameraConfiguration.AbortThrow) {
+        // config changes have been aborted.
+        return
+      }
+      val diff = CameraConfiguration.difference(this.configuration, config)
+      this.configuration = config
+
+      if (!diff.hasChanges) {
+        Log.i(TAG, "Nothing changed, aborting configure { ... }")
+        return@withLock
+      }
+
+      if (isDestroyed) {
+        Log.i(TAG, "CameraSession is already destroyed. Skipping configure { ... }")
+        return@withLock
+      }
+
+      Log.i(TAG, "configure { ... }: Updating CameraSession Configuration... $diff")
+
+      try {
+        // Build up session or update any props
+        if (diff.outputsChanged) {
+          // 1. outputs changed, re-create them
+          configureOutputs(config)
+          // 1.1. whenever the outputs changed, we need to update their orientation as well
+          configureOrientation()
+        }
+        if (diff.deviceChanged) {
+          // 2. input or outputs changed, or the session was destroyed from outside, rebind the session
+          configureCamera(provider, config)
+        }
+        if (diff.sidePropsChanged) {
+          // 3. side props such as zoom, exposure or torch changed.
+          configureSideProps(config)
+        }
+        if (diff.isActiveChanged) {
+          // 4. start or stop the session
+          configureIsActive(config)
+        }
+        if (diff.orientationChanged) {
+          // 5. update the target orientation mode
+          orientationManager.setTargetOutputOrientation(config.outputOrientation)
+        }
+        if (diff.locationChanged) {
+          // 6. start or stop location update streaming
+          metadataProvider.enableLocationUpdates(config.enableLocation)
+        }
+
+        Log.i(
+          TAG,
+          "configure { ... }: Completed CameraSession Configuration! (State: ${lifecycle.currentState})"
+        )
+      } catch (error: Throwable) {
+        Log.e(TAG, "Failed to configure CameraSession! Error: ${error.message}, Config-Diff: $diff", error)
+        callback.onError(error)
+      }
+    }
+  }
+
+  internal fun checkCameraPermission() {
+    val status = ContextCompat.checkSelfPermission(context, Manifest.permission.CAMERA)
+    if (status != PackageManager.PERMISSION_GRANTED) throw CameraPermissionError()
+  }
+  internal fun checkMicrophonePermission() {
+    val status = ContextCompat.checkSelfPermission(context, Manifest.permission.RECORD_AUDIO)
+    if (status != PackageManager.PERMISSION_GRANTED) throw MicrophonePermissionError()
+  }
+
+  override fun onOutputOrientationChanged(outputOrientation: Orientation) {
+    Log.i(TAG, "Output orientation changed! $outputOrientation")
+    configureOrientation()
+    callback.onOutputOrientationChanged(outputOrientation)
+  }
+
+  override fun onPreviewOrientationChanged(previewOrientation: Orientation) {
+    Log.i(TAG, "Preview orientation changed! $previewOrientation")
+    configureOrientation()
+    callback.onPreviewOrientationChanged(previewOrientation)
+  }
+
+  private fun configureOrientation() {
+    // Preview Orientation
+    orientationManager.previewOrientation.toSurfaceRotation().let { previewRotation ->
+      previewOutput?.targetRotation = previewRotation
+      codeScannerOutput?.targetRotation = previewRotation
+    }
+    // Outputs Orientation
+    orientationManager.outputOrientation.toSurfaceRotation().let { outputRotation ->
+      photoOutput?.targetRotation = outputRotation
+      videoOutput?.targetRotation = outputRotation
+    }
+    // Frame Processor output will not receive a target rotation, user is responsible for rotating himself
+  }
+
+  interface Callback {
+    fun onError(error: Throwable)
+    fun onFrame(frame: Frame)
+    fun onInitialized()
+    fun onStarted()
+    fun onStopped()
+    fun onShutter(type: ShutterType)
+    fun onOutputOrientationChanged(outputOrientation: Orientation)
+    fun onPreviewOrientationChanged(previewOrientation: Orientation)
+    fun onCodeScanned(codes: List<Barcode>, scannerFrame: CodeScannerFrame)
+  }
+}
diff --git a/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/core/CodeScannerFrame.kt b/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/core/CodeScannerFrame.kt
new file mode 100644
index 0000000..8cea9f2
--- /dev/null
+++ b/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/core/CodeScannerFrame.kt
@@ -0,0 +1,3 @@
+package com.mrousavy.camera.core
+
+data class CodeScannerFrame(val width: Int, val height: Int)
diff --git a/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/core/CodeScannerPipeline.kt b/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/core/CodeScannerPipeline.kt
new file mode 100644
index 0000000..23d78d1
--- /dev/null
+++ b/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/core/CodeScannerPipeline.kt
@@ -0,0 +1,58 @@
+package com.mrousavy.camera.core
+
+import android.util.Log
+import androidx.annotation.OptIn
+import androidx.camera.core.ExperimentalGetImage
+import androidx.camera.core.ImageAnalysis.Analyzer
+import androidx.camera.core.ImageProxy
+import com.google.mlkit.vision.barcode.BarcodeScanner
+import com.google.mlkit.vision.barcode.BarcodeScannerOptions
+import com.google.mlkit.vision.barcode.BarcodeScanning
+import com.google.mlkit.vision.common.InputImage
+import java.io.Closeable
+
+class CodeScannerPipeline(val configuration: CameraConfiguration.CodeScanner, val callback: CameraSession.Callback) :
+  Closeable,
+  Analyzer {
+  companion object {
+    private const val TAG = "CodeScannerPipeline"
+  }
+  private val scanner: BarcodeScanner
+
+  init {
+    val types = configuration.codeTypes.map { it.toBarcodeType() }
+    val barcodeScannerOptions = BarcodeScannerOptions.Builder()
+      .setBarcodeFormats(types[0], *types.toIntArray())
+      .build()
+    scanner = BarcodeScanning.getClient(barcodeScannerOptions)
+  }
+
+  @OptIn(ExperimentalGetImage::class)
+  override fun analyze(imageProxy: ImageProxy) {
+    val image = imageProxy.image ?: throw InvalidImageTypeError()
+
+    try {
+      val inputImage = InputImage.fromMediaImage(image, imageProxy.imageInfo.rotationDegrees)
+      scanner.process(inputImage)
+        .addOnSuccessListener { barcodes ->
+          if (barcodes.isNotEmpty()) {
+            callback.onCodeScanned(barcodes, CodeScannerFrame(inputImage.width, inputImage.height))
+          }
+        }
+        .addOnFailureListener { error ->
+          Log.e(TAG, "Failed to process Image!", error)
+          callback.onError(error)
+        }
+        .addOnCompleteListener {
+          imageProxy.close()
+        }
+    } catch (e: Throwable) {
+      Log.e(TAG, "Failed to process Image!", e)
+      imageProxy.close()
+    }
+  }
+
+  override fun close() {
+    scanner.close()
+  }
+}
diff --git a/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/core/FrameProcessorPipeline.kt b/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/core/FrameProcessorPipeline.kt
new file mode 100644
index 0000000..fe58bfb
--- /dev/null
+++ b/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/core/FrameProcessorPipeline.kt
@@ -0,0 +1,20 @@
+package com.mrousavy.camera.core
+
+import androidx.annotation.OptIn
+import androidx.camera.core.ExperimentalGetImage
+import androidx.camera.core.ImageAnalysis.Analyzer
+import androidx.camera.core.ImageProxy
+import com.mrousavy.camera.frameprocessors.Frame
+
+class FrameProcessorPipeline(private val callback: CameraSession.Callback) : Analyzer {
+  @OptIn(ExperimentalGetImage::class)
+  override fun analyze(imageProxy: ImageProxy) {
+    val frame = Frame(imageProxy)
+    try {
+      frame.incrementRefCount()
+      callback.onFrame(frame)
+    } finally {
+      frame.decrementRefCount()
+    }
+  }
+}
diff --git a/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/core/MetadataProvider.kt b/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/core/MetadataProvider.kt
new file mode 100644
index 0000000..db98780
--- /dev/null
+++ b/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/core/MetadataProvider.kt
@@ -0,0 +1,69 @@
+package com.mrousavy.camera.core
+
+import android.Manifest
+import android.annotation.SuppressLint
+import android.content.Context
+import android.content.pm.PackageManager
+import android.location.Location
+import android.location.LocationListener
+import android.location.LocationManager
+import android.os.Bundle
+import android.util.Log
+import androidx.core.content.ContextCompat
+
+class MetadataProvider(val context: Context) : LocationListener {
+  private val locationManager = context.getSystemService(Context.LOCATION_SERVICE) as LocationManager
+  companion object {
+    private const val TAG = "MetadataProvider"
+    private const val UPDATE_INTERVAL_MS = 5000L
+    private const val UPDATE_DISTANCE_M = 5f
+  }
+
+  private val hasLocationPermission: Boolean
+    get() {
+      val fineLocationStatus = ContextCompat.checkSelfPermission(context, Manifest.permission.ACCESS_FINE_LOCATION)
+      val coarseLocationStatus = ContextCompat.checkSelfPermission(context, Manifest.permission.ACCESS_COARSE_LOCATION)
+      return fineLocationStatus == PackageManager.PERMISSION_GRANTED || coarseLocationStatus == PackageManager.PERMISSION_GRANTED
+    }
+  var location: Location? = null
+    private set
+
+  @SuppressLint("MissingPermission")
+  fun enableLocationUpdates(enable: Boolean) {
+    if (enable) {
+      if (!hasLocationPermission) {
+        throw LocationPermissionError()
+      }
+
+      Log.i(TAG, "Start updating location...")
+      locationManager.requestLocationUpdates(LocationManager.GPS_PROVIDER, UPDATE_INTERVAL_MS, UPDATE_DISTANCE_M, this)
+      this.location = locationManager.getLastKnownLocation(LocationManager.GPS_PROVIDER)
+
+      if (this.location == null) {
+        // Request the current location if lastKnownLocation is null
+        locationManager.requestSingleUpdate(LocationManager.GPS_PROVIDER, this, null)
+      }
+    } else {
+      Log.i(TAG, "Stopping location updates...")
+      locationManager.removeUpdates(this)
+    }
+  }
+
+  override fun onLocationChanged(location: Location) {
+    Log.i(TAG, "Location updated: ${location.latitude}, ${location.longitude}")
+    this.location = location
+  }
+
+  override fun onProviderDisabled(provider: String) {
+    Log.i(TAG, "Location Provider $provider has been disabled.")
+  }
+
+  override fun onProviderEnabled(provider: String) {
+    Log.i(TAG, "Location Provider $provider has been enabled.")
+  }
+
+  @Deprecated("Deprecated in Java", ReplaceWith("", ""))
+  override fun onStatusChanged(provider: String?, status: Int, extras: Bundle?) {
+    Log.i(TAG, "Location Provider $provider status changed: $status")
+  }
+}
diff --git a/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/core/OrientationManager.kt b/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/core/OrientationManager.kt
new file mode 100644
index 0000000..5326d6b
--- /dev/null
+++ b/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/core/OrientationManager.kt
@@ -0,0 +1,112 @@
+package com.mrousavy.camera.core
+
+import android.content.Context
+import android.hardware.display.DisplayManager
+import android.util.Log
+import android.view.OrientationEventListener
+import android.view.Surface
+import com.mrousavy.camera.core.types.Orientation
+import com.mrousavy.camera.core.types.OutputOrientation
+
+class OrientationManager(private val context: Context, private val callback: Callback) {
+  companion object {
+    private const val TAG = "OrientationManager"
+  }
+
+  private var targetOutputOrientation = OutputOrientation.DEVICE
+  private var lastOutputOrientation: Orientation? = null
+  private var lastPreviewOrientation: Orientation? = null
+
+  // Screen Orientation Listener
+  private var screenRotation = Surface.ROTATION_0
+  private val displayManager = context.getSystemService(Context.DISPLAY_SERVICE) as DisplayManager
+  private val displayListener = object : DisplayManager.DisplayListener {
+    override fun onDisplayAdded(displayId: Int) = Unit
+    override fun onDisplayRemoved(displayId: Int) = Unit
+    override fun onDisplayChanged(displayId: Int) {
+      // Display rotated!
+      val display = displayManager.getDisplay(displayId) ?: return
+      screenRotation = display.rotation
+      maybeNotifyOrientationChanged()
+    }
+  }
+
+  // Physical Device Orientation listener
+  private var deviceRotation = Surface.ROTATION_0
+  private val orientationListener = object : OrientationEventListener(context) {
+    override fun onOrientationChanged(rotationDegrees: Int) {
+      // Phone rotated!
+      if (rotationDegrees == OrientationEventListener.ORIENTATION_UNKNOWN) {
+        // phone is laying flat - orientation is unknown! Avoid sending out event.
+        return
+      }
+      deviceRotation = degreesToSurfaceRotation(rotationDegrees)
+      maybeNotifyOrientationChanged()
+    }
+  }
+
+  // Get the current preview orientation (computed by the screen's orientation)
+  val previewOrientation: Orientation
+    get() = Orientation.fromSurfaceRotation(screenRotation)
+
+  // Get the current output orientation (a computed value)
+  val outputOrientation: Orientation
+    get() {
+      return when (targetOutputOrientation) {
+        OutputOrientation.DEVICE -> Orientation.fromSurfaceRotation(deviceRotation)
+        OutputOrientation.PREVIEW -> previewOrientation
+      }
+    }
+
+  private fun maybeNotifyOrientationChanged() {
+    val newPreviewOrientation = previewOrientation
+    if (lastPreviewOrientation != newPreviewOrientation) {
+      callback.onPreviewOrientationChanged(newPreviewOrientation)
+      lastPreviewOrientation = newPreviewOrientation
+    }
+    val newOutputOrientation = outputOrientation
+    if (lastOutputOrientation != newOutputOrientation) {
+      callback.onOutputOrientationChanged(newOutputOrientation)
+      lastOutputOrientation = newOutputOrientation
+    }
+  }
+
+  fun stopOrientationUpdates() {
+    displayManager.unregisterDisplayListener(displayListener)
+    orientationListener.disable()
+  }
+
+  fun setTargetOutputOrientation(targetOrientation: OutputOrientation) {
+    Log.i(TAG, "Target Orientation changed $targetOutputOrientation -> $targetOrientation!")
+    targetOutputOrientation = targetOrientation
+
+    // remove previous listeners if we have any
+    stopOrientationUpdates()
+
+    when (targetOrientation) {
+      OutputOrientation.DEVICE -> {
+        Log.i(TAG, "Starting streaming device and screen orientation updates...")
+        orientationListener.enable()
+        displayManager.registerDisplayListener(displayListener, null)
+      }
+
+      OutputOrientation.PREVIEW -> {
+        Log.i(TAG, "Starting streaming device and screen orientation updates...")
+        displayManager.registerDisplayListener(displayListener, null)
+      }
+    }
+  }
+
+  private fun degreesToSurfaceRotation(degrees: Int): Int =
+    when (degrees) {
+      in 45..135 -> Surface.ROTATION_270
+      in 135..225 -> Surface.ROTATION_180
+      in 225..315 -> Surface.ROTATION_90
+      else -> Surface.ROTATION_0
+    }
+
+  interface Callback {
+    fun onOutputOrientationChanged(outputOrientation: Orientation)
+    fun onPreviewOrientationChanged(previewOrientation: Orientation)
+  }
+}
diff --git a/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/core/Photo.kt b/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/core/Photo.kt
new file mode 100644
index 0000000..b1353ce
--- /dev/null
+++ b/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/core/Photo.kt
@@ -0,0 +1,5 @@
+package com.mrousavy.camera.core
+
+import com.mrousavy.camera.core.types.Orientation
+
+data class Photo(val path: String, val width: Int, val height: Int, val orientation: Orientation, val isMirrored: Boolean)
diff --git a/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/core/extensions/CameraInfo+id.kt b/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/core/extensions/CameraInfo+id.kt
new file mode 100644
index 0000000..30d7131
--- /dev/null
+++ b/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/core/extensions/CameraInfo+id.kt
@@ -0,0 +1,15 @@
+package com.mrousavy.camera.core.extensions
+
+import android.annotation.SuppressLint
+import androidx.camera.core.CameraInfo
+import androidx.camera.core.impl.CameraInfoInternal
+
+val CameraInfo.id: String?
+  @SuppressLint("RestrictedApi")
+  get() {
+    val infoInternal = this as? CameraInfoInternal
+    if (infoInternal != null) {
+      return infoInternal.cameraId
+    }
+    return null
+  }
diff --git a/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/core/extensions/CameraSelector+byId.kt b/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/core/extensions/CameraSelector+byId.kt
new file mode 100644
index 0000000..95ee022
--- /dev/null
+++ b/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/core/extensions/CameraSelector+byId.kt
@@ -0,0 +1,8 @@
+package com.mrousavy.camera.core.extensions
+
+import androidx.camera.core.CameraSelector
+
+fun CameraSelector.Builder.byId(id: String): CameraSelector.Builder =
+  addCameraFilter { cameraInfos ->
+    cameraInfos.filter { it.id == id }.toMutableList()
+  }
diff --git a/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/core/extensions/CameraSelector+withExtension.kt b/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/core/extensions/CameraSelector+withExtension.kt
new file mode 100644
index 0000000..4d3fd56
--- /dev/null
+++ b/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/core/extensions/CameraSelector+withExtension.kt
@@ -0,0 +1,38 @@
+package com.mrousavy.camera.core.extensions
+
+import android.content.Context
+import android.util.Log
+import androidx.camera.core.CameraSelector
+import androidx.camera.extensions.ExtensionsManager
+import androidx.camera.lifecycle.ProcessCameraProvider
+import androidx.core.content.ContextCompat
+
+private const val TAG = "CameraSelector"
+
+suspend fun CameraSelector.withExtension(
+  context: Context,
+  provider: ProcessCameraProvider,
+  needsImageAnalysis: Boolean,
+  extension: Int,
+  extensionDebugName: String
+): CameraSelector {
+  Log.i(TAG, "$extensionDebugName is enabled, looking up vendor $extensionDebugName extension...")
+
+  val mainExecutor = ContextCompat.getMainExecutor(context)
+  val extensionsManager = ExtensionsManager.getInstanceAsync(context, provider).await(mainExecutor)
+
+  if (extensionsManager.isExtensionAvailable(this, extension)) {
+    if (needsImageAnalysis && !extensionsManager.isImageAnalysisSupported(this, extension)) {
+      Log.i(
+        TAG,
+        "Device supports a $extensionDebugName vendor extension, but we cannot use it since we need ImageAnalysis " +
+          "and this extension does not work with ImageAnalysis use-cases."
+      )
+      return this
+    }
+
+    Log.i(TAG, "Device supports a $extensionDebugName vendor extension! Enabling...")
+    return extensionsManager.getExtensionEnabledCameraSelector(this, extension)
+  }
+  return this
+}
diff --git a/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/core/extensions/DynamicRange+isSDR.kt b/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/core/extensions/DynamicRange+isSDR.kt
new file mode 100644
index 0000000..0cf19ed
--- /dev/null
+++ b/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/core/extensions/DynamicRange+isSDR.kt
@@ -0,0 +1,6 @@
+package com.mrousavy.camera.core.extensions
+
+import androidx.camera.core.DynamicRange
+
+val DynamicRange.isSDR: Boolean
+  get() = encoding == DynamicRange.ENCODING_SDR || encoding == DynamicRange.ENCODING_UNSPECIFIED
diff --git a/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/core/extensions/ImageAnalysis.Builder+setTargetFrameRate.kt b/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/core/extensions/ImageAnalysis.Builder+setTargetFrameRate.kt
new file mode 100644
index 0000000..a905eb5
--- /dev/null
+++ b/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/core/extensions/ImageAnalysis.Builder+setTargetFrameRate.kt
@@ -0,0 +1,17 @@
+package com.mrousavy.camera.core.extensions
+
+import android.hardware.camera2.CaptureRequest
+import android.util.Range
+import androidx.annotation.OptIn
+import androidx.camera.camera2.interop.Camera2Interop
+import androidx.camera.camera2.interop.ExperimentalCamera2Interop
+import androidx.camera.core.ImageAnalysis
+
+@OptIn(ExperimentalCamera2Interop::class)
+fun ImageAnalysis.Builder.setTargetFrameRate(frameRate: Range<Int>) {
+  val camera2Interop = Camera2Interop.Extender(this)
+  camera2Interop.setCaptureRequestOption(
+    CaptureRequest.CONTROL_AE_TARGET_FPS_RANGE,
+    frameRate
+  )
+}
diff --git a/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/core/extensions/ImageCapture+takePicture.kt b/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/core/extensions/ImageCapture+takePicture.kt
new file mode 100644
index 0000000..a5f8957
--- /dev/null
+++ b/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/core/extensions/ImageCapture+takePicture.kt
@@ -0,0 +1,76 @@
+package com.mrousavy.camera.core.extensions
+
+import android.annotation.SuppressLint
+import android.media.MediaActionSound
+import android.util.Log
+import androidx.camera.core.ImageCapture
+import androidx.camera.core.ImageCapture.OutputFileOptions
+import androidx.camera.core.ImageCaptureException
+import com.mrousavy.camera.core.CameraSession
+import com.mrousavy.camera.core.MetadataProvider
+import com.mrousavy.camera.core.types.ShutterType
+import java.io.File
+import java.net.URI
+import java.util.concurrent.Executor
+import kotlin.coroutines.resume
+import kotlin.coroutines.resumeWithException
+import kotlinx.coroutines.suspendCancellableCoroutine
+
+data class PhotoFileInfo(val uri: URI, val metadata: ImageCapture.Metadata)
+
+@SuppressLint("RestrictedApi")
+suspend inline fun ImageCapture.takePicture(
+  file: File,
+  isMirrored: Boolean,
+  enableShutterSound: Boolean,
+  metadataProvider: MetadataProvider,
+  callback: CameraSession.Callback,
+  executor: Executor
+): PhotoFileInfo =
+  suspendCancellableCoroutine { continuation ->
+    // Shutter sound
+    val shutterSound = if (enableShutterSound) MediaActionSound() else null
+    shutterSound?.load(MediaActionSound.SHUTTER_CLICK)
+
+    // Create output file
+    val outputFileOptionsBuilder = OutputFileOptions.Builder(file).also { options ->
+      val metadata = ImageCapture.Metadata()
+      metadataProvider.location?.let { location ->
+        Log.i("ImageCapture", "Setting Photo Location to ${location.latitude}, ${location.longitude}...")
+        metadata.location = metadataProvider.location
+      }
+      metadata.isReversedHorizontal = isMirrored
+      options.setMetadata(metadata)
+    }
+    val outputFileOptions = outputFileOptionsBuilder.build()
+
+    // Take a photo with callbacks
+    takePicture(
+      outputFileOptions,
+      executor,
+      object : ImageCapture.OnImageSavedCallback {
+        override fun onCaptureStarted() {
+          super.onCaptureStarted()
+          if (enableShutterSound) {
+            shutterSound?.play(MediaActionSound.SHUTTER_CLICK)
+          }
+
+          callback.onShutter(ShutterType.PHOTO)
+        }
+
+        @SuppressLint("RestrictedApi")
+        override fun onImageSaved(outputFileResults: ImageCapture.OutputFileResults) {
+          if (continuation.isActive) {
+            val info = PhotoFileInfo(file.toURI(), outputFileOptions.metadata)
+            continuation.resume(info)
+          }
+        }
+
+        override fun onError(exception: ImageCaptureException) {
+          if (continuation.isActive) {
+            continuation.resumeWithException(exception)
+          }
+        }
+      }
+    )
+  }
diff --git a/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/core/extensions/ListenableFuture+await.kt b/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/core/extensions/ListenableFuture+await.kt
new file mode 100644
index 0000000..b03b26d
--- /dev/null
+++ b/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/core/extensions/ListenableFuture+await.kt
@@ -0,0 +1,33 @@
+package com.mrousavy.camera.core.extensions
+
+import com.google.common.util.concurrent.ListenableFuture
+import java.util.concurrent.ExecutionException
+import java.util.concurrent.Executor
+import kotlin.coroutines.cancellation.CancellationException
+import kotlin.coroutines.resume
+import kotlin.coroutines.resumeWithException
+import kotlin.coroutines.suspendCoroutine
+import kotlinx.coroutines.Dispatchers
+import kotlinx.coroutines.asExecutor
+import kotlinx.coroutines.isActive
+
+suspend fun <V> ListenableFuture<V>.await(executor: Executor? = null): V {
+  if (this.isCancelled) throw CancellationException("ListenableFuture<V> has been canceled!")
+  if (this.isDone) return this.get()
+
+  return suspendCoroutine { continuation ->
+    this.addListener({
+      if (this.isCancelled || !continuation.context.isActive) throw CancellationException("ListenableFuture<V> has been canceled!")
+      try {
+        continuation.resume(this.get())
+      } catch (e: ExecutionException) {
+        val cause = e.cause
+        if (cause != null) {
+          continuation.resumeWithException(cause)
+        } else {
+          throw e
+        }
+      }
+    }, executor ?: Dispatchers.Main.asExecutor())
+  }
+}
diff --git a/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/core/extensions/ResolutionSelector+forSize.kt b/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/core/extensions/ResolutionSelector+forSize.kt
new file mode 100644
index 0000000..5d29c67
--- /dev/null
+++ b/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/core/extensions/ResolutionSelector+forSize.kt
@@ -0,0 +1,20 @@
+package com.mrousavy.camera.core.extensions
+
+import android.util.Size
+import androidx.camera.core.resolutionselector.ResolutionSelector
+import kotlin.math.abs
+
+private fun sizeDifference(left: Size, right: Size): Int = abs(left.width * left.height - right.width * right.height)
+private fun aspectRatioDifference(left: Size, right: Size): Float = abs(left.aspectRatio - right.aspectRatio)
+
+/**
+ * Gets a [ResolutionSelector] that finds a resolution closest to the given target size.
+ * There will always be a size available, but it is not guaranteed that it will be exactly the target size.
+ * It is also possible that the resolved size is larger than the target size.
+ * The given target size's aspect ratio will have priority over sizes with a similar number of total pixels.
+ */
+fun ResolutionSelector.Builder.forSize(size: Size): ResolutionSelector.Builder {
+  return this.setResolutionFilter { supportedSizes, _ ->
+    return@setResolutionFilter supportedSizes.sortedWith(compareBy({ aspectRatioDifference(it, size) }, { sizeDifference(it, size) }))
+  }
+}
diff --git a/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/core/extensions/Size+aspectRatio.kt b/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/core/extensions/Size+aspectRatio.kt
new file mode 100644
index 0000000..5dad03d
--- /dev/null
+++ b/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/core/extensions/Size+aspectRatio.kt
@@ -0,0 +1,6 @@
+package com.mrousavy.camera.core.extensions
+
+import android.util.Size
+
+val Size.aspectRatio: Float
+  get() = width.toFloat() / height.toFloat()
diff --git a/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/core/extensions/StateError+toCameraError.kt b/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/core/extensions/StateError+toCameraError.kt
new file mode 100644
index 0000000..238e6db
--- /dev/null
+++ b/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/core/extensions/StateError+toCameraError.kt
@@ -0,0 +1,25 @@
+package com.mrousavy.camera.core.extensions
+
+import androidx.camera.core.CameraState
+import androidx.camera.core.CameraState.StateError
+import com.mrousavy.camera.core.CameraError
+import com.mrousavy.camera.core.CameraInUseError
+import com.mrousavy.camera.core.CameraIsRestrictedError
+import com.mrousavy.camera.core.DoNotDisturbBugError
+import com.mrousavy.camera.core.FatalCameraError
+import com.mrousavy.camera.core.InvalidOutputConfigurationError
+import com.mrousavy.camera.core.MaxCamerasInUseError
+import com.mrousavy.camera.core.RecoverableError
+import com.mrousavy.camera.core.UnknownCameraError
+
+fun StateError.toCameraError(): CameraError =
+  when (this.code) {
+    CameraState.ERROR_MAX_CAMERAS_IN_USE -> MaxCamerasInUseError(cause)
+    CameraState.ERROR_CAMERA_IN_USE -> CameraInUseError(cause)
+    CameraState.ERROR_CAMERA_FATAL_ERROR -> FatalCameraError(cause)
+    CameraState.ERROR_CAMERA_DISABLED -> CameraIsRestrictedError(cause)
+    CameraState.ERROR_DO_NOT_DISTURB_MODE_ENABLED -> DoNotDisturbBugError(cause)
+    CameraState.ERROR_OTHER_RECOVERABLE_ERROR -> RecoverableError(cause)
+    CameraState.ERROR_STREAM_CONFIG -> InvalidOutputConfigurationError(cause)
+    else -> UnknownCameraError(cause)
+  }
diff --git a/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/core/extensions/VideoRecordEvent+toCameraError.kt b/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/core/extensions/VideoRecordEvent+toCameraError.kt
new file mode 100644
index 0000000..0613078
--- /dev/null
+++ b/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/core/extensions/VideoRecordEvent+toCameraError.kt
@@ -0,0 +1,43 @@
+package com.mrousavy.camera.core.extensions
+
+import androidx.camera.video.VideoRecordEvent
+import com.mrousavy.camera.core.DurationLimitReachedError
+import com.mrousavy.camera.core.EncoderError
+import com.mrousavy.camera.core.FileSizeLimitReachedError
+import com.mrousavy.camera.core.InsufficientStorageForRecorderError
+import com.mrousavy.camera.core.InvalidRecorderConfigurationError
+import com.mrousavy.camera.core.NoDataError
+import com.mrousavy.camera.core.RecorderError
+import com.mrousavy.camera.core.UnknownRecorderError
+
+fun VideoRecordEvent.Finalize.getCameraError(): RecorderError? {
+  if (!hasError()) return null
+
+  return when (error) {
+    // errors where the recording still gets saved (so we can probably ignore them)
+    VideoRecordEvent.Finalize.ERROR_INSUFFICIENT_STORAGE -> return InsufficientStorageForRecorderError(cause)
+
+    VideoRecordEvent.Finalize.ERROR_SOURCE_INACTIVE -> return NoDataError(cause)
+
+    VideoRecordEvent.Finalize.ERROR_DURATION_LIMIT_REACHED -> return DurationLimitReachedError(cause)
+
+    VideoRecordEvent.Finalize.ERROR_FILE_SIZE_LIMIT_REACHED -> return FileSizeLimitReachedError(cause)
+
+    VideoRecordEvent.Finalize.ERROR_RECORDING_GARBAGE_COLLECTED -> return UnknownRecorderError(true, cause)
+
+    // fatal errors where no recording gets saved
+    VideoRecordEvent.Finalize.ERROR_NONE -> return null
+
+    VideoRecordEvent.Finalize.ERROR_UNKNOWN -> return UnknownRecorderError(false, cause)
+
+    VideoRecordEvent.Finalize.ERROR_INVALID_OUTPUT_OPTIONS -> return InvalidRecorderConfigurationError(cause)
+
+    VideoRecordEvent.Finalize.ERROR_ENCODING_FAILED -> return EncoderError(cause)
+
+    VideoRecordEvent.Finalize.ERROR_RECORDER_ERROR -> return UnknownRecorderError(false, cause)
+
+    VideoRecordEvent.Finalize.ERROR_NO_VALID_DATA -> return NoDataError(cause)
+
+    else -> UnknownRecorderError(false, cause)
+  }
+}
diff --git a/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/core/types/.gitattributes b/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/core/types/.gitattributes
new file mode 100644
index 0000000..c7986ee
--- /dev/null
+++ b/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/core/types/.gitattributes
@@ -0,0 +1,2 @@
+# Just mark all of this as Swift code, I just don't want it to show up as Kotlin on GitHub.
+*.kt linguist-language=Swift
diff --git a/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/core/types/AutoFocusSystem.kt b/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/core/types/AutoFocusSystem.kt
new file mode 100644
index 0000000..cf3cfd0
--- /dev/null
+++ b/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/core/types/AutoFocusSystem.kt
@@ -0,0 +1,14 @@
+package com.mrousavy.camera.core.types
+
+enum class AutoFocusSystem(override val unionValue: String) : JSUnionValue {
+  CONTRAST_DETECTION("contrast-detection"),
+  NONE("none");
+
+  companion object : JSUnionValue.Companion<AutoFocusSystem> {
+    override fun fromUnionValue(unionValue: String?): AutoFocusSystem =
+      when (unionValue) {
+        "contrast-detection" -> CONTRAST_DETECTION
+        else -> NONE
+      }
+  }
+}
diff --git a/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/core/types/CameraDeviceFormat.kt b/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/core/types/CameraDeviceFormat.kt
new file mode 100644
index 0000000..51b56a5
--- /dev/null
+++ b/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/core/types/CameraDeviceFormat.kt
@@ -0,0 +1,74 @@
+package com.mrousavy.camera.core.types
+
+import android.util.Size
+import androidx.camera.video.FallbackStrategy
+import androidx.camera.video.Quality
+import androidx.camera.video.QualitySelector
+import com.facebook.react.bridge.ReadableMap
+import com.mrousavy.camera.core.InvalidTypeScriptUnionError
+import kotlin.math.abs
+
+data class CameraDeviceFormat(
+  val videoWidth: Int,
+  val videoHeight: Int,
+  val photoWidth: Int,
+  val photoHeight: Int,
+  val minFps: Double,
+  val maxFps: Double,
+  val minISO: Double,
+  val maxISO: Double,
+  val fieldOfView: Double,
+  val videoStabilizationModes: List<VideoStabilizationMode>,
+  val autoFocusSystem: AutoFocusSystem,
+  val supportsVideoHdr: Boolean,
+  val supportsPhotoHdr: Boolean,
+  val supportsDepthCapture: Boolean
+) {
+  val photoSize: Size
+    get() = Size(photoWidth, photoHeight)
+  val videoSize: Size
+    get() = Size(videoWidth, videoHeight)
+
+  private val qualitySizes = mapOf<Quality, Int>(
+    Quality.SD to 720 * 480,
+    Quality.HD to 1280 * 720,
+    Quality.FHD to 1920 * 1080,
+    Quality.UHD to 3840 * 2160
+  )
+
+  private fun getQualitySelector(size: Size): QualitySelector {
+    val targetSize = size.width * size.height
+    val entry = qualitySizes.minBy { abs(targetSize - it.value) }
+    val targetQuality = entry.key
+    return QualitySelector.from(targetQuality, FallbackStrategy.higherQualityOrLowerThan(targetQuality))
+  }
+
+  val videoQualitySelector: QualitySelector
+    get() = getQualitySelector(videoSize)
+
+  companion object {
+    fun fromJSValue(value: ReadableMap): CameraDeviceFormat {
+      val modes = value.getArray("videoStabilizationModes") ?: throw InvalidTypeScriptUnionError("format", value.toString())
+      val videoStabilizationModes = modes.toArrayList().map { VideoStabilizationMode.fromUnionValue(it as String) }
+
+      val autoFocusSystem = AutoFocusSystem.fromUnionValue(value.getString("autoFocusSystem"))
+
+      return CameraDeviceFormat(
+        value.getInt("videoWidth"),
+        value.getInt("videoHeight"),
+        value.getInt("photoWidth"),
+        value.getInt("photoHeight"),
+        value.getDouble("minFps"),
+        value.getDouble("maxFps"),
+        value.getDouble("minISO"),
+        value.getDouble("maxISO"),
+        value.getDouble("fieldOfView"),
+        videoStabilizationModes,
+        autoFocusSystem,
+        value.getBoolean("supportsVideoHdr"),
+        value.getBoolean("supportsPhotoHdr"),
+        value.getBoolean("supportsDepthCapture")
+      )
+    }
+  }
+}
diff --git a/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/core/types/CodeScannerOptions.kt b/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/core/types/CodeScannerOptions.kt
new file mode 100644
index 0000000..233874a
--- /dev/null
+++ b/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/core/types/CodeScannerOptions.kt
@@ -0,0 +1,14 @@
+package com.mrousavy.camera.core.types
+
+import com.facebook.react.bridge.ReadableMap
+import com.mrousavy.camera.core.InvalidTypeScriptUnionError
+
+data class CodeScannerOptions(val codeTypes: List<CodeType>) {
+  companion object {
+    fun fromJSValue(value: ReadableMap): CodeScannerOptions {
+      val jsCodeTypes = value.getArray("codeTypes") ?: throw InvalidTypeScriptUnionError("codeScanner", value.toString())
+      val codeTypes = jsCodeTypes.toArrayList().map { CodeType.fromUnionValue(it as String) }
+      return CodeScannerOptions(codeTypes)
+    }
+  }
+}
diff --git a/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/core/types/CodeType.kt b/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/core/types/CodeType.kt
new file mode 100644
index 0000000..25983df
--- /dev/null
+++ b/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/core/types/CodeType.kt
@@ -0,0 +1,78 @@
+package com.mrousavy.camera.core.types
+
+import com.google.mlkit.vision.barcode.common.Barcode
+import com.mrousavy.camera.core.CodeTypeNotSupportedError
+import com.mrousavy.camera.core.InvalidTypeScriptUnionError
+
+enum class CodeType(override val unionValue: String) : JSUnionValue {
+  CODE_128("code-128"),
+  CODE_39("code-39"),
+  CODE_93("code-93"),
+  CODABAR("codabar"),
+  EAN_13("ean-13"),
+  EAN_8("ean-8"),
+  ITF("itf"),
+  UPC_E("upc-e"),
+  UPC_A("upc-a"),
+  QR("qr"),
+  PDF_417("pdf-417"),
+  AZTEC("aztec"),
+  DATA_MATRIX("data-matrix"),
+  UNKNOWN("unknown");
+
+  fun toBarcodeType(): Int =
+    when (this) {
+      CODE_128 -> Barcode.FORMAT_CODE_128
+      CODE_39 -> Barcode.FORMAT_CODE_39
+      CODE_93 -> Barcode.FORMAT_CODE_93
+      CODABAR -> Barcode.FORMAT_CODABAR
+      EAN_13 -> Barcode.FORMAT_EAN_13
+      EAN_8 -> Barcode.FORMAT_EAN_8
+      ITF -> Barcode.FORMAT_ITF
+      UPC_E -> Barcode.FORMAT_UPC_E
+      UPC_A -> Barcode.FORMAT_UPC_A
+      QR -> Barcode.FORMAT_QR_CODE
+      PDF_417 -> Barcode.FORMAT_PDF417
+      AZTEC -> Barcode.FORMAT_AZTEC
+      DATA_MATRIX -> Barcode.FORMAT_DATA_MATRIX
+      UNKNOWN -> throw CodeTypeNotSupportedError(this.unionValue)
+    }
+
+  companion object : JSUnionValue.Companion<CodeType> {
+    fun fromBarcodeType(barcodeType: Int): CodeType =
+      when (barcodeType) {
+        Barcode.FORMAT_CODE_128 -> CODE_128
+        Barcode.FORMAT_CODE_39 -> CODE_39
+        Barcode.FORMAT_CODE_93 -> CODE_93
+        Barcode.FORMAT_CODABAR -> CODABAR
+        Barcode.FORMAT_EAN_13 -> EAN_13
+        Barcode.FORMAT_EAN_8 -> EAN_8
+        Barcode.FORMAT_ITF -> ITF
+        Barcode.FORMAT_UPC_E -> UPC_E
+        Barcode.FORMAT_UPC_A -> UPC_A
+        Barcode.FORMAT_QR_CODE -> QR
+        Barcode.FORMAT_PDF417 -> PDF_417
+        Barcode.FORMAT_AZTEC -> AZTEC
+        Barcode.FORMAT_DATA_MATRIX -> DATA_MATRIX
+        else -> UNKNOWN
+      }
+
+    override fun fromUnionValue(unionValue: String?): CodeType =
+      when (unionValue) {
+        "code-128" -> CODE_128
+        "code-39" -> CODE_39
+        "code-93" -> CODE_93
+        "codabar" -> CODABAR
+        "ean-13" -> EAN_13
+        "ean-8" -> EAN_8
+        "itf" -> ITF
+        "upc-e" -> UPC_E
+        "upc-a" -> UPC_A
+        "qr" -> QR
+        "pdf-417" -> PDF_417
+        "aztec" -> AZTEC
+        "data-matrix" -> DATA_MATRIX
+        else -> throw InvalidTypeScriptUnionError("codeType", unionValue ?: "(null)")
+      }
+  }
+}
diff --git a/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/core/types/DeviceType.kt b/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/core/types/DeviceType.kt
new file mode 100644
index 0000000..38c9252
--- /dev/null
+++ b/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/core/types/DeviceType.kt
@@ -0,0 +1,7 @@
+package com.mrousavy.camera.core.types
+
+enum class DeviceType(override val unionValue: String) : JSUnionValue {
+  ULTRA_WIDE_ANGLE("ultra-wide-angle-camera"),
+  WIDE_ANGLE("wide-angle-camera"),
+  TELEPHOTO("telephoto-camera")
+}
diff --git a/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/core/types/Flash.kt b/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/core/types/Flash.kt
new file mode 100644
index 0000000..930b632
--- /dev/null
+++ b/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/core/types/Flash.kt
@@ -0,0 +1,27 @@
+package com.mrousavy.camera.core.types
+
+import androidx.camera.core.ImageCapture
+import com.mrousavy.camera.core.InvalidTypeScriptUnionError
+
+enum class Flash(override val unionValue: String) : JSUnionValue {
+  OFF("off"),
+  ON("on"),
+  AUTO("auto");
+
+  fun toFlashMode(): Int =
+    when (this) {
+      OFF -> ImageCapture.FLASH_MODE_OFF
+      ON -> ImageCapture.FLASH_MODE_ON
+      AUTO -> ImageCapture.FLASH_MODE_AUTO
+    }
+
+  companion object : JSUnionValue.Companion<Flash> {
+    override fun fromUnionValue(unionValue: String?): Flash =
+      when (unionValue) {
+        "off" -> OFF
+        "on" -> ON
+        "auto" -> AUTO
+        else -> throw InvalidTypeScriptUnionError("flash", unionValue ?: "(null)")
+      }
+  }
+}
diff --git a/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/core/types/HardwareLevel.kt b/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/core/types/HardwareLevel.kt
new file mode 100644
index 0000000..d94b9a7
--- /dev/null
+++ b/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/core/types/HardwareLevel.kt
@@ -0,0 +1,34 @@
+package com.mrousavy.camera.core.types
+
+import android.hardware.camera2.CameraCharacteristics
+
+enum class HardwareLevel(override val unionValue: String) : JSUnionValue {
+  LEGACY("legacy"),
+  LIMITED("limited"),
+  EXTERNAL("limited"),
+  FULL("full"),
+  LEVEL_3("full");
+
+  private val rank: Int
+    get() {
+      return when (this) {
+        LEGACY -> 0
+        LIMITED -> 1
+        EXTERNAL -> 1
+        FULL -> 2
+        LEVEL_3 -> 3
+      }
+    }
+
+  companion object {
+    fun fromCameraHardwareLevel(hardwareLevel: Int): HardwareLevel =
+      when (hardwareLevel) {
+        CameraCharacteristics.INFO_SUPPORTED_HARDWARE_LEVEL_LEGACY -> LEGACY
+        CameraCharacteristics.INFO_SUPPORTED_HARDWARE_LEVEL_LIMITED -> LIMITED
+        CameraCharacteristics.INFO_SUPPORTED_HARDWARE_LEVEL_EXTERNAL -> EXTERNAL
+        CameraCharacteristics.INFO_SUPPORTED_HARDWARE_LEVEL_FULL -> FULL
+        CameraCharacteristics.INFO_SUPPORTED_HARDWARE_LEVEL_3 -> LEVEL_3
+        else -> LEGACY
+      }
+  }
+}
diff --git a/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/core/types/JSUnionValue.kt b/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/core/types/JSUnionValue.kt
new file mode 100644
index 0000000..fdc9869
--- /dev/null
+++ b/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/core/types/JSUnionValue.kt
@@ -0,0 +1,9 @@
+package com.mrousavy.camera.core.types
+
+interface JSUnionValue {
+  val unionValue: String
+
+  interface Companion<T> {
+    fun fromUnionValue(unionValue: String?): T?
+  }
+}
diff --git a/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/core/types/Orientation.kt b/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/core/types/Orientation.kt
new file mode 100644
index 0000000..1476d93
--- /dev/null
+++ b/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/core/types/Orientation.kt
@@ -0,0 +1,65 @@
+package com.mrousavy.camera.core.types
+
+import android.view.Surface
+
+// This orientation represents the orientation of the device home button.
+enum class Orientation(override val unionValue: String) : JSUnionValue {
+  PORTRAIT("portrait"),
+  LANDSCAPE_RIGHT("landscape-right"),
+  PORTRAIT_UPSIDE_DOWN("portrait-upside-down"),
+  LANDSCAPE_LEFT("landscape-left");
+
+  // The SurfaceOrientation represents the orientation of the Android UI view.
+  // When you rotate your device in one direction, the UI view rotates in the opposite direction.
+  // For example, when you rotate the device clockwise, the view rotates counterclockwise.
+  fun toSurfaceRotation(): Int =
+    when (this) {
+      PORTRAIT -> Surface.ROTATION_0
+      LANDSCAPE_LEFT -> Surface.ROTATION_270
+      PORTRAIT_UPSIDE_DOWN -> Surface.ROTATION_180
+      LANDSCAPE_RIGHT -> Surface.ROTATION_90
+    }
+
+  /**
+   * Flips this Orientation to be interpreted as a rotation-offset.
+   * - 0° -> 0°
+   * - 90° -> 270°
+   * - 180° -> 180°
+   * - 270° -> 90°
+   */
+  fun reversed(): Orientation =
+    when (this) {
+      PORTRAIT -> PORTRAIT
+      LANDSCAPE_LEFT -> LANDSCAPE_RIGHT
+      PORTRAIT_UPSIDE_DOWN -> PORTRAIT_UPSIDE_DOWN
+      LANDSCAPE_RIGHT -> LANDSCAPE_LEFT
+    }
+
+  companion object : JSUnionValue.Companion<Orientation> {
+    override fun fromUnionValue(unionValue: String?): Orientation =
+      when (unionValue) {
+        "portrait" -> PORTRAIT
+        "landscape-right" -> LANDSCAPE_RIGHT
+        "portrait-upside-down" -> PORTRAIT_UPSIDE_DOWN
+        "landscape-left" -> LANDSCAPE_LEFT
+        else -> PORTRAIT
+      }
+
+    fun fromRotationDegrees(rotationDegrees: Int): Orientation =
+      when (rotationDegrees) {
+        in 45..135 -> LANDSCAPE_LEFT
+        in 135..225 -> PORTRAIT_UPSIDE_DOWN
+        in 225..315 -> LANDSCAPE_RIGHT
+        else -> PORTRAIT
+      }
+
+    fun fromSurfaceRotation(rotation: Int): Orientation =
+      when (rotation) {
+        Surface.ROTATION_0 -> PORTRAIT
+        Surface.ROTATION_90 -> LANDSCAPE_RIGHT
+        Surface.ROTATION_180 -> PORTRAIT_UPSIDE_DOWN
+        Surface.ROTATION_270 -> LANDSCAPE_LEFT
+        else -> PORTRAIT
+      }
+  }
+}
diff --git a/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/core/types/OutputOrientation.kt b/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/core/types/OutputOrientation.kt
new file mode 100644
index 0000000..0f9c870
--- /dev/null
+++ b/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/core/types/OutputOrientation.kt
@@ -0,0 +1,15 @@
+package com.mrousavy.camera.core.types
+
+enum class OutputOrientation(override val unionValue: String) : JSUnionValue {
+  DEVICE("device"),
+  PREVIEW("preview");
+
+  companion object : JSUnionValue.Companion<OutputOrientation> {
+    override fun fromUnionValue(unionValue: String?): OutputOrientation =
+      when (unionValue) {
+        "device" -> DEVICE
+        "preview" -> PREVIEW
+        else -> DEVICE
+      }
+  }
+}
diff --git a/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/core/types/PermissionStatus.kt b/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/core/types/PermissionStatus.kt
new file mode 100644
index 0000000..47b50ef
--- /dev/null
+++ b/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/core/types/PermissionStatus.kt
@@ -0,0 +1,18 @@
+package com.mrousavy.camera.core.types
+
+import android.content.pm.PackageManager
+
+enum class PermissionStatus(override val unionValue: String) : JSUnionValue {
+  DENIED("denied"),
+  NOT_DETERMINED("not-determined"),
+  GRANTED("granted");
+
+  companion object {
+    fun fromPermissionStatus(status: Int): PermissionStatus =
+      when (status) {
+        PackageManager.PERMISSION_DENIED -> DENIED
+        PackageManager.PERMISSION_GRANTED -> GRANTED
+        else -> NOT_DETERMINED
+      }
+  }
+}
diff --git a/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/core/types/PixelFormat.kt b/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/core/types/PixelFormat.kt
new file mode 100644
index 0000000..367175c
--- /dev/null
+++ b/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/core/types/PixelFormat.kt
@@ -0,0 +1,44 @@
+package com.mrousavy.camera.core.types
+
+import android.graphics.ImageFormat
+import android.util.Log
+import androidx.camera.core.ImageAnalysis
+import com.mrousavy.camera.core.InvalidTypeScriptUnionError
+import com.mrousavy.camera.core.PixelFormatNotSupportedError
+import com.mrousavy.camera.core.utils.ImageFormatUtils
+
+enum class PixelFormat(override val unionValue: String) : JSUnionValue {
+  YUV("yuv"),
+  RGB("rgb"),
+  UNKNOWN("unknown");
+
+  fun toImageAnalysisFormat(): Int =
+    when (this) {
+      YUV -> ImageAnalysis.OUTPUT_IMAGE_FORMAT_YUV_420_888
+      RGB -> ImageAnalysis.OUTPUT_IMAGE_FORMAT_RGBA_8888
+      else -> throw PixelFormatNotSupportedError(this.unionValue)
+    }
+
+  companion object : JSUnionValue.Companion<PixelFormat> {
+    private const val TAG = "PixelFormat"
+    fun fromImageFormat(imageFormat: Int): PixelFormat =
+      when (imageFormat) {
+        ImageFormat.YUV_420_888 -> YUV
+
+        android.graphics.PixelFormat.RGBA_8888 -> RGB
+
+        else -> {
+          Log.w(TAG, "Unknown PixelFormat! ${ImageFormatUtils.imageFormatToString(imageFormat)}")
+          UNKNOWN
+        }
+      }
+
+    override fun fromUnionValue(unionValue: String?): PixelFormat =
+      when (unionValue) {
+        "yuv" -> YUV
+        "rgb" -> RGB
+        "unknown" -> UNKNOWN
+        else -> throw InvalidTypeScriptUnionError("pixelFormat", unionValue)
+      }
+  }
+}
diff --git a/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/core/types/Position.kt b/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/core/types/Position.kt
new file mode 100644
index 0000000..871625a
--- /dev/null
+++ b/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/core/types/Position.kt
@@ -0,0 +1,23 @@
+package com.mrousavy.camera.core.types
+
+import androidx.annotation.OptIn
+import androidx.camera.core.CameraSelector
+import androidx.camera.core.ExperimentalLensFacing
+
+enum class Position(override val unionValue: String) : JSUnionValue {
+  BACK("back"),
+  FRONT("front"),
+  EXTERNAL("external");
+
+  companion object {
+    @OptIn(ExperimentalLensFacing::class)
+    fun fromLensFacing(lensFacing: Int): Position =
+      when (lensFacing) {
+        CameraSelector.LENS_FACING_BACK -> BACK
+        CameraSelector.LENS_FACING_FRONT -> FRONT
+        CameraSelector.LENS_FACING_EXTERNAL -> EXTERNAL
+        CameraSelector.LENS_FACING_UNKNOWN -> EXTERNAL
+        else -> EXTERNAL
+      }
+  }
+}
diff --git a/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/core/types/PreviewViewType.kt b/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/core/types/PreviewViewType.kt
new file mode 100644
index 0000000..caa399e
--- /dev/null
+++ b/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/core/types/PreviewViewType.kt
@@ -0,0 +1,24 @@
+package com.mrousavy.camera.core.types
+
+import androidx.camera.view.PreviewView
+import com.mrousavy.camera.core.InvalidTypeScriptUnionError
+
+enum class PreviewViewType(override val unionValue: String) : JSUnionValue {
+  SURFACE_VIEW("surface-view"),
+  TEXTURE_VIEW("texture-view");
+
+  fun toPreviewImplementationMode(): PreviewView.ImplementationMode =
+    when (this) {
+      SURFACE_VIEW -> PreviewView.ImplementationMode.PERFORMANCE
+      TEXTURE_VIEW -> PreviewView.ImplementationMode.COMPATIBLE
+    }
+
+  companion object : JSUnionValue.Companion<PreviewViewType> {
+    override fun fromUnionValue(unionValue: String?): PreviewViewType =
+      when (unionValue) {
+        "surface-view" -> SURFACE_VIEW
+        "texture-view" -> TEXTURE_VIEW
+        else -> throw InvalidTypeScriptUnionError("androidPreviewViewType", unionValue)
+      }
+  }
+}
diff --git a/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/core/types/QualityBalance.kt b/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/core/types/QualityBalance.kt
new file mode 100644
index 0000000..739cb22
--- /dev/null
+++ b/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/core/types/QualityBalance.kt
@@ -0,0 +1,29 @@
+package com.mrousavy.camera.core.types
+
+import androidx.annotation.OptIn
+import androidx.camera.core.ExperimentalZeroShutterLag
+import androidx.camera.core.ImageCapture
+
+enum class QualityBalance(override val unionValue: String) : JSUnionValue {
+  SPEED("speed"),
+  BALANCED("balanced"),
+  QUALITY("quality");
+
+  @OptIn(ExperimentalZeroShutterLag::class)
+  fun toCaptureMode(): Int =
+    when (this) {
+      SPEED -> ImageCapture.CAPTURE_MODE_MINIMIZE_LATENCY
+      BALANCED -> ImageCapture.CAPTURE_MODE_ZERO_SHUTTER_LAG
+      QUALITY -> ImageCapture.CAPTURE_MODE_MAXIMIZE_QUALITY
+    }
+
+  companion object : JSUnionValue.Companion<QualityBalance> {
+    override fun fromUnionValue(unionValue: String?): QualityBalance =
+      when (unionValue) {
+        "speed" -> SPEED
+        "balanced" -> BALANCED
+        "quality" -> QUALITY
+        else -> BALANCED
+      }
+  }
+}
diff --git a/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/core/types/RecordVideoOptions.kt b/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/core/types/RecordVideoOptions.kt
new file mode 100644
index 0000000..1fca870
--- /dev/null
+++ b/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/core/types/RecordVideoOptions.kt
@@ -0,0 +1,20 @@
+package com.mrousavy.camera.core.types
+
+import android.content.Context
+import com.facebook.react.bridge.ReadableMap
+import com.mrousavy.camera.core.utils.FileUtils
+import com.mrousavy.camera.core.utils.OutputFile
+
+class RecordVideoOptions(val file: OutputFile, val videoCodec: VideoCodec) {
+
+  companion object {
+    fun fromJSValue(context: Context, map: ReadableMap): RecordVideoOptions {
+      val directory = if (map.hasKey("path")) FileUtils.getDirectory(map.getString("path")) else context.cacheDir
+      val fileType = if (map.hasKey("fileType")) VideoFileType.fromUnionValue(map.getString("fileType")) else VideoFileType.MOV
+      val videoCodec = if (map.hasKey("videoCodec")) VideoCodec.fromUnionValue(map.getString("videoCodec")) else VideoCodec.H264
+
+      val outputFile = OutputFile(context, directory, fileType.toExtension())
+      return RecordVideoOptions(outputFile, videoCodec)
+    }
+  }
+}
diff --git a/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/core/types/ResizeMode.kt b/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/core/types/ResizeMode.kt
new file mode 100644
index 0000000..189a67a
--- /dev/null
+++ b/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/core/types/ResizeMode.kt
@@ -0,0 +1,24 @@
+package com.mrousavy.camera.core.types
+
+import androidx.camera.view.PreviewView
+import com.mrousavy.camera.core.InvalidTypeScriptUnionError
+
+enum class ResizeMode(override val unionValue: String) : JSUnionValue {
+  COVER("cover"),
+  CONTAIN("contain");
+
+  fun toScaleType(): PreviewView.ScaleType =
+    when (this) {
+      COVER -> PreviewView.ScaleType.FILL_CENTER
+      CONTAIN -> PreviewView.ScaleType.FIT_CENTER
+    }
+
+  companion object : JSUnionValue.Companion<ResizeMode> {
+    override fun fromUnionValue(unionValue: String?): ResizeMode =
+      when (unionValue) {
+        "cover" -> COVER
+        "contain" -> CONTAIN
+        else -> throw InvalidTypeScriptUnionError("resizeMode", unionValue)
+      }
+  }
+}
diff --git a/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/core/types/ShutterType.kt b/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/core/types/ShutterType.kt
new file mode 100644
index 0000000..4bb5f30
--- /dev/null
+++ b/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/core/types/ShutterType.kt
@@ -0,0 +1,6 @@
+package com.mrousavy.camera.core.types
+
+enum class ShutterType(override val unionValue: String) : JSUnionValue {
+  PHOTO("photo"),
+  SNAPSHOT("snapshot")
+}
diff --git a/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/core/types/TakePhotoOptions.kt b/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/core/types/TakePhotoOptions.kt
new file mode 100644
index 0000000..4c99c4b
--- /dev/null
+++ b/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/core/types/TakePhotoOptions.kt
@@ -0,0 +1,20 @@
+package com.mrousavy.camera.core.types
+
+import android.content.Context
+import com.facebook.react.bridge.ReadableMap
+import com.mrousavy.camera.core.utils.FileUtils
+import com.mrousavy.camera.core.utils.OutputFile
+
+data class TakePhotoOptions(val file: OutputFile, val flash: Flash, val enableShutterSound: Boolean) {
+
+  companion object {
+    fun fromJS(context: Context, map: ReadableMap): TakePhotoOptions {
+      val flash = if (map.hasKey("flash")) Flash.fromUnionValue(map.getString("flash")) else Flash.OFF
+      val enableShutterSound = if (map.hasKey("enableShutterSound")) map.getBoolean("enableShutterSound") else false
+      val directory = if (map.hasKey("path")) FileUtils.getDirectory(map.getString("path")) else context.cacheDir
+
+      val outputFile = OutputFile(context, directory, ".jpg")
+      return TakePhotoOptions(outputFile, flash, enableShutterSound)
+    }
+  }
+}
diff --git a/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/core/types/TakeSnapshotOptions.kt b/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/core/types/TakeSnapshotOptions.kt
new file mode 100644
index 0000000..b467632
--- /dev/null
+++ b/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/core/types/TakeSnapshotOptions.kt
@@ -0,0 +1,19 @@
+package com.mrousavy.camera.core.types
+
+import android.content.Context
+import com.facebook.react.bridge.ReadableMap
+import com.mrousavy.camera.core.utils.FileUtils
+import com.mrousavy.camera.core.utils.OutputFile
+
+data class TakeSnapshotOptions(val file: OutputFile, val quality: Int) {
+
+  companion object {
+    fun fromJSValue(context: Context, map: ReadableMap): TakeSnapshotOptions {
+      val quality = if (map.hasKey("quality")) map.getInt("quality") else 100
+      val directory = if (map.hasKey("path")) FileUtils.getDirectory(map.getString("path")) else context.cacheDir
+
+      val outputFile = OutputFile(context, directory, ".jpg")
+      return TakeSnapshotOptions(outputFile, quality)
+    }
+  }
+}
diff --git a/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/core/types/Torch.kt b/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/core/types/Torch.kt
new file mode 100644
index 0000000..b0f7f4f
--- /dev/null
+++ b/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/core/types/Torch.kt
@@ -0,0 +1,15 @@
+package com.mrousavy.camera.core.types
+
+enum class Torch(override val unionValue: String) : JSUnionValue {
+  OFF("off"),
+  ON("on");
+
+  companion object : JSUnionValue.Companion<Torch> {
+    override fun fromUnionValue(unionValue: String?): Torch =
+      when (unionValue) {
+        "off" -> OFF
+        "on" -> ON
+        else -> OFF
+      }
+  }
+}
diff --git a/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/core/types/Video.kt b/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/core/types/Video.kt
new file mode 100644
index 0000000..baa411e
--- /dev/null
+++ b/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/core/types/Video.kt
@@ -0,0 +1,5 @@
+package com.mrousavy.camera.core.types
+
+import android.util.Size
+
+data class Video(val path: String, val durationMs: Long, val size: Size)
diff --git a/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/core/types/VideoCodec.kt b/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/core/types/VideoCodec.kt
new file mode 100644
index 0000000..1a6ad22
--- /dev/null
+++ b/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/core/types/VideoCodec.kt
@@ -0,0 +1,23 @@
+package com.mrousavy.camera.core.types
+
+import android.media.MediaRecorder
+
+enum class VideoCodec(override val unionValue: String) : JSUnionValue {
+  H264("h264"),
+  H265("h265");
+
+  fun toVideoEncoder(): Int =
+    when (this) {
+      H264 -> MediaRecorder.VideoEncoder.H264
+      H265 -> MediaRecorder.VideoEncoder.HEVC
+    }
+
+  companion object : JSUnionValue.Companion<VideoCodec> {
+    override fun fromUnionValue(unionValue: String?): VideoCodec =
+      when (unionValue) {
+        "h264" -> H264
+        "h265" -> H265
+        else -> H264
+      }
+  }
+}
diff --git a/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/core/types/VideoFileType.kt b/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/core/types/VideoFileType.kt
new file mode 100644
index 0000000..4143e4a
--- /dev/null
+++ b/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/core/types/VideoFileType.kt
@@ -0,0 +1,23 @@
+package com.mrousavy.camera.core.types
+
+import com.mrousavy.camera.core.InvalidTypeScriptUnionError
+
+enum class VideoFileType(override val unionValue: String) : JSUnionValue {
+  MOV("mov"),
+  MP4("mp4");
+
+  fun toExtension(): String =
+    when (this) {
+      MOV -> ".mov"
+      MP4 -> ".mp4"
+    }
+
+  companion object : JSUnionValue.Companion<VideoFileType> {
+    override fun fromUnionValue(unionValue: String?): VideoFileType =
+      when (unionValue) {
+        "mov" -> MOV
+        "mp4" -> MP4
+        else -> throw InvalidTypeScriptUnionError("fileType", unionValue ?: "(null)")
+      }
+  }
+}
diff --git a/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/core/types/VideoStabilizationMode.kt b/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/core/types/VideoStabilizationMode.kt
new file mode 100644
index 0000000..0b33064
--- /dev/null
+++ b/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/core/types/VideoStabilizationMode.kt
@@ -0,0 +1,34 @@
+package com.mrousavy.camera.core.types
+
+import com.mrousavy.camera.core.InvalidTypeScriptUnionError
+
+enum class VideoStabilizationMode(override val unionValue: String) : JSUnionValue {
+  OFF("off"),
+  STANDARD("standard"),
+  CINEMATIC("cinematic"),
+  CINEMATIC_EXTENDED("cinematic-extended");
+
+  private val score: Int
+    get() {
+      return when (this) {
+        OFF -> 0
+        STANDARD -> 1
+        CINEMATIC -> 2
+        CINEMATIC_EXTENDED -> 3
+      }
+    }
+
+  fun isAtLeast(mode: VideoStabilizationMode): Boolean = score >= mode.score
+
+  companion object : JSUnionValue.Companion<VideoStabilizationMode> {
+    override fun fromUnionValue(unionValue: String?): VideoStabilizationMode =
+      when (unionValue) {
+        "off" -> OFF
+        "auto" -> OFF
+        "standard" -> STANDARD
+        "cinematic" -> CINEMATIC
+        "cinematic-extended" -> CINEMATIC_EXTENDED
+        else -> throw InvalidTypeScriptUnionError("videoStabilizationMode", unionValue)
+      }
+  }
+}
diff --git a/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/core/utils/CamcorderProfileUtils.kt b/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/core/utils/CamcorderProfileUtils.kt
new file mode 100644
index 0000000..791c412
--- /dev/null
+++ b/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/core/utils/CamcorderProfileUtils.kt
@@ -0,0 +1,133 @@
+package com.mrousavy.camera.core.utils
+
+import android.annotation.SuppressLint
+import android.media.CamcorderProfile
+import android.os.Build
+import android.util.Log
+import android.util.Size
+import kotlin.math.abs
+
+class CamcorderProfileUtils {
+  companion object {
+    private const val TAG = "CamcorderProfileUtils"
+
+    private fun getResolutionForCamcorderProfileQuality(camcorderProfile: Int): Int =
+      when (camcorderProfile) {
+        CamcorderProfile.QUALITY_QCIF -> 176 * 144
+        CamcorderProfile.QUALITY_QVGA -> 320 * 240
+        CamcorderProfile.QUALITY_CIF -> 352 * 288
+        CamcorderProfile.QUALITY_VGA -> 640 * 480
+        CamcorderProfile.QUALITY_480P -> 720 * 480
+        CamcorderProfile.QUALITY_720P -> 1280 * 720
+        CamcorderProfile.QUALITY_1080P -> 1920 * 1080
+        CamcorderProfile.QUALITY_2K -> 2048 * 1080
+        CamcorderProfile.QUALITY_QHD -> 2560 * 1440
+        CamcorderProfile.QUALITY_2160P -> 3840 * 2160
+        CamcorderProfile.QUALITY_4KDCI -> 4096 * 2160
+        CamcorderProfile.QUALITY_8KUHD -> 7680 * 4320
+        else -> throw Error("Invalid CamcorderProfile \"$camcorderProfile\"!")
+      }
+
+    private fun findClosestCamcorderProfileQuality(cameraId: String, resolution: Size, allowLargerSize: Boolean): Int {
+      // Iterate through all available CamcorderProfiles and find the one that matches the closest
+      val targetResolution = resolution.width * resolution.height
+      val cameraIdInt = cameraId.toIntOrNull()
+
+      @SuppressLint("InlinedApi")
+      var profiles = (CamcorderProfile.QUALITY_QCIF..CamcorderProfile.QUALITY_8KUHD).filter { profile ->
+        if (cameraIdInt != null) {
+          return@filter CamcorderProfile.hasProfile(cameraIdInt, profile)
+        } else {
+          return@filter CamcorderProfile.hasProfile(profile)
+        }
+      }
+      if (!allowLargerSize) {
+        profiles = profiles.filter { profile ->
+          val currentResolution = getResolutionForCamcorderProfileQuality(profile)
+          return@filter currentResolution <= targetResolution
+        }
+      }
+      val closestProfile = profiles.minBy { profile ->
+        val currentResolution = getResolutionForCamcorderProfileQuality(profile)
+        return@minBy abs(currentResolution - targetResolution)
+      }
+      return closestProfile
+    }
+
+    fun getMaximumVideoSize(cameraId: String): Size? {
+      try {
+        if (Build.VERSION.SDK_INT >= Build.VERSION_CODES.S) {
+          val profiles = CamcorderProfile.getAll(cameraId, CamcorderProfile.QUALITY_HIGH)
+          if (profiles != null) {
+            val largestProfile = profiles.videoProfiles.filterNotNull().maxByOrNull { it.width * it.height }
+            if (largestProfile != null) {
+              return Size(largestProfile.width, largestProfile.height)
+            }
+          }
+        }
+
+        val cameraIdInt = cameraId.toIntOrNull()
+        if (cameraIdInt != null) {
+          val profile = CamcorderProfile.get(cameraIdInt, CamcorderProfile.QUALITY_HIGH)
+          return Size(profile.videoFrameWidth, profile.videoFrameHeight)
+        }
+
+        return null
+      } catch (e: Throwable) {
+        // some Samsung phones just crash when trying to get the CamcorderProfile. Only god knows why.
+        Log.e(TAG, "Failed to get maximum video size for Camera ID $cameraId! ${e.message}", e)
+        return null
+      }
+    }
+
+    fun getMaximumFps(cameraId: String, size: Size): Int? {
+      try {
+        val quality = findClosestCamcorderProfileQuality(cameraId, size, false)
+
+        if (Build.VERSION.SDK_INT >= Build.VERSION_CODES.S) {
+          val profiles = CamcorderProfile.getAll(cameraId, quality)
+          if (profiles != null) {
+            return profiles.videoProfiles.maxOf { profile -> profile.frameRate }
+          }
+        }
+
+        val cameraIdInt = cameraId.toIntOrNull()
+        if (cameraIdInt != null) {
+          val profile = CamcorderProfile.get(cameraIdInt, quality)
+          return profile.videoFrameRate
+        }
+
+        return null
+      } catch (e: Throwable) {
+        // some Samsung phones just crash when trying to get the CamcorderProfile. Only god knows why.
+        Log.e(TAG, "Failed to get maximum FPS for Camera ID $cameraId! ${e.message}", e)
+        return null
+      }
+    }
+
+    fun getRecommendedBitRate(cameraId: String, videoSize: Size): Int? {
+      try {
+        val quality = findClosestCamcorderProfileQuality(cameraId, videoSize, true)
+
+        if (Build.VERSION.SDK_INT >= Build.VERSION_CODES.S) {
+          val profiles = CamcorderProfile.getAll(cameraId, quality)
+          if (profiles != null) {
+            return profiles.videoProfiles.maxOf { profile -> profile.bitrate }
+          }
+        }
+
+        val cameraIdInt = cameraId.toIntOrNull()
+        if (cameraIdInt != null) {
+          val profile = CamcorderProfile.get(cameraIdInt, quality)
+          return profile.videoBitRate
+        }
+
+        return null
+      } catch (e: Throwable) {
+        // some Samsung phones just crash when trying to get the CamcorderProfile. Only god knows why.
+        Log.e(TAG, "Failed to get recommended video bit-rate for Camera ID $cameraId! ${e.message}", e)
+        return null
+      }
+    }
+  }
+}
diff --git a/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/core/utils/FileUtils.kt b/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/core/utils/FileUtils.kt
new file mode 100644
index 0000000..4c594a5
--- /dev/null
+++ b/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/core/utils/FileUtils.kt
@@ -0,0 +1,39 @@
+package com.mrousavy.camera.core.utils
+
+import android.graphics.Bitmap
+import android.graphics.BitmapFactory
+import android.util.Size
+import com.mrousavy.camera.core.InvalidPathError
+import java.io.File
+import java.io.FileOutputStream
+
+class FileUtils {
+  companion object {
+    fun getDirectory(path: String?): File {
+      if (path == null) {
+        throw InvalidPathError("null")
+      }
+      val file = File(path)
+      if (!file.isDirectory) {
+        throw InvalidPathError(path)
+      }
+      return file
+    }
+
+    fun writeBitmapTofile(bitmap: Bitmap, file: File, quality: Int) {
+      FileOutputStream(file).use { stream ->
+        bitmap.compress(Bitmap.CompressFormat.JPEG, quality, stream)
+      }
+    }
+
+    fun getImageSize(imagePath: String): Size {
+      val bitmapOptions = BitmapFactory.Options().also {
+        it.inJustDecodeBounds = true
+      }
+      BitmapFactory.decodeFile(imagePath, bitmapOptions)
+      val width = bitmapOptions.outWidth
+      val height = bitmapOptions.outHeight
+      return Size(width, height)
+    }
+  }
+}
diff --git a/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/core/utils/ImageFormatUtils.kt b/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/core/utils/ImageFormatUtils.kt
new file mode 100644
index 0000000..aeb90d0
--- /dev/null
+++ b/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/core/utils/ImageFormatUtils.kt
@@ -0,0 +1,28 @@
+package com.mrousavy.camera.core.utils
+
+import android.graphics.ImageFormat
+import android.graphics.PixelFormat
+
+class ImageFormatUtils {
+  companion object {
+    fun imageFormatToString(format: Int): String =
+      when (format) {
+        ImageFormat.YUV_420_888 -> "YUV_420_888"
+        ImageFormat.NV21 -> "NV21"
+        ImageFormat.NV16 -> "NV16"
+        ImageFormat.YV12 -> "YV12"
+        ImageFormat.YUV_422_888 -> "YUV_422_888"
+        ImageFormat.YCBCR_P010 -> "YCBCR_P010"
+        ImageFormat.YUV_444_888 -> "YUV_444_888"
+        ImageFormat.YUY2 -> "YUY2"
+        ImageFormat.Y8 -> "Y8"
+        ImageFormat.JPEG -> "JPEG"
+        ImageFormat.RGB_565 -> "RGB_565"
+        ImageFormat.FLEX_RGB_888 -> "FLEX_RGB_888"
+        ImageFormat.FLEX_RGBA_8888 -> "FLEX_RGBA_8888"
+        PixelFormat.RGB_888 -> "RGB_888"
+        ImageFormat.PRIVATE -> "PRIVATE"
+        else -> "UNKNOWN ($format)"
+      }
+  }
+}
diff --git a/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/core/utils/OutputFile.kt b/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/core/utils/OutputFile.kt
new file mode 100644
index 0000000..1ed437a
--- /dev/null
+++ b/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/core/utils/OutputFile.kt
@@ -0,0 +1,15 @@
+package com.mrousavy.camera.core.utils
+
+import android.content.Context
+import java.io.File
+
+data class OutputFile(val context: Context, val directory: File, val extension: String) {
+  val file = File.createTempFile("mrousavy", extension, directory)
+
+  init {
+    if (directory.absolutePath.contains(context.cacheDir.absolutePath)) {
+      // If this is a temp file (inside temp directory), the file will be deleted once the app closes
+      file.deleteOnExit()
+    }
+  }
+}
diff --git a/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/core/utils/runOnUiThread.kt b/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/core/utils/runOnUiThread.kt
new file mode 100644
index 0000000..e96e78e
--- /dev/null
+++ b/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/core/utils/runOnUiThread.kt
@@ -0,0 +1,32 @@
+package com.mrousavy.camera.core.utils
+
+import com.facebook.react.bridge.UiThreadUtil
+import kotlin.coroutines.cancellation.CancellationException
+import kotlin.coroutines.resume
+import kotlinx.coroutines.suspendCancellableCoroutine
+
+suspend inline fun <T> runOnUiThreadAndWait(crossinline function: () -> T): T {
+  if (UiThreadUtil.isOnUiThread()) {
+    // We are already on UI Thread - immediately call the function
+    return function()
+  }
+
+  return suspendCancellableCoroutine { continuation ->
+    UiThreadUtil.runOnUiThread {
+      if (continuation.isCancelled) throw CancellationException()
+      val result = function()
+      continuation.resume(result)
+    }
+  }
+}
+
+inline fun runOnUiThread(crossinline function: () -> Unit) {
+  if (UiThreadUtil.isOnUiThread()) {
+    // We are already on UI Thread - immediately call the function
+    return function()
+  }
+
+  UiThreadUtil.runOnUiThread {
+    function()
+  }
+}
diff --git a/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/frameprocessors/Frame.class b/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/frameprocessors/Frame.class
new file mode 100644
index 0000000..4ec37c1
Binary files /dev/null and b/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/frameprocessors/Frame.class differ
diff --git a/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/frameprocessors/FrameProcessor.class b/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/frameprocessors/FrameProcessor.class
new file mode 100644
index 0000000..068f861
Binary files /dev/null and b/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/frameprocessors/FrameProcessor.class differ
diff --git a/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/frameprocessors/FrameProcessorPlugin.class b/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/frameprocessors/FrameProcessorPlugin.class
new file mode 100644
index 0000000..01f7d8c
Binary files /dev/null and b/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/frameprocessors/FrameProcessorPlugin.class differ
diff --git a/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/frameprocessors/FrameProcessorPluginRegistry$PluginInitializer.class b/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/frameprocessors/FrameProcessorPluginRegistry$PluginInitializer.class
new file mode 100644
index 0000000..ba2a435
Binary files /dev/null and b/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/frameprocessors/FrameProcessorPluginRegistry$PluginInitializer.class differ
diff --git a/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/frameprocessors/FrameProcessorPluginRegistry.class b/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/frameprocessors/FrameProcessorPluginRegistry.class
new file mode 100644
index 0000000..a630582
Binary files /dev/null and b/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/frameprocessors/FrameProcessorPluginRegistry.class differ
diff --git a/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/frameprocessors/SharedArray.class b/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/frameprocessors/SharedArray.class
new file mode 100644
index 0000000..ec7b323
Binary files /dev/null and b/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/frameprocessors/SharedArray.class differ
diff --git a/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/frameprocessors/VisionCameraInstaller.class b/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/frameprocessors/VisionCameraInstaller.class
new file mode 100644
index 0000000..8fdd6e0
Binary files /dev/null and b/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/frameprocessors/VisionCameraInstaller.class differ
diff --git a/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/frameprocessors/VisionCameraProxy.kt b/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/frameprocessors/VisionCameraProxy.kt
new file mode 100644
index 0000000..8de418b
--- /dev/null
+++ b/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/frameprocessors/VisionCameraProxy.kt
@@ -0,0 +1,78 @@
+package com.mrousavy.camera.frameprocessors
+
+import android.util.Log
+import androidx.annotation.Keep
+import androidx.annotation.UiThread
+import com.facebook.jni.HybridData
+import com.facebook.proguard.annotations.DoNotStrip
+import com.facebook.react.bridge.ReactApplicationContext
+import com.facebook.react.bridge.UiThreadUtil
+import com.facebook.react.common.annotations.FrameworkAPI
+import com.facebook.react.turbomodule.core.CallInvokerHolderImpl
+import com.facebook.react.uimanager.UIManagerHelper
+import com.mrousavy.camera.core.ViewNotFoundError
+import com.mrousavy.camera.react.CameraView
+import java.lang.ref.WeakReference
+
+@OptIn(FrameworkAPI::class)
+@Suppress("KotlinJniMissingFunction") // we use fbjni.
+class VisionCameraProxy(private val reactContext: ReactApplicationContext) {
+  companion object {
+    const val TAG = "VisionCameraProxy"
+  }
+
+  @DoNotStrip
+  @Keep
+  private var mHybridData: HybridData
+  private var mContext: WeakReference<ReactApplicationContext>
+  private var mScheduler: VisionCameraScheduler
+  val context: ReactApplicationContext
+    get() = reactContext
+
+  init {
+    val jsCallInvokerHolder = context.catalystInstance.jsCallInvokerHolder as CallInvokerHolderImpl
+    val jsRuntimeHolder =
+      context.javaScriptContextHolder?.get() ?: throw Error("JSI Runtime is null! VisionCamera does not yet support bridgeless mode..")
+    mScheduler = VisionCameraScheduler()
+    mContext = WeakReference(context)
+    mHybridData = initHybrid(jsRuntimeHolder, jsCallInvokerHolder, mScheduler)
+  }
+
+  @UiThread
+  private fun findCameraViewById(viewId: Int): CameraView {
+    Log.d(TAG, "Finding view $viewId...")
+    val ctx = mContext.get()
+    val view = if (ctx != null) UIManagerHelper.getUIManager(ctx, viewId)?.resolveView(viewId) as CameraView? else null
+    Log.d(TAG, if (view != null) "Found view $viewId!" else "Couldn't find view $viewId!")
+    return view ?: throw ViewNotFoundError(viewId)
+  }
+
+  @Suppress("unused")
+  @DoNotStrip
+  @Keep
+  fun setFrameProcessor(viewId: Int, frameProcessor: FrameProcessor) {
+    UiThreadUtil.runOnUiThread {
+      val view = findCameraViewById(viewId)
+      view.frameProcessor = frameProcessor
+    }
+  }
+
+  @Suppress("unused")
+  @DoNotStrip
+  @Keep
+  fun removeFrameProcessor(viewId: Int) {
+    UiThreadUtil.runOnUiThread {
+      val view = findCameraViewById(viewId)
+      view.frameProcessor = null
+    }
+  }
+
+  @Suppress("unused")
+  @DoNotStrip
+  @Keep
+  fun initFrameProcessorPlugin(name: String, options: Map<String, Any>): FrameProcessorPlugin? =
+    FrameProcessorPluginRegistry.getPlugin(name, this, options)
+
+  // private C++ funcs
+  private external fun initHybrid(jsContext: Long, jsCallInvokerHolder: CallInvokerHolderImpl, scheduler: VisionCameraScheduler): HybridData
+}
diff --git a/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/frameprocessors/VisionCameraScheduler.class b/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/frameprocessors/VisionCameraScheduler.class
new file mode 100644
index 0000000..85181c1
Binary files /dev/null and b/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/frameprocessors/VisionCameraScheduler.class differ
diff --git a/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/react/CameraDevicesManager.kt b/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/react/CameraDevicesManager.kt
new file mode 100644
index 0000000..21ac2b2
--- /dev/null
+++ b/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/react/CameraDevicesManager.kt
@@ -0,0 +1,125 @@
+package com.mrousavy.camera.react
+
+import android.content.Context
+import android.hardware.camera2.CameraManager
+import android.util.Log
+import androidx.camera.extensions.ExtensionsManager
+import androidx.camera.lifecycle.ProcessCameraProvider
+import com.facebook.react.bridge.Arguments
+import com.facebook.react.bridge.ReactApplicationContext
+import com.facebook.react.bridge.ReactContextBaseJavaModule
+import com.facebook.react.bridge.ReactMethod
+import com.facebook.react.bridge.ReadableArray
+import com.facebook.react.modules.core.DeviceEventManagerModule.RCTDeviceEventEmitter
+import com.mrousavy.camera.core.CameraDeviceDetails
+import com.mrousavy.camera.core.CameraQueues
+import com.mrousavy.camera.core.extensions.await
+import kotlinx.coroutines.CoroutineScope
+import kotlinx.coroutines.asCoroutineDispatcher
+import kotlinx.coroutines.launch
+
+class CameraDevicesManager(private val reactContext: ReactApplicationContext) : ReactContextBaseJavaModule(reactContext) {
+  companion object {
+    private const val TAG = "CameraDevices"
+  }
+  private val executor = CameraQueues.cameraExecutor
+  private val coroutineScope = CoroutineScope(executor.asCoroutineDispatcher())
+  private val cameraManager = reactContext.getSystemService(Context.CAMERA_SERVICE) as CameraManager
+  private var cameraProvider: ProcessCameraProvider? = null
+  private var extensionsManager: ExtensionsManager? = null
+
+  private val callback = object : CameraManager.AvailabilityCallback() {
+    private var deviceIds = cameraManager.cameraIdList.toMutableList()
+
+    // Check if device is still physically connected (even if onCameraUnavailable() is called)
+    private fun isDeviceConnected(cameraId: String): Boolean =
+      try {
+        cameraManager.getCameraCharacteristics(cameraId)
+        true
+      } catch (_: Throwable) {
+        false
+      }
+
+    override fun onCameraAvailable(cameraId: String) {
+      Log.i(TAG, "Camera #$cameraId is now available.")
+      if (!deviceIds.contains(cameraId)) {
+        deviceIds.add(cameraId)
+        sendAvailableDevicesChangedEvent()
+      }
+    }
+
+    override fun onCameraUnavailable(cameraId: String) {
+      Log.i(TAG, "Camera #$cameraId is now unavailable.")
+      if (deviceIds.contains(cameraId) && !isDeviceConnected(cameraId)) {
+        deviceIds.remove(cameraId)
+        sendAvailableDevicesChangedEvent()
+      }
+    }
+  }
+
+  override fun getName(): String = TAG
+
+  // Init cameraProvider + manager as early as possible
+  init {
+    coroutineScope.launch {
+      try {
+        Log.i(TAG, "Initializing ProcessCameraProvider...")
+        cameraProvider = ProcessCameraProvider.getInstance(reactContext).await(executor)
+        Log.i(TAG, "Initializing ExtensionsManager...")
+        extensionsManager = ExtensionsManager.getInstanceAsync(reactContext, cameraProvider!!).await(executor)
+        Log.i(TAG, "Successfully initialized!")
+      } catch (error: Throwable) {
+        Log.e(TAG, "Failed to initialize ProcessCameraProvider/ExtensionsManager! Error: ${error.message}", error)
+      }
+      sendAvailableDevicesChangedEvent()
+    }
+  }
+
+  // Note: initialize() will be called after getConstants on new arch!
+  override fun initialize() {
+    super.initialize()
+    cameraManager.registerAvailabilityCallback(callback, null)
+  }
+
+  override fun invalidate() {
+    cameraManager.unregisterAvailabilityCallback(callback)
+    super.invalidate()
+  }
+
+  private fun getDevicesJson(): ReadableArray {
+    val devices = Arguments.createArray()
+    val cameraProvider = cameraProvider ?: return devices
+    val extensionsManager = extensionsManager ?: return devices
+
+    cameraProvider.availableCameraInfos.forEach { cameraInfo ->
+      val device = CameraDeviceDetails(cameraInfo, extensionsManager)
+      devices.pushMap(device.toMap())
+    }
+    return devices
+  }
+
+  fun sendAvailableDevicesChangedEvent() {
+    val eventEmitter = reactContext.getJSModule(RCTDeviceEventEmitter::class.java)
+    val devices = getDevicesJson()
+    eventEmitter.emit("CameraDevicesChanged", devices)
+  }
+
+  override fun getConstants(): MutableMap<String, Any?> {
+    val devices = getDevicesJson()
+    val preferredDevice = if (devices.size() > 0) devices.getMap(0) else null
+
+    return mutableMapOf(
+      "availableCameraDevices" to devices,
+      "userPreferredCameraDevice" to preferredDevice?.toHashMap()
+    )
+  }
+
+  // Required for NativeEventEmitter, this is just a dummy implementation:
+  @Suppress("unused", "UNUSED_PARAMETER")
+  @ReactMethod
+  fun addListener(eventName: String) {}
+
+  @Suppress("unused", "UNUSED_PARAMETER")
+  @ReactMethod
+  fun removeListeners(count: Int) {}
+}
diff --git a/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/react/CameraPackage.kt b/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/react/CameraPackage.kt
new file mode 100644
index 0000000..ca2e06c
--- /dev/null
+++ b/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/react/CameraPackage.kt
@@ -0,0 +1,16 @@
+package com.mrousavy.camera.react
+
+import com.facebook.react.ReactPackage
+import com.facebook.react.bridge.NativeModule
+import com.facebook.react.bridge.ReactApplicationContext
+import com.facebook.react.uimanager.ViewManager
+
+class CameraPackage : ReactPackage {
+  override fun createNativeModules(reactContext: ReactApplicationContext): List<NativeModule> =
+    listOf(
+      CameraViewModule(reactContext),
+      CameraDevicesManager(reactContext)
+    )
+
+  override fun createViewManagers(reactContext: ReactApplicationContext): List<ViewManager<*, *>> = listOf(CameraViewManager())
+}
diff --git a/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/react/CameraView+Events.kt b/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/react/CameraView+Events.kt
new file mode 100644
index 0000000..aacb5c7
--- /dev/null
+++ b/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/react/CameraView+Events.kt
@@ -0,0 +1,185 @@
+package com.mrousavy.camera.react
+
+import android.util.Log
+import com.facebook.react.bridge.Arguments
+import com.facebook.react.bridge.ReactContext
+import com.facebook.react.bridge.WritableMap
+import com.facebook.react.uimanager.UIManagerHelper
+import com.facebook.react.uimanager.events.Event
+import com.google.mlkit.vision.barcode.common.Barcode
+import com.mrousavy.camera.core.CameraError
+import com.mrousavy.camera.core.CodeScannerFrame
+import com.mrousavy.camera.core.UnknownCameraError
+import com.mrousavy.camera.core.types.CodeType
+import com.mrousavy.camera.core.types.Orientation
+import com.mrousavy.camera.core.types.ShutterType
+
+fun CameraView.invokeOnInitialized() {
+  Log.i(CameraView.TAG, "invokeOnInitialized()")
+
+  val surfaceId = UIManagerHelper.getSurfaceId(this)
+  val event = CameraInitializedEvent(surfaceId, id)
+  this.sendEvent(event)
+}
+
+fun CameraView.invokeOnStarted() {
+  Log.i(CameraView.TAG, "invokeOnStarted()")
+
+  val surfaceId = UIManagerHelper.getSurfaceId(this)
+  val event = CameraStartedEvent(surfaceId, id)
+  this.sendEvent(event)
+}
+
+fun CameraView.invokeOnStopped() {
+  Log.i(CameraView.TAG, "invokeOnStopped()")
+
+  val surfaceId = UIManagerHelper.getSurfaceId(this)
+  val event = CameraStoppedEvent(surfaceId, id)
+  this.sendEvent(event)
+}
+
+fun CameraView.invokeOnPreviewStarted() {
+  Log.i(CameraView.TAG, "invokeOnPreviewStarted()")
+
+  val surfaceId = UIManagerHelper.getSurfaceId(this)
+  val event = CameraPreviewStartedEvent(surfaceId, id)
+  this.sendEvent(event)
+}
+
+fun CameraView.invokeOnPreviewStopped() {
+  Log.i(CameraView.TAG, "invokeOnPreviewStopped()")
+
+  val surfaceId = UIManagerHelper.getSurfaceId(this)
+  val event = CameraPreviewStoppedEvent(surfaceId, id)
+  this.sendEvent(event)
+}
+
+fun CameraView.invokeOnShutter(type: ShutterType) {
+  Log.i(CameraView.TAG, "invokeOnShutter($type)")
+
+  val surfaceId = UIManagerHelper.getSurfaceId(this)
+  val data = Arguments.createMap()
+  data.putString("type", type.unionValue)
+
+  val event = CameraShutterEvent(surfaceId, id, data)
+  this.sendEvent(event)
+}
+
+fun CameraView.invokeOnOutputOrientationChanged(outputOrientation: Orientation) {
+  Log.i(CameraView.TAG, "invokeOnOutputOrientationChanged($outputOrientation)")
+
+  val surfaceId = UIManagerHelper.getSurfaceId(this)
+  val data = Arguments.createMap()
+  data.putString("outputOrientation", outputOrientation.unionValue)
+
+  val event = CameraOutputOrientationChangedEvent(surfaceId, id, data)
+  this.sendEvent(event)
+}
+
+fun CameraView.invokeOnPreviewOrientationChanged(previewOrientation: Orientation) {
+  Log.i(CameraView.TAG, "invokeOnPreviewOrientationChanged($previewOrientation)")
+
+  val surfaceId = UIManagerHelper.getSurfaceId(this)
+  val data = Arguments.createMap()
+  data.putString("previewOrientation", previewOrientation.unionValue)
+
+  val event = CameraPreviewOrientationChangedEvent(surfaceId, id, data)
+  this.sendEvent(event)
+}
+
+fun CameraView.invokeOnError(error: Throwable) {
+  Log.e(CameraView.TAG, "invokeOnError(...):")
+  error.printStackTrace()
+
+  val cameraError =
+    when (error) {
+      is CameraError -> error
+      else -> UnknownCameraError(error)
+    }
+  val data = Arguments.createMap()
+  data.putString("code", cameraError.code)
+  data.putString("message", cameraError.message)
+  cameraError.cause?.let { cause ->
+    data.putMap("cause", errorToMap(cause))
+  }
+
+  val surfaceId = UIManagerHelper.getSurfaceId(this)
+  val event = CameraErrorEvent(surfaceId, id, data)
+  this.sendEvent(event)
+}
+
+fun CameraView.invokeOnViewReady() {
+  val surfaceId = UIManagerHelper.getSurfaceId(this)
+  val event = CameraViewReadyEvent(surfaceId, id)
+  this.sendEvent(event)
+}
+
+fun CameraView.invokeOnAverageFpsChanged(averageFps: Double) {
+  Log.i(CameraView.TAG, "invokeOnAverageFpsChanged($averageFps)")
+
+  val surfaceId = UIManagerHelper.getSurfaceId(this)
+  val data = Arguments.createMap()
+  data.putDouble("averageFps", averageFps)
+
+  val event = AverageFpsChangedEvent(surfaceId, id, data)
+  this.sendEvent(event)
+}
+
+fun CameraView.invokeOnCodeScanned(barcodes: List<Barcode>, scannerFrame: CodeScannerFrame) {
+  val codes = Arguments.createArray()
+  barcodes.forEach { barcode ->
+    val code = Arguments.createMap()
+    val type = CodeType.fromBarcodeType(barcode.format)
+    code.putString("type", type.unionValue)
+    code.putString("value", barcode.rawValue)
+
+    barcode.boundingBox?.let { rect ->
+      val frame = Arguments.createMap()
+      frame.putInt("x", rect.left)
+      frame.putInt("y", rect.top)
+      frame.putInt("width", rect.right - rect.left)
+      frame.putInt("height", rect.bottom - rect.top)
+      code.putMap("frame", frame)
+    }
+
+    barcode.cornerPoints?.let { points ->
+      val corners = Arguments.createArray()
+      points.forEach { point ->
+        val pt = Arguments.createMap()
+        pt.putInt("x", point.x)
+        pt.putInt("y", point.y)
+        corners.pushMap(pt)
+      }
+      code.putArray("corners", corners)
+    }
+    codes.pushMap(code)
+  }
+
+  val data = Arguments.createMap()
+  data.putArray("codes", codes)
+  val codeScannerFrame = Arguments.createMap()
+  codeScannerFrame.putInt("width", scannerFrame.width)
+  codeScannerFrame.putInt("height", scannerFrame.height)
+  data.putMap("frame", codeScannerFrame)
+
+  val surfaceId = UIManagerHelper.getSurfaceId(this)
+  val event = CameraCodeScannedEvent(surfaceId, id, data)
+  this.sendEvent(event)
+}
+
+private fun CameraView.sendEvent(event: Event<*>) {
+  val reactContext = context as ReactContext
+  val dispatcher =
+    UIManagerHelper.getEventDispatcherForReactTag(reactContext, id)
+  dispatcher?.dispatchEvent(event)
+}
+
+private fun errorToMap(error: Throwable): WritableMap {
+  val map = Arguments.createMap()
+  map.putString("message", error.message)
+  map.putString("stacktrace", error.stackTraceToString())
+  error.cause?.let { cause ->
+    map.putMap("cause", errorToMap(cause))
+  }
+  return map
+}
diff --git a/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/react/CameraView+Focus.kt b/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/react/CameraView+Focus.kt
new file mode 100644
index 0000000..a9d5683
--- /dev/null
+++ b/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/react/CameraView+Focus.kt
@@ -0,0 +1,19 @@
+package com.mrousavy.camera.react
+
+import android.content.res.Resources
+import com.facebook.react.bridge.ReadableMap
+import com.mrousavy.camera.core.FocusRequiresPreviewError
+import com.mrousavy.camera.core.focus
+import com.mrousavy.camera.core.utils.runOnUiThreadAndWait
+
+suspend fun CameraView.focus(pointMap: ReadableMap) {
+  val x = pointMap.getDouble("x")
+  val y = pointMap.getDouble("y")
+  val previewView = previewView ?: throw FocusRequiresPreviewError()
+
+  val point = runOnUiThreadAndWait {
+    val dp = Resources.getSystem().displayMetrics.density
+    previewView.meteringPointFactory.createPoint(x.toFloat() * dp, y.toFloat() * dp)
+  }
+  cameraSession.focus(point)
+}
diff --git a/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/react/CameraView+RecordVideo.kt b/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/react/CameraView+RecordVideo.kt
new file mode 100644
index 0000000..e2e16e4
--- /dev/null
+++ b/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/react/CameraView+RecordVideo.kt
@@ -0,0 +1,56 @@
+package com.mrousavy.camera.react
+
+import android.Manifest
+import android.content.pm.PackageManager
+import androidx.core.content.ContextCompat
+import com.facebook.react.bridge.Arguments
+import com.facebook.react.bridge.Callback
+import com.mrousavy.camera.core.CameraError
+import com.mrousavy.camera.core.MicrophonePermissionError
+import com.mrousavy.camera.core.cancelRecording
+import com.mrousavy.camera.core.pauseRecording
+import com.mrousavy.camera.core.resumeRecording
+import com.mrousavy.camera.core.startRecording
+import com.mrousavy.camera.core.stopRecording
+import com.mrousavy.camera.core.types.RecordVideoOptions
+import com.mrousavy.camera.core.types.Video
+import com.mrousavy.camera.react.utils.makeErrorMap
+
+fun CameraView.startRecording(options: RecordVideoOptions, onRecordCallback: Callback) {
+  // check audio permission
+  if (audio) {
+    if (ContextCompat.checkSelfPermission(context, Manifest.permission.RECORD_AUDIO) != PackageManager.PERMISSION_GRANTED) {
+      throw MicrophonePermissionError()
+    }
+  }
+
+  val callback = { video: Video ->
+    val map = Arguments.createMap()
+    map.putString("path", video.path)
+    map.putDouble("duration", video.durationMs.toDouble() / 1000.0)
+    map.putInt("width", video.size.width)
+    map.putInt("height", video.size.height)
+    onRecordCallback(map, null)
+  }
+  val onError = { error: CameraError ->
+    val errorMap = makeErrorMap(error.code, error.message)
+    onRecordCallback(null, errorMap)
+  }
+  cameraSession.startRecording(audio, options, callback, onError)
+}
+
+fun CameraView.pauseRecording() {
+  cameraSession.pauseRecording()
+}
+
+fun CameraView.resumeRecording() {
+  cameraSession.resumeRecording()
+}
+
+fun CameraView.stopRecording() {
+  cameraSession.stopRecording()
+}
+
+fun CameraView.cancelRecording() {
+  cameraSession.cancelRecording()
+}
diff --git a/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/react/CameraView+TakePhoto.kt b/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/react/CameraView+TakePhoto.kt
new file mode 100644
index 0000000..b1445bb
--- /dev/null
+++ b/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/react/CameraView+TakePhoto.kt
@@ -0,0 +1,32 @@
+package com.mrousavy.camera.react
+
+import android.annotation.SuppressLint
+import android.util.Log
+import com.facebook.react.bridge.Arguments
+import com.facebook.react.bridge.ReadableMap
+import com.facebook.react.bridge.WritableMap
+import com.mrousavy.camera.core.takePhoto
+import com.mrousavy.camera.core.types.TakePhotoOptions
+
+private const val TAG = "CameraView.takePhoto"
+
+@SuppressLint("UnsafeOptInUsageError")
+suspend fun CameraView.takePhoto(optionsMap: ReadableMap): WritableMap {
+  Log.i(TAG, "Taking photo... Options: ${optionsMap.toHashMap()}")
+
+  // Parse options and shoot photo
+  val options = TakePhotoOptions.fromJS(context, optionsMap)
+  val photo = cameraSession.takePhoto(options)
+
+  Log.i(TAG, "Successfully captured ${photo.width} x ${photo.height} photo!")
+
+  val map = Arguments.createMap()
+  map.putString("path", photo.path)
+  map.putInt("width", photo.width)
+  map.putInt("height", photo.height)
+  map.putString("orientation", photo.orientation.unionValue)
+  map.putBoolean("isRawPhoto", false)
+  map.putBoolean("isMirrored", photo.isMirrored)
+
+  return map
+}
diff --git a/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/react/CameraView+TakeSnapshot.kt b/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/react/CameraView+TakeSnapshot.kt
new file mode 100644
index 0000000..212d296
--- /dev/null
+++ b/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/react/CameraView+TakeSnapshot.kt
@@ -0,0 +1,37 @@
+package com.mrousavy.camera.react
+
+import android.util.Log
+import com.facebook.react.bridge.Arguments
+import com.facebook.react.bridge.WritableMap
+import com.mrousavy.camera.core.SnapshotFailedError
+import com.mrousavy.camera.core.SnapshotFailedPreviewNotEnabledError
+import com.mrousavy.camera.core.types.ShutterType
+import com.mrousavy.camera.core.types.TakeSnapshotOptions
+import com.mrousavy.camera.core.utils.FileUtils
+
+private const val TAG = "CameraView.takeSnapshot"
+
+fun CameraView.takeSnapshot(options: TakeSnapshotOptions): WritableMap {
+  Log.i(TAG, "Capturing snapshot of Camera View...")
+  val previewView = previewView ?: throw SnapshotFailedPreviewNotEnabledError()
+  val bitmap = previewView.bitmap ?: throw SnapshotFailedError()
+
+  // Shutter Event (JS)
+  onShutter(ShutterType.SNAPSHOT)
+
+  // Write snapshot to .jpg file
+  FileUtils.writeBitmapTofile(bitmap, options.file.file, options.quality)
+
+  Log.i(TAG, "Successfully saved snapshot to file!")
+
+  val orientation = cameraSession.outputOrientation
+
+  // Parse output data
+  val map = Arguments.createMap()
+  map.putString("path", options.file.file.absolutePath)
+  map.putInt("width", bitmap.width)
+  map.putInt("height", bitmap.height)
+  map.putString("orientation", orientation.unionValue)
+  map.putBoolean("isMirrored", false)
+  return map
+}
diff --git a/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/react/CameraView.kt b/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/react/CameraView.kt
new file mode 100644
index 0000000..64a751e
--- /dev/null
+++ b/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/react/CameraView.kt
@@ -0,0 +1,353 @@
+package com.mrousavy.camera.react
+
+import android.annotation.SuppressLint
+import android.content.Context
+import android.util.Log
+import android.view.Gravity
+import android.view.ScaleGestureDetector
+import android.widget.FrameLayout
+import androidx.camera.view.PreviewView
+import com.google.mlkit.vision.barcode.common.Barcode
+import com.mrousavy.camera.core.CameraConfiguration
+import com.mrousavy.camera.core.CameraSession
+import com.mrousavy.camera.core.CodeScannerFrame
+import com.mrousavy.camera.core.types.CameraDeviceFormat
+import com.mrousavy.camera.core.types.CodeScannerOptions
+import com.mrousavy.camera.core.types.Orientation
+import com.mrousavy.camera.core.types.OutputOrientation
+import com.mrousavy.camera.core.types.PixelFormat
+import com.mrousavy.camera.core.types.PreviewViewType
+import com.mrousavy.camera.core.types.QualityBalance
+import com.mrousavy.camera.core.types.ResizeMode
+import com.mrousavy.camera.core.types.ShutterType
+import com.mrousavy.camera.core.types.Torch
+import com.mrousavy.camera.core.types.VideoStabilizationMode
+import com.mrousavy.camera.frameprocessors.Frame
+import com.mrousavy.camera.frameprocessors.FrameProcessor
+import com.mrousavy.camera.react.extensions.installHierarchyFitter
+import kotlinx.coroutines.CoroutineScope
+import kotlinx.coroutines.Dispatchers
+import kotlinx.coroutines.launch
+
+//
+// TODOs for the CameraView which are currently too hard to implement either because of CameraX' limitations, or my brain capacity.
+//
+// TODO: High-speed video recordings (export in CameraViewModule::getAvailableVideoDevices(), and set in CameraView::configurePreview()) (120FPS+)
+// TODO: Better startRecording()/stopRecording() (promise + callback, wait for TurboModules/JSI)
+// TODO: takePhoto() depth data
+// TODO: takePhoto() raw capture
+// TODO: takePhoto() return with jsi::Value Image reference for faster capture
+// TODO: Support videoCodec on Android
+
+@SuppressLint("ClickableViewAccessibility", "ViewConstructor", "MissingPermission")
+class CameraView(context: Context) :
+  FrameLayout(context),
+  CameraSession.Callback,
+  FpsSampleCollector.Callback {
+  companion object {
+    const val TAG = "CameraView"
+  }
+
+  // react properties
+  // props that require reconfiguring
+  var cameraId: String? = null
+  var enableDepthData = false
+  var enablePortraitEffectsMatteDelivery = false
+  var isMirrored = false
+
+  // use-cases
+  var photo = false
+  var video = false
+  var audio = false
+  var enableFrameProcessor = false
+  var pixelFormat: PixelFormat = PixelFormat.YUV
+  var enableLocation = false
+  var preview = true
+    set(value) {
+      field = value
+      updatePreview()
+    }
+
+  // props that require format reconfiguring
+  var format: CameraDeviceFormat? = null
+  var minFps: Int? = null
+  var maxFps: Int? = null
+  var videoStabilizationMode: VideoStabilizationMode? = null
+  var videoHdr = false
+  var photoHdr = false
+  var videoBitRateOverride: Double? = null
+  var videoBitRateMultiplier: Double? = null
+
+  // TODO: Use .BALANCED once CameraX fixes it https://issuetracker.google.com/issues/337214687
+  var photoQualityBalance = QualityBalance.SPEED
+  var lowLightBoost = false
+
+  // other props
+  var isActive = false
+  var torch: Torch = Torch.OFF
+  var zoom: Float = 1f // in "factor"
+  var exposure: Double = 0.0
+  var outputOrientation: OutputOrientation = OutputOrientation.DEVICE
+  var androidPreviewViewType: PreviewViewType = PreviewViewType.SURFACE_VIEW
+    set(value) {
+      field = value
+      updatePreview()
+    }
+  var enableZoomGesture = false
+    set(value) {
+      field = value
+      updateZoomGesture()
+    }
+  var resizeMode: ResizeMode = ResizeMode.COVER
+    set(value) {
+      field = value
+      updatePreview()
+    }
+
+  // code scanner
+  var codeScannerOptions: CodeScannerOptions? = null
+
+  // private properties
+  private var isMounted = false
+  private val mainCoroutineScope = CoroutineScope(Dispatchers.Main)
+
+  // session
+  internal val cameraSession: CameraSession
+  internal var frameProcessor: FrameProcessor? = null
+  internal var previewView: PreviewView? = null
+  private var currentConfigureCall: Long = System.currentTimeMillis()
+  private val fpsSampleCollector = FpsSampleCollector(this)
+
+  init {
+    clipToOutline = true
+    cameraSession = CameraSession(context, this)
+    this.installHierarchyFitter()
+    updatePreview()
+  }
+
+  override fun onAttachedToWindow() {
+    Log.i(TAG, "CameraView attached to window!")
+    super.onAttachedToWindow()
+    if (!isMounted) {
+      // Notifies JS view that the native view is now available
+      isMounted = true
+      invokeOnViewReady()
+    }
+    // start collecting FPS samples
+    fpsSampleCollector.start()
+  }
+
+  override fun onDetachedFromWindow() {
+    Log.i(TAG, "CameraView detached from window!")
+    super.onDetachedFromWindow()
+    // stop collecting FPS samples
+    fpsSampleCollector.stop()
+  }
+
+  fun destroy() {
+    cameraSession.close()
+  }
+
+  fun update() {
+    Log.i(TAG, "Updating CameraSession...")
+    val now = System.currentTimeMillis()
+    currentConfigureCall = now
+
+    mainCoroutineScope.launch {
+      cameraSession.configure { config ->
+        if (currentConfigureCall != now) {
+          // configure waits for a lock, and if a new call to update() happens in the meantime we can drop this one.
+          // this works similar to how React implemented concurrent rendering, the newer call to update() has higher priority.
+          Log.i(TAG, "A new configure { ... } call arrived, aborting this one...")
+          throw CameraConfiguration.AbortThrow()
+        }
+
+        // Input Camera Device
+        config.cameraId = cameraId
+
+        // Preview
+        val previewView = previewView
+        if (previewView != null) {
+          config.preview = CameraConfiguration.Output.Enabled.create(CameraConfiguration.Preview(previewView.surfaceProvider))
+        } else {
+          config.preview = CameraConfiguration.Output.Disabled.create()
+        }
+
+        // Photo
+        if (photo) {
+          config.photo = CameraConfiguration.Output.Enabled.create(CameraConfiguration.Photo(isMirrored, photoHdr, photoQualityBalance))
+        } else {
+          config.photo = CameraConfiguration.Output.Disabled.create()
+        }
+
+        // Video
+        if (video || enableFrameProcessor) {
+          config.video =
+            CameraConfiguration.Output.Enabled.create(
+              CameraConfiguration.Video(isMirrored, videoHdr, videoBitRateOverride, videoBitRateMultiplier)
+            )
+        } else {
+          config.video = CameraConfiguration.Output.Disabled.create()
+        }
+
+        // Frame Processor
+        if (enableFrameProcessor) {
+          config.frameProcessor = CameraConfiguration.Output.Enabled.create(CameraConfiguration.FrameProcessor(isMirrored, pixelFormat))
+        } else {
+          config.frameProcessor = CameraConfiguration.Output.Disabled.create()
+        }
+
+        // Audio
+        if (audio) {
+          config.audio = CameraConfiguration.Output.Enabled.create(CameraConfiguration.Audio(Unit))
+        } else {
+          config.audio = CameraConfiguration.Output.Disabled.create()
+        }
+
+        // Location
+        config.enableLocation = enableLocation && this@CameraView.isActive
+
+        // Code Scanner
+        val codeScanner = codeScannerOptions
+        if (codeScanner != null) {
+          config.codeScanner = CameraConfiguration.Output.Enabled.create(
+            CameraConfiguration.CodeScanner(codeScanner.codeTypes)
+          )
+        } else {
+          config.codeScanner = CameraConfiguration.Output.Disabled.create()
+        }
+
+        // Orientation
+        config.outputOrientation = outputOrientation
+
+        // Format
+        config.format = format
+
+        // Side-Props
+        config.minFps = minFps
+        config.maxFps = maxFps
+        config.enableLowLightBoost = lowLightBoost
+        config.torch = torch
+        config.exposure = exposure
+
+        // Zoom
+        config.zoom = zoom
+
+        // isActive
+        config.isActive = this@CameraView.isActive
+      }
+    }
+  }
+
+  @SuppressLint("ClickableViewAccessibility")
+  private fun updateZoomGesture() {
+    if (enableZoomGesture) {
+      val scaleGestureDetector = ScaleGestureDetector(
+        context,
+        object : ScaleGestureDetector.SimpleOnScaleGestureListener() {
+          override fun onScale(detector: ScaleGestureDetector): Boolean {
+            zoom *= detector.scaleFactor
+            update()
+            return true
+          }
+        }
+      )
+      setOnTouchListener { _, event ->
+        scaleGestureDetector.onTouchEvent(event)
+      }
+    } else {
+      setOnTouchListener(null)
+    }
+  }
+
+  private fun updatePreview() {
+    mainCoroutineScope.launch {
+      if (preview && previewView == null) {
+        // User enabled Preview, add the PreviewView
+        previewView = createPreviewView()
+        addView(previewView)
+      } else if (!preview && previewView != null) {
+        // User disabled Preview, remove the PreviewView
+        removeView(previewView)
+        previewView = null
+      }
+      previewView?.let {
+        // Update implementation type from React
+        it.implementationMode = androidPreviewViewType.toPreviewImplementationMode()
+        // Update scale type from React
+        it.scaleType = resizeMode.toScaleType()
+      }
+      update()
+    }
+  }
+
+  private fun createPreviewView(): PreviewView =
+    PreviewView(context).also {
+      it.installHierarchyFitter()
+      it.implementationMode = androidPreviewViewType.toPreviewImplementationMode()
+      it.layoutParams = LayoutParams(
+        LayoutParams.MATCH_PARENT,
+        LayoutParams.MATCH_PARENT,
+        Gravity.CENTER
+      )
+      var lastIsPreviewing = false
+      it.previewStreamState.observe(cameraSession) { state ->
+        Log.i(TAG, "PreviewView Stream State changed to $state")
+
+        val isPreviewing = state == PreviewView.StreamState.STREAMING
+        if (isPreviewing != lastIsPreviewing) {
+          // Notify callback
+          if (isPreviewing) {
+            invokeOnPreviewStarted()
+          } else {
+            invokeOnPreviewStopped()
+          }
+          lastIsPreviewing = isPreviewing
+        }
+      }
+    }
+
+  override fun onFrame(frame: Frame) {
+    // Update average FPS samples
+    fpsSampleCollector.onTick()
+
+    // Call JS Frame Processor
+    frameProcessor?.call(frame)
+  }
+
+  override fun onError(error: Throwable) {
+    invokeOnError(error)
+  }
+
+  override fun onInitialized() {
+    invokeOnInitialized()
+  }
+
+  override fun onStarted() {
+    invokeOnStarted()
+  }
+
+  override fun onStopped() {
+    invokeOnStopped()
+  }
+
+  override fun onShutter(type: ShutterType) {
+    invokeOnShutter(type)
+  }
+
+  override fun onOutputOrientationChanged(outputOrientation: Orientation) {
+    invokeOnOutputOrientationChanged(outputOrientation)
+  }
+
+  override fun onPreviewOrientationChanged(previewOrientation: Orientation) {
+    invokeOnPreviewOrientationChanged(previewOrientation)
+  }
+
+  override fun onCodeScanned(codes: List<Barcode>, scannerFrame: CodeScannerFrame) {
+    invokeOnCodeScanned(codes, scannerFrame)
+  }
+
+  override fun onAverageFpsChanged(averageFps: Double) {
+    invokeOnAverageFpsChanged(averageFps)
+  }
+}
diff --git a/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/react/CameraViewManager.kt b/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/react/CameraViewManager.kt
new file mode 100644
index 0000000..cc20b40
--- /dev/null
+++ b/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/react/CameraViewManager.kt
@@ -0,0 +1,261 @@
+package com.mrousavy.camera.react
+
+import com.facebook.react.bridge.ReadableMap
+import com.facebook.react.common.MapBuilder
+import com.facebook.react.uimanager.ThemedReactContext
+import com.facebook.react.uimanager.ViewGroupManager
+import com.facebook.react.uimanager.annotations.ReactProp
+import com.mrousavy.camera.core.types.CameraDeviceFormat
+import com.mrousavy.camera.core.types.CodeScannerOptions
+import com.mrousavy.camera.core.types.OutputOrientation
+import com.mrousavy.camera.core.types.PixelFormat
+import com.mrousavy.camera.core.types.PreviewViewType
+import com.mrousavy.camera.core.types.QualityBalance
+import com.mrousavy.camera.core.types.ResizeMode
+import com.mrousavy.camera.core.types.Torch
+import com.mrousavy.camera.core.types.VideoStabilizationMode
+
+@Suppress("unused")
+class CameraViewManager : ViewGroupManager<CameraView>() {
+  companion object {
+    const val TAG = "CameraView"
+  }
+  public override fun createViewInstance(context: ThemedReactContext): CameraView = CameraView(context)
+
+  override fun onAfterUpdateTransaction(view: CameraView) {
+    super.onAfterUpdateTransaction(view)
+    view.update()
+  }
+
+  override fun getExportedCustomDirectEventTypeConstants(): Map<String, Any>? =
+    MapBuilder.builder<String, Any>()
+      .put(CameraViewReadyEvent.EVENT_NAME, MapBuilder.of("registrationName", "onViewReady"))
+      .put(CameraInitializedEvent.EVENT_NAME, MapBuilder.of("registrationName", "onInitialized"))
+      .put(CameraStartedEvent.EVENT_NAME, MapBuilder.of("registrationName", "onStarted"))
+      .put(CameraStoppedEvent.EVENT_NAME, MapBuilder.of("registrationName", "onStopped"))
+      .put(CameraShutterEvent.EVENT_NAME, MapBuilder.of("registrationName", "onShutter"))
+      .put(CameraErrorEvent.EVENT_NAME, MapBuilder.of("registrationName", "onError"))
+      .put(CameraCodeScannedEvent.EVENT_NAME, MapBuilder.of("registrationName", "onCodeScanned"))
+      .put(CameraPreviewStartedEvent.EVENT_NAME, MapBuilder.of("registrationName", "onPreviewStarted"))
+      .put(CameraPreviewStoppedEvent.EVENT_NAME, MapBuilder.of("registrationName", "onPreviewStopped"))
+      .put(CameraOutputOrientationChangedEvent.EVENT_NAME, MapBuilder.of("registrationName", "onOutputOrientationChanged"))
+      .put(CameraPreviewOrientationChangedEvent.EVENT_NAME, MapBuilder.of("registrationName", "onPreviewOrientationChanged"))
+      .put(AverageFpsChangedEvent.EVENT_NAME, MapBuilder.of("registrationName", "onAverageFpsChanged"))
+      .build()
+
+  override fun getName(): String = TAG
+
+  override fun onDropViewInstance(view: CameraView) {
+    view.destroy()
+    super.onDropViewInstance(view)
+  }
+
+  @ReactProp(name = "cameraId")
+  fun setCameraId(view: CameraView, cameraId: String) {
+    view.cameraId = cameraId
+  }
+
+  @ReactProp(name = "isMirrored")
+  fun setIsMirrored(view: CameraView, isMirrored: Boolean) {
+    view.isMirrored = isMirrored
+  }
+
+  @ReactProp(name = "preview", defaultBoolean = true)
+  fun setPreview(view: CameraView, preview: Boolean) {
+    view.preview = preview
+  }
+
+  @ReactProp(name = "photo")
+  fun setPhoto(view: CameraView, photo: Boolean) {
+    view.photo = photo
+  }
+
+  @ReactProp(name = "video")
+  fun setVideo(view: CameraView, video: Boolean) {
+    view.video = video
+  }
+
+  @ReactProp(name = "audio")
+  fun setAudio(view: CameraView, audio: Boolean) {
+    view.audio = audio
+  }
+
+  @ReactProp(name = "enableLocation")
+  fun setEnableLocation(view: CameraView, enableLocation: Boolean) {
+    view.enableLocation = enableLocation
+  }
+
+  @ReactProp(name = "enableFrameProcessor")
+  fun setEnableFrameProcessor(view: CameraView, enableFrameProcessor: Boolean) {
+    view.enableFrameProcessor = enableFrameProcessor
+  }
+
+  @ReactProp(name = "pixelFormat")
+  fun setPixelFormat(view: CameraView, pixelFormat: String?) {
+    if (pixelFormat != null) {
+      val newPixelFormat = PixelFormat.fromUnionValue(pixelFormat)
+      view.pixelFormat = newPixelFormat
+    } else {
+      view.pixelFormat = PixelFormat.YUV
+    }
+  }
+
+  @ReactProp(name = "enableDepthData")
+  fun setEnableDepthData(view: CameraView, enableDepthData: Boolean) {
+    view.enableDepthData = enableDepthData
+  }
+
+  @ReactProp(name = "enableZoomGesture")
+  fun setEnableZoomGesture(view: CameraView, enableZoomGesture: Boolean) {
+    view.enableZoomGesture = enableZoomGesture
+  }
+
+  @ReactProp(name = "videoStabilizationMode")
+  fun setVideoStabilizationMode(view: CameraView, videoStabilizationMode: String?) {
+    if (videoStabilizationMode != null) {
+      val newMode = VideoStabilizationMode.fromUnionValue(videoStabilizationMode)
+      view.videoStabilizationMode = newMode
+    } else {
+      view.videoStabilizationMode = null
+    }
+  }
+
+  @ReactProp(name = "enablePortraitEffectsMatteDelivery")
+  fun setEnablePortraitEffectsMatteDelivery(view: CameraView, enablePortraitEffectsMatteDelivery: Boolean) {
+    view.enablePortraitEffectsMatteDelivery = enablePortraitEffectsMatteDelivery
+  }
+
+  @ReactProp(name = "format")
+  fun setFormat(view: CameraView, format: ReadableMap?) {
+    if (format != null) {
+      val newFormat = CameraDeviceFormat.fromJSValue(format)
+      view.format = newFormat
+    } else {
+      view.format = null
+    }
+  }
+
+  @ReactProp(name = "resizeMode")
+  fun setResizeMode(view: CameraView, resizeMode: String?) {
+    if (resizeMode != null) {
+      val newMode = ResizeMode.fromUnionValue(resizeMode)
+      view.resizeMode = newMode
+    } else {
+      view.resizeMode = ResizeMode.COVER
+    }
+  }
+
+  @ReactProp(name = "androidPreviewViewType")
+  fun setAndroidPreviewViewType(view: CameraView, androidPreviewViewType: String?) {
+    if (androidPreviewViewType != null) {
+      val newMode = PreviewViewType.fromUnionValue(androidPreviewViewType)
+      view.androidPreviewViewType = newMode
+    } else {
+      view.androidPreviewViewType = PreviewViewType.SURFACE_VIEW
+    }
+  }
+
+  // TODO: Change when TurboModules release.
+  // We're treating -1 as "null" here, because when I make the fps parameter
+  // of type "Int?" the react bridge throws an error.
+  @ReactProp(name = "minFps", defaultInt = -1)
+  fun setMinFps(view: CameraView, minFps: Int) {
+    view.minFps = if (minFps > 0) minFps else null
+  }
+
+  // TODO: Change when TurboModules release.
+  // We're treating -1 as "null" here, because when I make the fps parameter
+  // of type "Int?" the react bridge throws an error.
+  @ReactProp(name = "maxFps", defaultInt = -1)
+  fun setMaxFps(view: CameraView, maxFps: Int) {
+    view.maxFps = if (maxFps > 0) maxFps else null
+  }
+
+  @ReactProp(name = "photoHdr")
+  fun setPhotoHdr(view: CameraView, photoHdr: Boolean) {
+    view.photoHdr = photoHdr
+  }
+
+  @ReactProp(name = "photoQualityBalance")
+  fun setPhotoQualityBalance(view: CameraView, photoQualityBalance: String?) {
+    if (photoQualityBalance != null) {
+      val newMode = QualityBalance.fromUnionValue(photoQualityBalance)
+      view.photoQualityBalance = newMode
+    } else {
+      view.photoQualityBalance = QualityBalance.BALANCED
+    }
+  }
+
+  @ReactProp(name = "videoHdr")
+  fun setVideoHdr(view: CameraView, videoHdr: Boolean) {
+    view.videoHdr = videoHdr
+  }
+
+  @ReactProp(name = "videoBitRateOverride", defaultDouble = -1.0)
+  fun setVideoBitRateOverride(view: CameraView, videoBitRateOverride: Double) {
+    if (videoBitRateOverride != -1.0) {
+      view.videoBitRateOverride = videoBitRateOverride
+    } else {
+      view.videoBitRateOverride = null
+    }
+  }
+
+  @ReactProp(name = "videoBitRateMultiplier", defaultDouble = -1.0)
+  fun setVideoBitRateMultiplier(view: CameraView, videoBitRateMultiplier: Double) {
+    if (videoBitRateMultiplier != -1.0) {
+      view.videoBitRateMultiplier = videoBitRateMultiplier
+    } else {
+      view.videoBitRateMultiplier = null
+    }
+  }
+
+  @ReactProp(name = "lowLightBoost")
+  fun setLowLightBoost(view: CameraView, lowLightBoost: Boolean) {
+    view.lowLightBoost = lowLightBoost
+  }
+
+  @ReactProp(name = "isActive")
+  fun setIsActive(view: CameraView, isActive: Boolean) {
+    view.isActive = isActive
+  }
+
+  @ReactProp(name = "torch")
+  fun setTorch(view: CameraView, torch: String?) {
+    if (torch != null) {
+      val newMode = Torch.fromUnionValue(torch)
+      view.torch = newMode
+    } else {
+      view.torch = Torch.OFF
+    }
+  }
+
+  @ReactProp(name = "zoom")
+  fun setZoom(view: CameraView, zoom: Double) {
+    view.zoom = zoom.toFloat()
+  }
+
+  @ReactProp(name = "exposure")
+  fun setExposure(view: CameraView, exposure: Double) {
+    view.exposure = exposure
+  }
+
+  @ReactProp(name = "outputOrientation")
+  fun setOrientation(view: CameraView, outputOrientation: String?) {
+    if (outputOrientation != null) {
+      val newMode = OutputOrientation.fromUnionValue(outputOrientation)
+      view.outputOrientation = newMode
+    } else {
+      view.outputOrientation = OutputOrientation.DEVICE
+    }
+  }
+
+  @ReactProp(name = "codeScannerOptions")
+  fun setCodeScanner(view: CameraView, codeScannerOptions: ReadableMap?) {
+    if (codeScannerOptions != null) {
+      val newCodeScannerOptions = CodeScannerOptions.fromJSValue(codeScannerOptions)
+      view.codeScannerOptions = newCodeScannerOptions
+    } else {
+      view.codeScannerOptions = null
+    }
+  }
+}
diff --git a/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/react/CameraViewModule.kt b/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/react/CameraViewModule.kt
new file mode 100644
index 0000000..059f677
--- /dev/null
+++ b/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/react/CameraViewModule.kt
@@ -0,0 +1,261 @@
+package com.mrousavy.camera.react
+
+import android.Manifest
+import android.content.pm.PackageManager
+import android.util.Log
+import androidx.core.content.ContextCompat
+import com.facebook.react.bridge.Callback
+import com.facebook.react.bridge.Promise
+import com.facebook.react.bridge.ReactApplicationContext
+import com.facebook.react.bridge.ReactContextBaseJavaModule
+import com.facebook.react.bridge.ReactMethod
+import com.facebook.react.bridge.ReadableMap
+import com.facebook.react.module.annotations.ReactModule
+import com.facebook.react.modules.core.PermissionAwareActivity
+import com.facebook.react.modules.core.PermissionListener
+import com.facebook.react.uimanager.UIManagerHelper
+import com.facebook.react.uimanager.common.UIManagerType
+import com.mrousavy.camera.BuildConfig
+import com.mrousavy.camera.core.CameraError
+import com.mrousavy.camera.core.CameraQueues
+import com.mrousavy.camera.core.ViewNotFoundError
+import com.mrousavy.camera.core.types.PermissionStatus
+import com.mrousavy.camera.core.types.RecordVideoOptions
+import com.mrousavy.camera.core.types.TakeSnapshotOptions
+import com.mrousavy.camera.core.utils.runOnUiThread
+import com.mrousavy.camera.core.utils.runOnUiThreadAndWait
+import com.mrousavy.camera.frameprocessors.VisionCameraInstaller
+import com.mrousavy.camera.frameprocessors.VisionCameraProxy
+import com.mrousavy.camera.react.utils.makeErrorMap
+import com.mrousavy.camera.react.utils.withPromise
+import kotlinx.coroutines.CoroutineScope
+import kotlinx.coroutines.asCoroutineDispatcher
+import kotlinx.coroutines.cancel
+import kotlinx.coroutines.isActive
+import kotlinx.coroutines.launch
+
+@ReactModule(name = CameraViewModule.TAG)
+@Suppress("unused")
+class CameraViewModule(reactContext: ReactApplicationContext) : ReactContextBaseJavaModule(reactContext) {
+  companion object {
+    const val TAG = "CameraView"
+    var sharedRequestCode = 10
+
+    init {
+      try {
+        // Load the native part of VisionCamera.
+        // Includes the OpenGL VideoPipeline, as well as Frame Processor JSI bindings
+        System.loadLibrary("VisionCamera")
+      } catch (e: UnsatisfiedLinkError) {
+        Log.e(VisionCameraProxy.TAG, "Failed to load VisionCamera C++ library!", e)
+        throw e
+      }
+    }
+  }
+
+  private val backgroundCoroutineScope = CoroutineScope(CameraQueues.cameraExecutor.asCoroutineDispatcher())
+
+  override fun invalidate() {
+    super.invalidate()
+    if (backgroundCoroutineScope.isActive) {
+      backgroundCoroutineScope.cancel("CameraViewModule has been destroyed.")
+    }
+  }
+
+  override fun getName(): String = TAG
+
+  private suspend fun findCameraView(viewId: Int): CameraView =
+    runOnUiThreadAndWait {
+      Log.d(TAG, "Finding view $viewId...")
+      val context = reactApplicationContext ?: throw Error("React Context was null!")
+
+      val uiManagerType = if (BuildConfig.IS_NEW_ARCHITECTURE_ENABLED) UIManagerType.FABRIC else UIManagerType.DEFAULT
+      val uiManager = UIManagerHelper.getUIManager(context, uiManagerType) ?: throw Error("UIManager not found!")
+
+      val view = uiManager.resolveView(viewId) as? CameraView ?: throw ViewNotFoundError(viewId)
+      Log.d(TAG, "Found view $viewId!")
+      return@runOnUiThreadAndWait view
+    }
+
+  @ReactMethod(isBlockingSynchronousMethod = true)
+  fun installFrameProcessorBindings(): Boolean =
+    try {
+      val proxy = VisionCameraProxy(reactApplicationContext)
+      VisionCameraInstaller.install(proxy)
+      true
+    } catch (e: Error) {
+      Log.e(TAG, "Failed to install Frame Processor JSI Bindings!", e)
+      false
+    }
+
+  @ReactMethod
+  fun takePhoto(viewTag: Int, options: ReadableMap, promise: Promise) {
+    backgroundCoroutineScope.launch {
+      val view = findCameraView(viewTag)
+      withPromise(promise) {
+        view.takePhoto(options)
+      }
+    }
+  }
+
+  @ReactMethod
+  fun takeSnapshot(viewTag: Int, jsOptions: ReadableMap, promise: Promise) {
+    backgroundCoroutineScope.launch {
+      val view = findCameraView(viewTag)
+      runOnUiThread {
+        try {
+          val options = TakeSnapshotOptions.fromJSValue(reactApplicationContext, jsOptions)
+          val result = view.takeSnapshot(options)
+          promise.resolve(result)
+        } catch (e: Throwable) {
+          promise.reject(e)
+        }
+      }
+    }
+  }
+
+  // TODO: startRecording() cannot be awaited, because I can't have a Promise and a onRecordedCallback in the same function. Hopefully TurboModules allows that
+  @ReactMethod
+  fun startRecording(viewTag: Int, jsOptions: ReadableMap, onRecordCallback: Callback) {
+    backgroundCoroutineScope.launch {
+      val view = findCameraView(viewTag)
+      try {
+        val options = RecordVideoOptions.fromJSValue(reactApplicationContext, jsOptions)
+        view.startRecording(options, onRecordCallback)
+      } catch (error: CameraError) {
+        val map = makeErrorMap("${error.domain}/${error.id}", error.message, error)
+        onRecordCallback(null, map)
+      } catch (error: Throwable) {
+        val map =
+          makeErrorMap("capture/unknown", "An unknown error occurred while trying to start a video recording! ${error.message}", error)
+        onRecordCallback(null, map)
+      }
+    }
+  }
+
+  @ReactMethod
+  fun pauseRecording(viewTag: Int, promise: Promise) {
+    backgroundCoroutineScope.launch {
+      withPromise(promise) {
+        val view = findCameraView(viewTag)
+        view.pauseRecording()
+        return@withPromise null
+      }
+    }
+  }
+
+  @ReactMethod
+  fun resumeRecording(viewTag: Int, promise: Promise) {
+    backgroundCoroutineScope.launch {
+      val view = findCameraView(viewTag)
+      withPromise(promise) {
+        view.resumeRecording()
+        return@withPromise null
+      }
+    }
+  }
+
+  @ReactMethod
+  fun stopRecording(viewTag: Int, promise: Promise) {
+    backgroundCoroutineScope.launch {
+      val view = findCameraView(viewTag)
+      withPromise(promise) {
+        view.stopRecording()
+        return@withPromise null
+      }
+    }
+  }
+
+  @ReactMethod
+  fun cancelRecording(viewTag: Int, promise: Promise) {
+    backgroundCoroutineScope.launch {
+      val view = findCameraView(viewTag)
+      withPromise(promise) {
+        view.cancelRecording()
+        return@withPromise null
+      }
+    }
+  }
+
+  @ReactMethod
+  fun focus(viewTag: Int, point: ReadableMap, promise: Promise) {
+    backgroundCoroutineScope.launch {
+      val view = findCameraView(viewTag)
+      withPromise(promise) {
+        view.focus(point)
+        return@withPromise null
+      }
+    }
+  }
+
+  private fun canRequestPermission(permission: String): Boolean {
+    val activity = reactApplicationContext.currentActivity as? PermissionAwareActivity
+    return activity?.shouldShowRequestPermissionRationale(permission) ?: false
+  }
+
+  private fun getPermission(permission: String): PermissionStatus {
+    val status = ContextCompat.checkSelfPermission(reactApplicationContext, permission)
+    var parsed = PermissionStatus.fromPermissionStatus(status)
+    if (parsed == PermissionStatus.DENIED && canRequestPermission(permission)) {
+      parsed = PermissionStatus.NOT_DETERMINED
+    }
+    return parsed
+  }
+
+  @ReactMethod(isBlockingSynchronousMethod = true)
+  fun getCameraPermissionStatus(): String {
+    val status = getPermission(Manifest.permission.CAMERA)
+    return status.unionValue
+  }
+
+  @ReactMethod(isBlockingSynchronousMethod = true)
+  fun getMicrophonePermissionStatus(): String {
+    val status = getPermission(Manifest.permission.RECORD_AUDIO)
+    return status.unionValue
+  }
+
+  @ReactMethod(isBlockingSynchronousMethod = true)
+  fun getLocationPermissionStatus(): String {
+    val fineStatus = getPermission(Manifest.permission.ACCESS_FINE_LOCATION)
+    if (fineStatus == PermissionStatus.GRANTED) {
+      return fineStatus.unionValue
+    }
+
+    val coarseStatus = getPermission(Manifest.permission.ACCESS_COARSE_LOCATION)
+    return coarseStatus.unionValue
+  }
+
+  private fun requestPermission(permission: String, promise: Promise) {
+    val activity = reactApplicationContext.currentActivity
+    if (activity is PermissionAwareActivity) {
+      val currentRequestCode = sharedRequestCode++
+      val listener = PermissionListener { requestCode: Int, _: Array<String>, grantResults: IntArray ->
+        if (requestCode == currentRequestCode) {
+          val permissionStatus = if (grantResults.isNotEmpty()) grantResults[0] else PackageManager.PERMISSION_DENIED
+          val parsed = PermissionStatus.fromPermissionStatus(permissionStatus)
+          promise.resolve(parsed.unionValue)
+          return@PermissionListener true
+        }
+        return@PermissionListener false
+      }
+      activity.requestPermissions(arrayOf(permission), currentRequestCode, listener)
+    } else {
+      promise.reject("NO_ACTIVITY", "No PermissionAwareActivity was found! Make sure the app has launched before calling this function.")
+    }
+  }
+
+  @ReactMethod
+  fun requestCameraPermission(promise: Promise) {
+    requestPermission(Manifest.permission.CAMERA, promise)
+  }
+
+  @ReactMethod
+  fun requestMicrophonePermission(promise: Promise) {
+    requestPermission(Manifest.permission.RECORD_AUDIO, promise)
+  }
+
+  @ReactMethod
+  fun requestLocationPermission(promise: Promise) {
+    requestPermission(Manifest.permission.ACCESS_FINE_LOCATION, promise)
+  }
+}
diff --git a/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/react/Events.kt b/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/react/Events.kt
new file mode 100644
index 0000000..acbb77a
--- /dev/null
+++ b/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/react/Events.kt
@@ -0,0 +1,104 @@
+package com.mrousavy.camera.react
+
+import com.facebook.react.bridge.Arguments
+import com.facebook.react.bridge.WritableMap
+import com.facebook.react.uimanager.events.Event
+
+class CameraInitializedEvent(surfaceId: Int, viewId: Int) : Event<CameraInitializedEvent>(surfaceId, viewId) {
+  override fun getEventName() = EVENT_NAME
+  override fun getEventData(): WritableMap = Arguments.createMap()
+  companion object {
+    const val EVENT_NAME = "topCameraInitialized"
+  }
+}
+
+class CameraStartedEvent(surfaceId: Int, viewId: Int) : Event<CameraStartedEvent>(surfaceId, viewId) {
+  override fun getEventName() = EVENT_NAME
+  override fun getEventData(): WritableMap = Arguments.createMap()
+  companion object {
+    const val EVENT_NAME = "topCameraStarted"
+  }
+}
+
+class CameraStoppedEvent(surfaceId: Int, viewId: Int) : Event<CameraStoppedEvent>(surfaceId, viewId) {
+  override fun getEventName() = EVENT_NAME
+  override fun getEventData(): WritableMap = Arguments.createMap()
+  companion object {
+    const val EVENT_NAME = "topCameraStopped"
+  }
+}
+
+class CameraPreviewStartedEvent(surfaceId: Int, viewId: Int) : Event<CameraPreviewStartedEvent>(surfaceId, viewId) {
+  override fun getEventName() = EVENT_NAME
+  override fun getEventData(): WritableMap = Arguments.createMap()
+  companion object {
+    const val EVENT_NAME = "topCameraPreviewStarted"
+  }
+}
+
+class CameraPreviewStoppedEvent(surfaceId: Int, viewId: Int) : Event<CameraPreviewStoppedEvent>(surfaceId, viewId) {
+  override fun getEventName() = EVENT_NAME
+  override fun getEventData(): WritableMap = Arguments.createMap()
+  companion object {
+    const val EVENT_NAME = "topCameraPreviewStopped"
+  }
+}
+
+class CameraShutterEvent(surfaceId: Int, viewId: Int, private val data: WritableMap) : Event<CameraShutterEvent>(surfaceId, viewId) {
+  override fun getEventName() = EVENT_NAME
+  override fun getEventData() = data
+  companion object {
+    const val EVENT_NAME = "topCameraShutter"
+  }
+}
+
+class CameraOutputOrientationChangedEvent(surfaceId: Int, viewId: Int, private val data: WritableMap) :
+  Event<CameraOutputOrientationChangedEvent>(surfaceId, viewId) {
+  override fun getEventName() = EVENT_NAME
+  override fun getEventData() = data
+  companion object {
+    const val EVENT_NAME = "topCameraOutputOrientationChanged"
+  }
+}
+
+class CameraPreviewOrientationChangedEvent(surfaceId: Int, viewId: Int, private val data: WritableMap) :
+  Event<CameraPreviewOrientationChangedEvent>(surfaceId, viewId) {
+  override fun getEventName() = EVENT_NAME
+  override fun getEventData() = data
+  companion object {
+    const val EVENT_NAME = "topCameraPreviewOrientationChanged"
+  }
+}
+
+class AverageFpsChangedEvent(surfaceId: Int, viewId: Int, private val data: WritableMap) : Event<CameraShutterEvent>(surfaceId, viewId) {
+  override fun getEventName() = EVENT_NAME
+  override fun getEventData() = data
+  companion object {
+    const val EVENT_NAME = "topCameraAverageFpsChanged"
+  }
+}
+
+class CameraErrorEvent(surfaceId: Int, viewId: Int, private val data: WritableMap) : Event<CameraErrorEvent>(surfaceId, viewId) {
+  override fun getEventName() = EVENT_NAME
+  override fun getEventData() = data
+  companion object {
+    const val EVENT_NAME = "topCameraError"
+  }
+}
+
+class CameraViewReadyEvent(surfaceId: Int, viewId: Int) : Event<CameraViewReadyEvent>(surfaceId, viewId) {
+  override fun getEventName() = EVENT_NAME
+  override fun getEventData(): WritableMap = Arguments.createMap()
+  companion object {
+    const val EVENT_NAME = "topCameraViewReady"
+  }
+}
+
+class CameraCodeScannedEvent(surfaceId: Int, viewId: Int, private val data: WritableMap) :
+  Event<CameraCodeScannedEvent>(surfaceId, viewId) {
+  override fun getEventName() = EVENT_NAME
+  override fun getEventData() = data
+  companion object {
+    const val EVENT_NAME = "topCameraCodeScanned"
+  }
+}
diff --git a/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/react/FpsSampleCollector.kt b/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/react/FpsSampleCollector.kt
new file mode 100644
index 0000000..56a7844
--- /dev/null
+++ b/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/react/FpsSampleCollector.kt
@@ -0,0 +1,47 @@
+package com.mrousavy.camera.react
+
+import java.util.Timer
+import kotlin.concurrent.schedule
+
+class FpsSampleCollector(val callback: Callback) {
+  private var timestamps = mutableListOf<Long>()
+  private var timer: Timer? = null
+
+  fun start() {
+    timer = Timer("VisionCamera FPS Sample Collector")
+    timer?.schedule(1000, 1000) {
+      callback.onAverageFpsChanged(averageFps)
+    }
+  }
+
+  fun stop() {
+    timer?.cancel()
+    timer = null
+  }
+
+  fun onTick() {
+    val now = System.currentTimeMillis()
+    timestamps.add(now)
+
+    // filter out any timestamps that are older than 1 second
+    timestamps = timestamps.filter { timestamp ->
+      val differenceMs = now - timestamp
+      return@filter differenceMs < 1000
+    }.toMutableList()
+  }
+
+  private val averageFps: Double
+    get() {
+      val first = timestamps.firstOrNull()
+      val last = timestamps.lastOrNull()
+      if (first == null || last == null) return 0.0
+
+      val totalDurationMs = last - first
+      val averageFrameDurationMs = totalDurationMs.toDouble() / (timestamps.count() - 1).toDouble()
+      return 1000.0 / averageFrameDurationMs
+    }
+
+  interface Callback {
+    fun onAverageFpsChanged(averageFps: Double)
+  }
+}
diff --git a/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/react/extensions/List+toJSValue.kt b/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/react/extensions/List+toJSValue.kt
new file mode 100644
index 0000000..f34005f
--- /dev/null
+++ b/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/react/extensions/List+toJSValue.kt
@@ -0,0 +1,11 @@
+package com.mrousavy.camera.react.extensions
+
+import com.facebook.react.bridge.Arguments
+import com.facebook.react.bridge.ReadableArray
+import com.mrousavy.camera.core.types.JSUnionValue
+
+fun List<JSUnionValue>.toJSValue(): ReadableArray {
+  val arguments = Arguments.createArray()
+  this.forEach { arguments.pushString(it.unionValue) }
+  return arguments
+}
diff --git a/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/react/extensions/ViewGroup+installHierarchyFitter.kt b/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/react/extensions/ViewGroup+installHierarchyFitter.kt
new file mode 100644
index 0000000..b4b25bf
--- /dev/null
+++ b/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/react/extensions/ViewGroup+installHierarchyFitter.kt
@@ -0,0 +1,19 @@
+package com.mrousavy.camera.react.extensions
+
+import android.view.View
+import android.view.ViewGroup
+
+// React does not trigger onLayout events for dynamically added views (`addView`). This fixes that.
+// https://github.com/facebook/react-native/issues/17968#issuecomment-633308615
+fun ViewGroup.installHierarchyFitter() {
+  setOnHierarchyChangeListener(object : ViewGroup.OnHierarchyChangeListener {
+    override fun onChildViewRemoved(parent: View?, child: View?) = Unit
+    override fun onChildViewAdded(parent: View?, child: View?) {
+      parent?.measure(
+        View.MeasureSpec.makeMeasureSpec(measuredWidth, View.MeasureSpec.EXACTLY),
+        View.MeasureSpec.makeMeasureSpec(measuredHeight, View.MeasureSpec.EXACTLY)
+      )
+      parent?.layout(0, 0, parent.measuredWidth, parent.measuredHeight)
+    }
+  })
+}
diff --git a/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/react/utils/CallbackPromise.kt b/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/react/utils/CallbackPromise.kt
new file mode 100644
index 0000000..9b750ed
--- /dev/null
+++ b/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/react/utils/CallbackPromise.kt
@@ -0,0 +1,24 @@
+package com.mrousavy.camera.react.utils
+
+import com.facebook.react.bridge.Arguments
+import com.facebook.react.bridge.ReadableMap
+import com.facebook.react.bridge.WritableMap
+
+private fun makeErrorCauseMap(throwable: Throwable): ReadableMap {
+  val map = Arguments.createMap()
+  map.putString("message", throwable.message)
+  map.putString("stacktrace", throwable.stackTraceToString())
+  if (throwable.cause != null) {
+    map.putMap("cause", makeErrorCauseMap(throwable.cause!!))
+  }
+  return map
+}
+
+fun makeErrorMap(code: String? = null, message: String? = null, throwable: Throwable? = null, userInfo: WritableMap? = null): ReadableMap {
+  val map = Arguments.createMap()
+  map.putString("code", code)
+  map.putString("message", message)
+  map.putMap("cause", if (throwable != null) makeErrorCauseMap(throwable) else null)
+  map.putMap("userInfo", userInfo)
+  return map
+}
diff --git a/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/react/utils/withPromise.kt b/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/react/utils/withPromise.kt
new file mode 100644
index 0000000..b6d71dd
--- /dev/null
+++ b/node_modules/react-native-vision-camera/android/bin/src/main/java/com/mrousavy/camera/react/utils/withPromise.kt
@@ -0,0 +1,16 @@
+package com.mrousavy.camera.react.utils
+
+import com.facebook.react.bridge.Promise
+import com.mrousavy.camera.core.CameraError
+import com.mrousavy.camera.core.UnknownCameraError
+
+inline fun withPromise(promise: Promise, closure: () -> Any?) {
+  try {
+    val result = closure()
+    promise.resolve(result)
+  } catch (e: Throwable) {
+    e.printStackTrace()
+    val error = if (e is CameraError) e else UnknownCameraError(e)
+    promise.reject("${error.domain}/${error.id}", error.message, error.cause)
+  }
+}
diff --git a/node_modules/react-native-vision-camera/android/build.gradle b/node_modules/react-native-vision-camera/android/build.gradle
index b1d9973..0b65a5c 100644
--- a/node_modules/react-native-vision-camera/android/build.gradle
+++ b/node_modules/react-native-vision-camera/android/build.gradle
@@ -96,6 +96,7 @@ repositories {
 }
 
 android {
+    namespace 'com.mrousavy.camera'
   if (agpVersion >= 7) {
     namespace "com.mrousavy.camera"
   }
diff --git a/node_modules/react-native-vision-camera/android/src/main/java/com/mrousavy/camera/react/CameraDevicesManager.kt b/node_modules/react-native-vision-camera/android/src/main/java/com/mrousavy/camera/react/CameraDevicesManager.kt
index 21ac2b2..680b5aa 100644
--- a/node_modules/react-native-vision-camera/android/src/main/java/com/mrousavy/camera/react/CameraDevicesManager.kt
+++ b/node_modules/react-native-vision-camera/android/src/main/java/com/mrousavy/camera/react/CameraDevicesManager.kt
@@ -99,9 +99,19 @@ class CameraDevicesManager(private val reactContext: ReactApplicationContext) :
   }
 
   fun sendAvailableDevicesChangedEvent() {
-    val eventEmitter = reactContext.getJSModule(RCTDeviceEventEmitter::class.java)
-    val devices = getDevicesJson()
-    eventEmitter.emit("CameraDevicesChanged", devices)
+    // Safety check: Only send events if React context is fully initialized
+    if (!reactContext.hasActiveReactInstance()) {
+      android.util.Log.d(TAG, "Skipping CameraDevicesChanged event - React context not ready yet")
+      return
+    }
+    
+    try {
+      val eventEmitter = reactContext.getJSModule(RCTDeviceEventEmitter::class.java)
+      val devices = getDevicesJson()
+      eventEmitter.emit("CameraDevicesChanged", devices)
+    } catch (e: Exception) {
+      android.util.Log.e(TAG, "Failed to send CameraDevicesChanged event: ${e.message}", e)
+    }
   }
 
   override fun getConstants(): MutableMap<String, Any?> {
