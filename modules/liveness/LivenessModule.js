/**
 * Liveness Detection Module
 * CanlÄ±lÄ±k testi modÃ¼lÃ¼ - GerÃ§ek yÃ¼z algÄ±lama ve doÄŸrulama
 * Android 11 uyumlu
 */

import {
    View,
    Text,
    StyleSheet,
    TouchableOpacity,
    Alert,
    ActivityIndicator,
    Animated,
    Dimensions,
    StatusBar,
    Platform,
    NativeModules,
} from 'react-native';
import { Camera, useCameraDevice } from 'react-native-vision-camera';
import { check, request, PERMISSIONS, RESULTS } from 'react-native-permissions';
import Tts from 'react-native-tts';
import FaceDetection from '@react-native-ml-kit/face-detection';

const { width: screenWidth, height: screenHeight } = Dimensions.get('window');

// Liveness challenge types
const CHALLENGES = {
    LOOK_STRAIGHT: {
        id: 'lookStraight',
        instruction: 'DÃ¼z bakÄ±n',
        voice: 'LÃ¼tfen dÃ¼z bakÄ±n',
        duration: 3000,
        detectionKey: 'headPose',
    },
    BLINK: {
        id: 'blink',
        instruction: 'GÃ¶zlerinizi kÄ±rpÄ±n',
        voice: 'LÃ¼tfen gÃ¶zlerinizi kÄ±rpÄ±n',
        duration: 3000,
        detectionKey: 'eyes',
    },
    SMILE: {
        id: 'smile',
        instruction: 'GÃ¼lÃ¼mseme',
        voice: 'LÃ¼tfen gÃ¼lÃ¼mseyin',
        duration: 3000,
        detectionKey: 'smile',
    },
    TURN_HEAD_LEFT: {
        id: 'turnHeadLeft',
        instruction: 'BaÅŸÄ±nÄ±zÄ± sola Ã§evirin',
        voice: 'LÃ¼tfen baÅŸÄ±nÄ±zÄ± sola Ã§evirin',
        duration: 3000,
        detectionKey: 'headPose',
    },
    TURN_HEAD_RIGHT: {
        id: 'turnHeadRight',
        instruction: 'BaÅŸÄ±nÄ±zÄ± saÄŸa Ã§evirin',
        voice: 'LÃ¼tfen baÅŸÄ±nÄ±zÄ± saÄŸa Ã§evirin',
        duration: 3000,
        detectionKey: 'headPose',
    },
    NOD_HEAD: {
        id: 'nodHead',
        instruction: 'BaÅŸÄ±nÄ±zÄ± aÅŸaÄŸÄ± yukarÄ± sallayÄ±n',
        voice: 'LÃ¼tfen baÅŸÄ±nÄ±zÄ± aÅŸaÄŸÄ± yukarÄ± sallayÄ±n',
        duration: 3000,
        detectionKey: 'headPose',
    },
    LOOKUP: {
        id: 'lookUp',
        instruction: 'BaÅŸÄ±nÄ±zÄ± yukarÄ± kaldÄ±rÄ±n',
        voice: 'LÃ¼tfen baÅŸÄ±nÄ±zÄ± yukarÄ± kaldÄ±rÄ±n',
        duration: 3000,
    },
    LOOKDOWN: {
        id: 'lookDown',
        instruction: 'BaÅŸÄ±nÄ±zÄ± aÅŸaÄŸÄ± eÄŸin',
        voice: 'LÃ¼tfen baÅŸÄ±nÄ±zÄ± aÅŸaÄŸÄ± eÄŸin',
        duration: 3000,
    },
    TILTHEAD: {
        id: 'tiltHead',
        instruction: 'BaÅŸÄ±nÄ±zÄ± yana eÄŸin',
        voice: 'LÃ¼tfen baÅŸÄ±nÄ±zÄ± yana eÄŸin',
        duration: 3000,
    },
};

class LivenessDetectionModule {
    constructor() {
        this.callbacks = {};
        this.challenges = [];
        this.currentChallengeIndex = 0;
        this.results = [];
        this.faceDetected = false;
        this.challengeStartTime = null;
        this.ttsEnabled = true;
        this.noFaceDetectionCount = 0;
        this.lastDebugLogTime = 0; // For throttling debug logs
        this.challengeTimeoutId = null; // Store timeout ID for cleanup

        // Blink detection state machine
        this.blinkState = null; // null | 'eyes_open' | 'eyes_closed'
        this.blinkStateTime = null; // Track when state changed

        // Face comparison for NFC verification
        this.capturedPhotos = []; // Photos captured during liveness test
        this.referencePhotoUri = null; // NFC photo for comparison
        this.referenceFaceData = null; // Face data extracted from NFC photo
        this.enableFaceComparison = false;
        this.photoCaptureChance = 0.6; // 60% chance to capture photo during each challenge
        this.currentFaceData = null; // Current face data from processFaceData
        this.similarityThreshold = 0.25; // 25% minimum similarity for match (lowered due to basic algorithm)
    }

    // API Methods
    startLiveness = async (challenges = ['lookStraight', 'turnHeadRight', 'turnHeadLeft', 'lookUp', 'lookDown']) => {
        try {
            console.log('[LivenessModule] ========================================');
            console.log('[LivenessModule] ğŸš€ Starting liveness test...');
            console.log('[LivenessModule] â° Timestamp:', new Date().toISOString());
            console.log('[LivenessModule] ğŸ“‹ Requested challenges:', challenges);
            console.log('[LivenessModule] ğŸ“Š Challenge count:', challenges.length);
            console.log('[LivenessModule] ğŸ” Face comparison enabled:', this.enableFaceComparison);
            console.log('[LivenessModule] ğŸ“¸ Reference photo loaded:', !!this.referenceFaceData);
            console.log('[LivenessModule] ========================================');

            // Validate challenges
            this.challenges = challenges.map(c => {
                const challenge = Object.values(CHALLENGES).find(ch => ch.id === c);
                if (!challenge) {
                    console.error(`[LivenessModule] âŒ Invalid challenge: ${c}`);
                    throw new Error(`Invalid challenge: ${c}`);
                }
                console.log(`[LivenessModule] âœ… Challenge validated: ${c} - "${challenge.instruction}"`);
                return challenge;
            });

            // Randomize challenge order for security (prevent spoof attacks)
            // Always keep 'lookStraight' first for better UX
            const firstChallenge = this.challenges[0];
            const remainingChallenges = this.challenges.slice(1);

            // Fisher-Yates shuffle for remaining challenges
            for (let i = remainingChallenges.length - 1; i > 0; i--) {
                const j = Math.floor(Math.random() * (i + 1));
                [remainingChallenges[i], remainingChallenges[j]] = [remainingChallenges[j], remainingChallenges[i]];
            }

            this.challenges = [firstChallenge, ...remainingChallenges];
            console.log('[LivenessModule] ğŸ”€ Challenges randomized (keeping first challenge fixed)');
            console.log('[LivenessModule] ğŸ“‹ Final order:', this.challenges.map(c => c.id).join(', '));

            this.currentChallengeIndex = 0;
            this.results = [];
            console.log(`[LivenessModule] ğŸ“Š Total challenges to complete: ${this.challenges.length}`);

            // Initialize TTS
            console.log('[LivenessModule] ğŸ”Š Initializing TTS...');
            await this.initializeTTS();

            if (this.callbacks.onStarted) {
                console.log('[LivenessModule] ğŸ“¢ Calling onStarted callback');
                this.callbacks.onStarted();
            }

            // Start first challenge
            console.log('[LivenessModule] â–¶ï¸ Starting first challenge...');
            await this.startNextChallenge();

        } catch (error) {
            console.error('[LivenessModule] âŒ Error starting liveness:', error);
            this.handleError(error);
        }
    };

    stopLiveness = () => {
        console.log('[LivenessModule] ========================================');
        console.log('[LivenessModule] â¹ï¸ Stopping liveness test...');
        console.log('[LivenessModule] â° Timestamp:', new Date().toISOString());
        console.log('[LivenessModule] ğŸ“Š Current challenge index:', this.currentChallengeIndex);
        console.log('[LivenessModule] ğŸ“Š Total challenges:', this.challenges.length);
        console.log('[LivenessModule] ğŸ“Š Results collected:', this.results.length);
        console.log('[LivenessModule] ğŸ“¸ Photos captured:', this.capturedPhotos.length);

        // Clear any pending challenge timeout
        if (this.challengeTimeoutId) {
            console.log('[LivenessModule] â±ï¸ Clearing pending timeout...');
            clearTimeout(this.challengeTimeoutId);
            this.challengeTimeoutId = null;
        }

        // ğŸ”§ FIX: Handle TTS stop promise rejection
        try {
            console.log('[LivenessModule] ğŸ”Š Stopping TTS...');
            Tts.stop().catch(() => {
                console.log('[LivenessModule] âš ï¸ TTS stop rejected (ignored)');
            });
        } catch (error) {
            console.log('[LivenessModule] âš ï¸ TTS stop error (ignored):', error.message);
        }

        this.challenges = [];
        this.currentChallengeIndex = 0;
        this.results = [];
        this.capturedPhotos = []; // Clean up captured photos

        console.log('[LivenessModule] âœ… Liveness stopped and cleaned up');
        console.log('[LivenessModule] ========================================');

        if (this.callbacks.onStopped) {
            console.log('[LivenessModule] ğŸ“¢ Calling onStopped callback');
            this.callbacks.onStopped();
        }
    };

    onLivenessResult = (callback) => {
        this.callbacks.onResult = callback;
    };

    onLivenessError = (callback) => {
        this.callbacks.onError = callback;
    };

    onLivenessStarted = (callback) => {
        this.callbacks.onStarted = callback;
    };

    onLivenessStopped = (callback) => {
        this.callbacks.onStopped = callback;
    };

    onChallengeChanged = (callback) => {
        this.callbacks.onChallengeChanged = callback;
    };

    onPhotoCapture = (callback) => {
        this.callbacks.onPhotoCapture = callback;
    };

    // Face Comparison Methods
    setReferencePhoto = async (photoUri) => {
        this.referencePhotoUri = photoUri;
        this.enableFaceComparison = !!photoUri;

        if (!photoUri) {
            console.log('[LivenessModule] ğŸ“¸ Reference photo disabled');
            return;
        }

        try {
            console.log(`[LivenessModule] ğŸ“¸ Loading reference photo...`);
            console.log(`[LivenessModule] ğŸ“± Platform: ${Platform.OS}`);
            console.log(`[LivenessModule] ğŸ“„ URI Type: ${typeof photoUri}`);
            console.log(`[LivenessModule] ğŸ“ URI Length: ${photoUri?.length || 0}`);
            console.log(`[LivenessModule] ğŸ” URI Preview: ${String(photoUri).substring(0, 100)}...`);

            // Validate photo URI
            if (typeof photoUri !== 'string' || photoUri.trim() === '') {
                throw new Error('Invalid photo URI: URI must be a non-empty string');
            }

            // Detect and validate photo format
            let photoFormat = 'unknown';
            let fixedPath = photoUri;

            if (photoUri.startsWith('file://')) {
                photoFormat = 'file_uri';
                console.log('[LivenessModule] âœ… Format: File URI');

                // Fix Android file path - ensure exactly 3 slashes (file:///)
                if (Platform.OS === 'android') {
                    // Remove all file:// prefixes
                    fixedPath = photoUri.replace(/^file:\/\/+/g, '');
                    // Add exactly 3 slashes for Android ML Kit
                    fixedPath = `file:///${fixedPath}`;
                    console.log(`[LivenessModule] ğŸ”§ Fixed Android path: ${fixedPath}`);
                }

            } else if (photoUri.startsWith('data:image')) {
                photoFormat = 'data_uri';
                console.log('[LivenessModule] âœ… Format: Data URI (base64)');

                // Data URI'leri ML Kit desteklemiyor, file'a kaydetmek gerekir
                throw new Error('Data URI format desteklenmiyor. LÃ¼tfen file:// formatÄ±nda gÃ¶nderin.');

            } else if (/^[A-Za-z0-9+/=]+$/.test(photoUri.substring(0, 100))) {
                photoFormat = 'base64';
                console.log('[LivenessModule] âš ï¸ Format: Raw base64 (data URI olmalÄ±)');

                // Raw base64 desteklenmez
                throw new Error('Raw base64 format desteklenmiyor. LÃ¼tfen file:// formatÄ±nda gÃ¶nderin.');

            } else if (photoUri.startsWith('/')) {
                photoFormat = 'absolute_path';
                console.log('[LivenessModule] âš ï¸ Format: Absolute path (file:/// ekleniyor)');

                // Absolute path'e file:/// ekle (3 slashes for Android ML Kit)
                fixedPath = `file:///` + photoUri;
                console.log(`[LivenessModule] ğŸ”§ Converted to: ${fixedPath}`);

            } else if (photoUri.startsWith('content://')) {
                photoFormat = 'content_uri';
                console.log('[LivenessModule] âŒ Format: Content URI');

                // Content URI desteklenmez
                throw new Error('Content URI format desteklenmiyor. LÃ¼tfen file:// formatÄ±nda gÃ¶nderin.');

            } else {
                console.log('[LivenessModule] âŒ Format: Unknown/Unsupported');
                throw new Error(`Bilinmeyen foto formatÄ±. URI: ${photoUri.substring(0, 50)}...`);
            }

            console.log(`[LivenessModule] ğŸ“‹ Final format: ${photoFormat}`);
            console.log(`[LivenessModule] ğŸ“‹ Final path: ${fixedPath}`);
            console.log(`[LivenessModule] ğŸ“‹ Path length: ${fixedPath.length}`);

            // Verify file exists (for file:// URIs)
            if (fixedPath.startsWith('file://')) {
                const RNFS = require('react-native-fs');
                const cleanPath = fixedPath.replace(/^file:\/\/+/g, '');
                console.log(`[LivenessModule] ğŸ“‚ Checking file: ${cleanPath}`);

                const exists = await RNFS.exists(cleanPath);
                console.log(`[LivenessModule] ğŸ“‚ File exists: ${exists}`);

                if (!exists) {
                    throw new Error(`Reference photo file not found: ${cleanPath}`);
                }

                const stat = await RNFS.stat(cleanPath);
                console.log(`[LivenessModule] ğŸ“‚ File size: ${stat.size} bytes`);

                // Get image dimensions for debugging (ALWAYS show, even if face detection fails)
                let imageDimensions = null;
                try {
                    const Image = require('react-native').Image;
                    imageDimensions = await new Promise((resolve, reject) => {
                        Image.getSize(
                            fixedPath,
                            (width, height) => {
                                console.log(`[LivenessModule] ğŸ“ Image dimensions: ${width}x${height}px`);
                                resolve({ width, height });
                            },
                            (error) => {
                                console.log(`[LivenessModule] âš ï¸ Could not get image dimensions:`, error.message);
                                resolve(null); // Don't fail, just log
                            }
                        );
                    });
                } catch (imgError) {
                    console.log(`[LivenessModule] âš ï¸ Image.getSize error:`, imgError.message);
                }

                // Store dimensions for later reference
                this.referencePhotoDimensions = imageDimensions;
            }

            console.log(`[LivenessModule] ğŸ” Detecting face in reference photo...`);

            // Extract face data from NFC photo with timeout
            // NFC passport photos are often small/low-quality, use tolerant settings
            const detectionPromise = FaceDetection.detect(fixedPath, {
                performanceMode: 'fast',  // More tolerant for small/low-quality photos
                landmarkMode: 'all',
                classificationMode: 'all',
                contourMode: 'all',
                minFaceSize: 0.1,  // Allow smaller faces (10% of image)
            });

            // Add 10 second timeout
            const timeoutPromise = new Promise((_, reject) =>
                setTimeout(() => reject(new Error('Face detection timeout (10s)')), 10000)
            );

            const faces = await Promise.race([detectionPromise, timeoutPromise]);

            console.log(`[LivenessModule] ğŸ‘¤ Detected ${faces?.length || 0} face(s)`);

            if (!faces || faces.length === 0) {
                console.log(`[LivenessModule] ========================================`);
                console.log(`[LivenessModule] âŒ NO FACE DETECTED IN REFERENCE PHOTO`);
                console.log(`[LivenessModule] ========================================`);

                // Show image info for debugging
                if (this.referencePhotoDimensions) {
                    console.log(`[LivenessModule] ğŸ“ Image size: ${this.referencePhotoDimensions.width}x${this.referencePhotoDimensions.height}px`);
                    console.log(`[LivenessModule] ğŸ“Š Total pixels: ${this.referencePhotoDimensions.width * this.referencePhotoDimensions.height}`);
                } else {
                    console.log(`[LivenessModule] âš ï¸ Image dimensions: UNKNOWN (unsupported format?)`);
                }

                console.log(`[LivenessModule] âš ï¸ Possible reasons:`);
                console.log(`[LivenessModule]    1. Unsupported image format (JPEG2000 should be auto-converted)`);
                console.log(`[LivenessModule]    2. Photo too small (passport photos are typically 200-300px)`);
                console.log(`[LivenessModule]    3. Low quality/resolution`);
                console.log(`[LivenessModule]    4. Face not clearly visible`);
                console.log(`[LivenessModule]    5. Photo corruption during NFC read`);
                console.log(`[LivenessModule] ========================================`);

                throw new Error('NFC fotoÄŸrafÄ±nda yÃ¼z algÄ±lanamadÄ±. Format otomatik dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lmÃ¼ÅŸ olmalÄ±, lÃ¼tfen NFC okuma loglarÄ±nÄ± kontrol edin.');
            }

            // Store first face data as reference
            this.referenceFaceData = faces[0];
            console.log(`[LivenessModule] âœ… Reference face data extracted successfully`);
            console.log(`[LivenessModule] ğŸ“Š Reference face bounds:`, this.referenceFaceData.frame);
            console.log(`[LivenessModule] ğŸ“Š Landmarks count: ${this.referenceFaceData.landmarks?.length || 0}`);

        } catch (error) {
            console.error('[LivenessModule] âŒ Failed to load reference photo');
            console.error('[LivenessModule] âŒ Error type:', error.constructor.name);
            console.error('[LivenessModule] âŒ Error message:', error.message);
            console.error('[LivenessModule] âŒ Error stack:', error.stack?.split('\n')[0]);

            this.enableFaceComparison = false;
            this.referenceFaceData = null;

            // Throw with more context
            throw new Error(`Reference photo hatasÄ±: ${error.message}`);
        }
    };

    capturePhotoForComparison = (photoUri, faceData) => {
        console.log('[LivenessModule] ğŸ“¸ capturePhotoForComparison called');
        console.log('[LivenessModule] ğŸ“¸ Photo URI:', photoUri?.substring(0, 80) + '...');
        console.log('[LivenessModule] ğŸ“¸ Face comparison enabled:', this.enableFaceComparison);
        console.log('[LivenessModule] ğŸ“¸ Reference face loaded:', !!this.referenceFaceData);

        if (!this.enableFaceComparison || !this.referenceFaceData) {
            console.log('[LivenessModule] âš ï¸ Skipping photo capture (comparison disabled or no reference)');
            return;
        }

        console.log('[LivenessModule] ğŸ”„ Calculating face similarity...');
        console.log('[LivenessModule] ğŸ”„ Reference face frame:', this.referenceFaceData.frame);
        console.log('[LivenessModule] ğŸ”„ Live face frame:', faceData.frame);

        // Calculate similarity immediately
        const similarity = this.compareFaces(this.referenceFaceData, faceData);
        console.log('[LivenessModule] ğŸ”„ Similarity calculated:', (similarity * 100).toFixed(2) + '%');

        const photoData = {
            uri: photoUri,
            timestamp: Date.now(),
            challenge: this.challenges[this.currentChallengeIndex]?.id,
            faceData: faceData,
            similarity: similarity, // Store similarity score
        };

        this.capturedPhotos.push(photoData);
        console.log(`[LivenessModule] âœ… Photo captured for comparison (#${this.capturedPhotos.length})`);
        console.log(`[LivenessModule] âœ… Similarity: ${(similarity * 100).toFixed(1)}%`);
        console.log(`[LivenessModule] âœ… Challenge: ${photoData.challenge}`);
        console.log(`[LivenessModule] âœ… Total photos: ${this.capturedPhotos.length}`);

        if (this.callbacks.onPhotoCapture) {
            console.log('[LivenessModule] ğŸ“¢ Calling onPhotoCapture callback');
            this.callbacks.onPhotoCapture({
                photoCount: this.capturedPhotos.length,
                challenge: photoData.challenge,
                similarity: similarity,
            });
        }
    };

    /**
     * Compare two faces using landmark-based similarity
     * @param {Object} face1 - Reference face (NFC photo)
     * @param {Object} face2 - Live face (captured during test)
     * @returns {number} Similarity score (0-1)
     */
    compareFaces = (face1, face2) => {
        if (!face1 || !face2) return 0;

        try {
            let totalScore = 0;
            let weightSum = 0;

            // 1. Landmark similarity (50% weight)
            if (face1.landmarks && face2.landmarks && face1.frame && face2.frame) {
                const landmarkScore = this.compareLandmarks(face1.landmarks, face2.landmarks, face1.frame, face2.frame);
                totalScore += landmarkScore * 0.5;
                weightSum += 0.5;
            }

            // 2. Face geometry similarity (30% weight)
            if (face1.frame && face2.frame) {
                const geometryScore = this.compareFaceGeometry(face1.frame, face2.frame);
                totalScore += geometryScore * 0.3;
                weightSum += 0.3;
            }

            // 3. Feature similarity (20% weight) - eye, smile probabilities
            const featureScore = this.compareFaceFeatures(face1, face2);
            totalScore += featureScore * 0.2;
            weightSum += 0.2;

            // Normalize
            const finalScore = weightSum > 0 ? totalScore / weightSum : 0;

            return Math.max(0, Math.min(1, finalScore));

        } catch (error) {
            console.error('[LivenessModule] âŒ Face comparison error:', error);
            return 0;
        }
    };

    /**
     * Compare facial landmarks (eyes, nose, mouth positions)
     * Normalizes distance based on face width for resolution independence
     */
    compareLandmarks = (landmarks1, landmarks2, frame1, frame2) => {
        const keyPoints = ['leftEye', 'rightEye', 'noseBase', 'mouthLeft', 'mouthRight'];
        let totalDistance = 0;
        let validPoints = 0;

        for (const point of keyPoints) {
            if (landmarks1[point] && landmarks2[point]) {
                const pos1 = landmarks1[point].position;
                const pos2 = landmarks2[point].position;

                // Euclidean distance (normalized by face size)
                const distance = Math.sqrt(
                    Math.pow(pos1.x - pos2.x, 2) +
                    Math.pow(pos1.y - pos2.y, 2)
                );

                totalDistance += distance;
                validPoints++;
            }
        }

        if (validPoints === 0) return 0;

        // Normalize: smaller distance = higher similarity
        // Use average face width for normalization (resolution independent)
        const avgFaceWidth = (frame1.width + frame2.width) / 2;
        const maxAcceptableDistance = avgFaceWidth * 0.5; // 50% of face width

        const avgDistance = totalDistance / validPoints;
        const normalizedDistance = Math.min(avgDistance / maxAcceptableDistance, 1);

        return 1 - normalizedDistance;
    };

    /**
     * Compare face geometry (size, aspect ratio)
     * IMPROVED: More tolerant to different camera distances and resolutions
     */
    compareFaceGeometry = (frame1, frame2) => {
        const width1 = frame1.width;
        const height1 = frame1.height;
        const width2 = frame2.width;
        const height2 = frame2.height;

        // Aspect ratio similarity (more lenient - allow up to 30% difference)
        const aspectRatio1 = width1 / height1;
        const aspectRatio2 = width2 / height2;
        const aspectDiff = Math.abs(aspectRatio1 - aspectRatio2);
        const aspectScore = Math.max(0, 1 - aspectDiff);  // Changed from * 2 to be more lenient

        // Size similarity (REMOVED - passport photos are small, live photos are large)
        // This was causing very low scores (21-35%) due to resolution differences
        // Instead, only use aspect ratio which is resolution-independent

        return aspectScore;  // Changed from (aspectScore + sizeRatio) / 2
    };

    /**
     * Compare facial features (eye open, smile probabilities)
     */
    compareFaceFeatures = (face1, face2) => {
        let score = 0;
        let count = 0;

        // Left eye
        if (face1.leftEyeOpenProbability !== undefined && face2.leftEyeOpenProbability !== undefined) {
            const diff = Math.abs(face1.leftEyeOpenProbability - face2.leftEyeOpenProbability);
            score += 1 - diff;
            count++;
        }

        // Right eye
        if (face1.rightEyeOpenProbability !== undefined && face2.rightEyeOpenProbability !== undefined) {
            const diff = Math.abs(face1.rightEyeOpenProbability - face2.rightEyeOpenProbability);
            score += 1 - diff;
            count++;
        }

        // Smile
        if (face1.smilingProbability !== undefined && face2.smilingProbability !== undefined) {
            const diff = Math.abs(face1.smilingProbability - face2.smilingProbability);
            score += 1 - diff;
            count++;
        }

        return count > 0 ? score / count : 0.5; // Default to neutral if no features available
    };

    // Private Methods
    initializeTTS = async () => {
        console.log('[LivenessModule] ğŸ”Š Initializing TTS engine...');
        // ğŸ”§ FIX: Properly handle all TTS promise rejections
        try {
            await Tts.getInitStatus();

            // Check if TTS is available
            const voices = await Tts.voices();
            console.log(`[LivenessModule] ğŸ—£ï¸ Available voices: ${voices.length}`);
            const turkishVoice = voices.find(v => v.language === 'tr-TR');

            if (turkishVoice) {
                console.log(`[LivenessModule] âœ… Turkish voice found: ${turkishVoice.name}`);
                await Tts.setDefaultVoice(turkishVoice.id);
            } else {
                console.log('[LivenessModule] âš ï¸ No Turkish voice found, using default');
            }

            this.ttsEnabled = true;
            console.log('[LivenessModule] âœ… TTS enabled successfully');
        } catch (error) {
            // Catch ALL TTS errors here - no rethrow
            console.log('[LivenessModule] âš ï¸ TTS not available (running on emulator or no TTS engine), continuing without voice');
            this.ttsEnabled = false;
        }
    };

    startNextChallenge = async () => {
        console.log(`[LivenessModule] ğŸ¯ Challenge index: ${this.currentChallengeIndex}/${this.challenges.length}`);

        if (this.currentChallengeIndex >= this.challenges.length) {
            // All challenges completed
            console.log('[LivenessModule] ğŸŠ All challenges completed!');
            this.completeDetection();
            return;
        }

        const challenge = this.challenges[this.currentChallengeIndex];
        this.challengeStartTime = Date.now();
        this.noFaceDetectionCount = 0; // Reset no-face counter
        this.blinkState = null; // Reset blink state machine for new challenge
        this.blinkStateTime = null;

        // Adaptive timeout based on challenge type
        // Blink needs more time for state machine transitions
        const timeoutBuffer = challenge.id === 'blink' ? 1500 : 1000;
        const timeoutDuration = challenge.duration + timeoutBuffer;

        console.log(`[LivenessModule] ğŸ¯ Starting challenge ${this.currentChallengeIndex + 1}/${this.challenges.length}: "${challenge.instruction}"`);
        console.log(`[LivenessModule] â±ï¸ Challenge timeout: ${timeoutDuration}ms (${challenge.duration}ms + ${timeoutBuffer}ms buffer)`);

        // Speak instruction
        if (this.ttsEnabled) {
            console.log(`[LivenessModule] ğŸ”Š Speaking: "${challenge.voice}"`);
            try {
                // ğŸ”§ FIX: Handle promise rejection
                Tts.speak(challenge.voice).catch(() => {
                    console.log('[LivenessModule] âš ï¸ TTS speak failed');
                });
            } catch (error) {
                console.log('[LivenessModule] âš ï¸ TTS not available');
            }
        } else {
            console.log('[LivenessModule] ğŸ”‡ TTS disabled, skipping voice instruction');
        }

        if (this.callbacks.onChallengeChanged) {
            console.log('[LivenessModule] ğŸ“¢ Calling onChallengeChanged callback');
            this.callbacks.onChallengeChanged(challenge);
        }

        // Clear any existing timeout
        if (this.challengeTimeoutId) {
            clearTimeout(this.challengeTimeoutId);
        }

        // Set timeout for challenge (optimized for fast mode: 4-4.5s instead of 5s)
        this.challengeTimeoutId = setTimeout(() => {
            this.challengeTimeout(challenge);
        }, timeoutDuration);
    };

    processFaceData = (faces) => {
        const now = Date.now();

        console.log('[LivenessModule] ========================================');
        console.log('[LivenessModule] ğŸ”„ processFaceData called');
        console.log('[LivenessModule] ğŸ“Š Face array length:', faces?.length || 0);
        console.log('[LivenessModule] ğŸ“Š Current challenge index:', this.currentChallengeIndex);
        console.log('[LivenessModule] ğŸ“Š Total challenges:', this.challenges.length);

        if (!faces || faces.length === 0) {
            console.log('[LivenessModule] âš ï¸ No face in array, incrementing no-face count');
            this.faceDetected = false;
            this.noFaceDetectionCount++;

            // Log every 2 seconds when no face
            if (now - this.lastDebugLogTime > 2000) {
                console.log(`[LivenessModule] âš ï¸ NO FACE: count=${this.noFaceDetectionCount}, threshold=20`);
                this.lastDebugLogTime = now;
            }

            // If no face detected for too long (20 consecutive checks ~10s), fail the challenge
            if (this.noFaceDetectionCount > 20 && this.currentChallengeIndex < this.challenges.length) {
                const challenge = this.challenges[this.currentChallengeIndex];
                console.log(`[LivenessModule] âŒ CHALLENGE FAILED: No face detected for ${this.noFaceDetectionCount} frames (~${(this.noFaceDetectionCount * 0.5).toFixed(1)}s)`);
                console.log(`[LivenessModule] âŒ Failed challenge: ${challenge.id} - "${challenge.instruction}"`);
                this.challengeCompleted(challenge, false);
            }
            return;
        }

        this.faceDetected = true;

        // Log when face is restored after being lost
        if (this.noFaceDetectionCount > 0) {
            console.log(`[LivenessModule] âœ… FACE RESTORED after ${this.noFaceDetectionCount} frames`);
        }

        this.noFaceDetectionCount = 0; // Reset counter when face is detected
        const face = faces[0];

        // Store current face data for photo capture
        this.currentFaceData = face;

        // Debug log angles and probabilities every 1 second
        if (now - this.lastDebugLogTime > 1000) {
            console.log(`[LivenessModule] ğŸ“ Face angles: x=${face.xAngle?.toFixed(1) || 'N/A'}Â°, y=${face.yAngle?.toFixed(1) || 'N/A'}Â°, z=${face.zAngle?.toFixed(1) || 'N/A'}Â°`);
            console.log(`[LivenessModule] ğŸ‘ï¸ Eyes: L=${face.leftEyeOpenProbability?.toFixed(2) || 'N/A'}, R=${face.rightEyeOpenProbability?.toFixed(2) || 'N/A'}`);
            console.log(`[LivenessModule] ğŸ˜Š Smile: ${face.smilingProbability?.toFixed(2) || 'N/A'}`);
            console.log(`[LivenessModule] ğŸ“¦ Frame: ${face.frame?.width || 'N/A'}x${face.frame?.height || 'N/A'}`);
            this.lastDebugLogTime = now;
        }

        // Check if we have an active challenge
        if (this.currentChallengeIndex >= this.challenges.length) {
            console.log('[LivenessModule] âš ï¸ No active challenge (all completed)');
            return;
        }

        const challenge = this.challenges[this.currentChallengeIndex];
        console.log(`[LivenessModule] ğŸ¯ Checking challenge: ${challenge.id}`);

        const detected = this.detectChallengeCompletion(face, challenge);
        console.log(`[LivenessModule] ğŸ” Detection result: ${detected ? 'âœ… SUCCESS' : 'â³ waiting...'}`);

        if (detected) {
            console.log(`[LivenessModule] ğŸ‰ Challenge "${challenge.id}" COMPLETED!`);

            // Capture photo immediately when challenge is completed (if face comparison enabled)
            if (this.enableFaceComparison && this.referenceFaceData && this.currentFaceData) {
                console.log('[LivenessModule] ğŸ“¸ Capturing completion photo...');
                // We need the photo URI, but we don't have it here
                // This will be handled by LivenessWrapper's onChallengeCompleted callback
            }

            this.challengeCompleted(challenge, true);
        }
    };

    detectChallengeCompletion = (face, challenge) => {
        const now = Date.now();
        const timeSinceStart = now - this.challengeStartTime;

        console.log('[LivenessModule] ----------------------------------------');
        console.log('[LivenessModule] ğŸ“Š detectChallengeCompletion for:', challenge.id);
        console.log('[LivenessModule] â±ï¸ Time since challenge start:', timeSinceStart + 'ms');

        // Make sure enough time has passed since challenge started
        if (timeSinceStart < 500) {
            console.log('[LivenessModule] â¸ï¸ Too early, waiting... (need 500ms)');
            return false;
        }

        switch (challenge.id) {
            case 'lookStraight':
                // Detect looking straight - head should be neutral
                const xAngleStraight = face.xAngle;
                const yAngleStraight = face.yAngle;

                console.log(`[LivenessModule] ğŸ“Š lookStraight check: x=${xAngleStraight?.toFixed(1)}Â°, y=${yAngleStraight?.toFixed(1)}Â°`);
                console.log(`[LivenessModule] ğŸ¯ Threshold: |x| < 15Â°, |y| < 15Â°`);

                if (xAngleStraight !== undefined && yAngleStraight !== undefined) {
                    const xAbs = Math.abs(xAngleStraight);
                    const yAbs = Math.abs(yAngleStraight);
                    console.log(`[LivenessModule] ğŸ“Š Absolute values: x=${xAbs.toFixed(1)}Â°, y=${yAbs.toFixed(1)}Â°`);

                    // Both angles should be close to 0 (within Â±15 degrees for easier detection)
                    if (xAbs < 15 && yAbs < 15) {
                        console.log(`âœ… lookStraight detected: x=${xAngleStraight.toFixed(1)}Â°, y=${yAngleStraight.toFixed(1)}Â°`);
                        return true;
                    } else {
                        console.log(`[LivenessModule] âŒ Failed: x=${xAbs.toFixed(1)}Â° >= 15 OR y=${yAbs.toFixed(1)}Â° >= 15`);
                    }
                }
                break;

            case 'blink':
                // Detect real eye blink - sequence: eyes_open â†’ eyes_closed â†’ eyes_open
                const leftEyeOpen = face.leftEyeOpenProbability;
                const rightEyeOpen = face.rightEyeOpenProbability;

                if (leftEyeOpen !== undefined && rightEyeOpen !== undefined) {
                    // Optimized thresholds for better detection
                    // Eyes are "open" when BOTH are clearly open (>0.7)
                    // Eyes are "closed" when BOTH are clearly closed (<0.35)
                    // Wider gap reduces false positives from partial blinks
                    const eyesOpen = leftEyeOpen > 0.7 && rightEyeOpen > 0.7;
                    const eyesClosed = leftEyeOpen < 0.35 && rightEyeOpen < 0.35;

                    // Debug: Always log eye state during blink challenge
                    console.log(` Eye state: L=${leftEyeOpen.toFixed(2)}, R=${rightEyeOpen.toFixed(2)}, State=${this.blinkState || 'null'}`);
                    console.log(` Evaluation: eyesOpen=${eyesOpen}, eyesClosed=${eyesClosed}`);

                    // State machine for blink detection
                    if (eyesOpen && this.blinkState !== 'eyes_open') {
                        // Eyes are open - set initial state or detect reopening after blink
                        if (this.blinkState === 'eyes_closed') {
                            // BLINK COMPLETED: eyes were closed, now open again!
                            console.log(` blink detected: full sequence (openâ†’closedâ†’open)`);
                            console.log(`   Final eye state: L=${leftEyeOpen.toFixed(2)}, R=${rightEyeOpen.toFixed(2)}`);
                            this.blinkState = null; // Reset for next challenge
                            return true;
                        }
                        console.log(` Eyes open confirmed, waiting for blink...`);
                        this.blinkState = 'eyes_open';
                        this.blinkStateTime = now;
                    } else if (eyesClosed && this.blinkState === 'eyes_open') {
                        // Eyes closed after being open - blink in progress
                        console.log(` Blink in progress: L=${leftEyeOpen.toFixed(2)}, R=${rightEyeOpen.toFixed(2)}`);
                        this.blinkState = 'eyes_closed';
                        this.blinkStateTime = now;
                    }
                }
                break;

            case 'smile':
                // Detect smile - stricter threshold
                const smileProbability = face.smilingProbability;
                if (smileProbability !== undefined && smileProbability > 0.75) {
                    return true;
                }
                break;

            case 'turnHeadLeft':
                // Detect head turned left - LARGE absolute yAngle (bigger turn)
                // Data analysis from multiple tests:
                // - Test2: +43.3Â°, +36.3Â° (successful left turn)
                // - Test3: -33.4Â° (successful left turn, different sign)
                // - Test4: -39.3Â° (successful left turn)
                // Pattern: LEFT = LARGE angle (30-40Â°), RIGHT = SMALL angle (5-10Â°)
                // Using |yAngle| > 15Â° to catch large turns while excluding small right turns
                const yAngleLeft = face.yAngle;
                const yAbsLeft = Math.abs(yAngleLeft || 0);
                console.log(`[LivenessModule] ğŸ“Š turnHeadLeft check: yAngle=${yAngleLeft?.toFixed(1)}Â° (|abs|=${yAbsLeft.toFixed(1)}Â°)`);
                console.log(`[LivenessModule] ğŸ¯ Threshold: |yAngle| > 15Â° (LARGE turn = left)`);

                if (yAngleLeft !== undefined) {
                    console.log(`[LivenessModule] ğŸ“Š Current absolute value: ${yAbsLeft.toFixed(1)}Â°`);

                    // Large absolute yAngle = head turned LEFT (significant turn)
                    // 15Â° threshold: Catches 30-40Â° left turns, excludes 5-10Â° right turns
                    if (yAbsLeft > 15) {
                        console.log(`âœ… turnHeadLeft detected: |yAngle|=${yAbsLeft.toFixed(1)}Â° (raw: ${yAngleLeft.toFixed(1)}Â°)`);
                        return true;
                    } else {
                        console.log(`[LivenessModule] âŒ Failed: ${yAbsLeft.toFixed(1)}Â° <= 15Â°`);
                    }
                }
                break;

            case 'turnHeadRight':
                // Detect head turned right - NEGATIVE yAngle (user turns right from their POV)
                // Based on VERIFIED log data: yAngle=-7.2Â° when user turns right
                // Using -5Â° threshold (conservative, user showed -7.2Â°)
                const yAngleRight = face.yAngle;
                console.log(`[LivenessModule] ğŸ“Š turnHeadRight check: yAngle=${yAngleRight?.toFixed(1)}Â°`);
                console.log(`[LivenessModule] ğŸ¯ Threshold: yAngle < -5Â° (NEGATIVE = right)`);

                if (yAngleRight !== undefined) {
                    console.log(`[LivenessModule] ğŸ“Š Current value: ${yAngleRight.toFixed(1)}Â°`);

                    // NEGATIVE yAngle = head turned RIGHT (verified from logs)
                    if (yAngleRight < -5) {
                        console.log(`âœ… turnHeadRight detected: yAngle=${yAngleRight.toFixed(1)}Â°`);
                        return true;
                    } else {
                        console.log(`[LivenessModule] âŒ Failed: ${yAngleRight.toFixed(1)}Â° >= -5Â°`);
                    }
                }
                break;

            case 'nodHead':
                // Detect head nod (up/down)
                const xAngle = face.xAngle;
                if (xAngle !== undefined && Math.abs(xAngle) > 15) {
                    return true;
                }
                break;

            case 'lookUp':
                // Detect head tilted up - xAngle should be NEGATIVE (head back)
                // Threshold lowered to -3Â° based on user test data showing -1.8Â° to -2.9Â°
                // This is more realistic for users (was -5Â°, then -10Â° originally)
                const xAngleUp = face.xAngle;
                console.log(`[LivenessModule] ğŸ“Š lookUp check: xAngle=${xAngleUp?.toFixed(1)}Â°`);
                console.log(`[LivenessModule] ğŸ¯ Threshold: xAngle < -3Â° (head tilted back)`);

                if (xAngleUp !== undefined) {
                    console.log(`[LivenessModule] ğŸ“Š Current value: ${xAngleUp.toFixed(1)}Â°`);

                    // Looking up means head tilts back, which is NEGATIVE xAngle
                    if (xAngleUp < -3) {
                        console.log(`âœ… lookUp detected: xAngle=${xAngleUp.toFixed(1)}Â°`);
                        return true;
                    } else {
                        console.log(`[LivenessModule] âŒ Failed: ${xAngleUp.toFixed(1)}Â° >= -3Â°`);
                    }
                }
                break;

            case 'lookDown':
                // Detect head tilted down - xAngle should be POSITIVE (head forward)
                // Lowered threshold to 5Â° for easier detection (was 10Â°)
                const xAngleDown = face.xAngle;
                console.log(`[LivenessModule] ğŸ“Š lookDown check: xAngle=${xAngleDown?.toFixed(1)}Â°`);
                console.log(`[LivenessModule] ğŸ¯ Threshold: xAngle > 5Â° (head tilted forward)`);

                if (xAngleDown !== undefined) {
                    console.log(`[LivenessModule] ğŸ“Š Current value: ${xAngleDown.toFixed(1)}Â°`);

                    // Looking down means head tilts forward, which is POSITIVE xAngle
                    if (xAngleDown > 5) {
                        console.log(`âœ… lookDown detected: xAngle=${xAngleDown.toFixed(1)}Â°`);
                        return true;
                    } else {
                        console.log(`[LivenessModule] âŒ Failed: ${xAngleDown.toFixed(1)}Â° <= 5Â°`);
                    }
                }
                break;

            case 'tiltHead':
                // Detect head tilted sideways (roll)
                const zAngleTilt = face.zAngle;
                if (zAngleTilt !== undefined && Math.abs(zAngleTilt) > 20) {
                    return true;
                }
                break;

            default:
                return false;
        }

        return false;
    };

    challengeCompleted = (challenge, success) => {
        // Clear challenge timeout to prevent duplicate execution
        if (this.challengeTimeoutId) {
            clearTimeout(this.challengeTimeoutId);
            this.challengeTimeoutId = null;
        }

        const duration = Date.now() - this.challengeStartTime;
        console.log(`[LivenessModule] ${success ? 'âœ…' : 'âŒ'} Challenge "${challenge.instruction}" ${success ? 'COMPLETED' : 'FAILED'} in ${duration}ms`);

        // Record result
        this.results.push({
            challenge: challenge.id,
            success: success,
            timestamp: Date.now(),
            duration: duration,
        });

        console.log(`[LivenessModule] ğŸ“Š Progress: ${this.results.filter(r => r.success).length}/${this.results.length} successful`);

        // Move to next challenge
        this.currentChallengeIndex++;

        // Small delay before next challenge
        setTimeout(() => {
            this.startNextChallenge();
        }, 1000);
    };

    challengeTimeout = (challenge) => {
        // Check if this challenge is still active
        if (this.currentChallengeIndex < this.challenges.length &&
            this.challenges[this.currentChallengeIndex].id === challenge.id) {
            // Challenge failed due to timeout
            console.log(`[LivenessModule] â±ï¸ TIMEOUT: Challenge "${challenge.instruction}" took too long`);
            this.challengeCompleted(challenge, false);
        }
    };

    completeDetection = () => {
        console.log('[LivenessModule] ğŸ Completing detection...');

        // Calculate overall score
        const successCount = this.results.filter(r => r.success).length;
        const totalCount = this.results.length;
        const score = totalCount > 0 ? (successCount / totalCount) * 100 : 0;
        const passed = score >= 60; // 60% threshold (3/5 challenges must succeed)

        console.log(`[LivenessModule] ğŸ“Š Final Score: ${successCount}/${totalCount} = ${Math.round(score)}%`);
        console.log(`[LivenessModule] ${passed ? 'âœ… PASSED' : 'âŒ FAILED'} (threshold: 60%)`);

        const response = {
            passed: passed,
            score: Math.round(score),
            details: {
                totalChallenges: totalCount,
                successfulChallenges: successCount,
                failedChallenges: totalCount - successCount,
                challenges: this.results,
            },
            timestamp: new Date().toISOString(),
        };

        // Add face comparison result if enabled
        if (this.enableFaceComparison && this.capturedPhotos.length > 0) {
            console.log(`[LivenessModule] ğŸ” Performing face comparison with ${this.capturedPhotos.length} photos...`);

            // Skip first photo (often has low score as user may not be fully in frame yet)
            // Use all photos if only 1 captured, otherwise skip first
            const photosToAnalyze = this.capturedPhotos.length > 1
                ? this.capturedPhotos.slice(1)
                : this.capturedPhotos;

            console.log(`[LivenessModule] ğŸ“¸ Analyzing ${photosToAnalyze.length} photos (skipped first: ${this.capturedPhotos.length > 1})`);

            // Calculate similarity scores
            const similarities = photosToAnalyze
                .map(p => p.similarity)
                .filter(s => s !== undefined && s !== null);

            if (similarities.length > 0) {
                const averageSimilarity = similarities.reduce((a, b) => a + b, 0) / similarities.length;
                const minScore = Math.min(...similarities);
                const maxScore = Math.max(...similarities);
                const comparisonPassed = averageSimilarity >= this.similarityThreshold;

                console.log(`[LivenessModule] ğŸ“Š Face Comparison Results:`);
                console.log(`[LivenessModule]   Average Similarity: ${(averageSimilarity * 100).toFixed(1)}%`);
                console.log(`[LivenessModule]   Min Score: ${(minScore * 100).toFixed(1)}%`);
                console.log(`[LivenessModule]   Max Score: ${(maxScore * 100).toFixed(1)}%`);
                console.log(`[LivenessModule]   ${comparisonPassed ? 'âœ… PASSED' : 'âŒ FAILED'} (threshold: ${(this.similarityThreshold * 100)}%)`);

                response.faceComparison = {
                    enabled: true,
                    passed: comparisonPassed,
                    averageSimilarity: parseFloat(averageSimilarity.toFixed(4)),
                    minScore: parseFloat(minScore.toFixed(4)),
                    maxScore: parseFloat(maxScore.toFixed(4)),
                    threshold: this.similarityThreshold,
                    photosCaptured: this.capturedPhotos.length,
                    photosAnalyzed: similarities.length,
                    photosWithChallenges: this.capturedPhotos.map(p => ({
                        challenge: p.challenge,
                        timestamp: p.timestamp,
                        similarity: p.similarity ? parseFloat(p.similarity.toFixed(4)) : null,
                    })),
                };

                // Update overall pass status to include face comparison
                if (!comparisonPassed) {
                    console.log('[LivenessModule] âš ï¸ Liveness passed but face comparison failed');
                    response.passed = false;
                    response.failureReason = 'Face comparison similarity below threshold';
                }
            } else {
                response.faceComparison = {
                    enabled: true,
                    passed: false,
                    error: 'No valid similarity scores calculated',
                    photosCaptured: this.capturedPhotos.length,
                };
            }
        }

        if (this.callbacks.onResult) {
            console.log('[LivenessModule] ğŸ“¢ Calling onResult callback with:', response);
            this.callbacks.onResult(response);
        } else {
            console.log('[LivenessModule] âš ï¸ No onResult callback registered');
        }
    };

    handleError = (error) => {
        console.error('[LivenessModule] âŒ Error occurred:', error);
        const errorResponse = {
            success: false,
            error: error.message || 'Liveness detection error',
            code: 'LIVENESS_ERROR',
        };

        if (this.callbacks.onError) {
            console.log('[LivenessModule] ğŸ“¢ Calling onError callback');
            this.callbacks.onError(errorResponse);
        } else {
            console.log('[LivenessModule] âš ï¸ No onError callback registered');
        }
    };
}

export default LivenessDetectionModule;
